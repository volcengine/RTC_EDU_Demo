"use strict";
/*
* Copyright (c) 2022 Beijing Volcano Engine Technology Ltd.
* SPDX-License-Identifier: MIT
*/
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];
    result["default"] = mod;
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const events_1 = require("events");
const NativeSDK = require("../../build/Release/electron-sdk.node");
const { logger } = require("../utils/logger");
const yuv_render_1 = require("../utils/yuv_render");
const data_1 = __importStar(require("../data"));
const utils_1 = require("../utils");
const os_1 = __importDefault(require("os"));
const types_1 = require("../types");
const room_1 = __importDefault(require("./room"));
const audio_effect_player_1 = __importDefault(require("./audio_effect_player"));
const media_player_1 = __importDefault(require("./media_player"));
var fs = require("fs");
var path = require("path");
const mkdirsSync = (dirname) => {
    if (fs.existsSync(dirname)) {
        return true;
    }
    else {
        if (mkdirsSync(path.dirname(dirname))) {
            fs.mkdirSync(dirname);
            return true;
        }
    }
};
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// RTCVideo
function checkInit(target, propertyName, projectDescriptor) {
    const method = projectDescriptor.value;
    projectDescriptor.value = function (...args) {
        let result = 0;
        try {
            if (!this.instance) {
                throw "instance is null";
            }
            result = method.apply(this, args);
        }
        catch (err) {
            console.error(`occured in  ${propertyName} results: ${result} , error: `, err);
            result = -1;
        }
        return result;
    };
    return projectDescriptor;
}
/////////////////////////////////////////////////////////////////////////////////
/** {en}
 * @list 85530
 * @detail 85532
 */
/** {zh}
 * @list 85530
 * @detail 85532
 */
class RTCVideo extends events_1.EventEmitter {
    constructor() {
        super();
        this.instance = null;
        this.defaultMixedStreamConfig = {
            is_support_client_push_stream: false,
            expected_mix_type: 0,
            room_id: "",
            user_id: "",
            push_url: "",
            audio_config: {
                sample_rate: 48000,
                channels: 2,
                bitrate: 64,
                audio_profile: 0,
                audio_codec: 0,
            },
            video_config: {
                width: 360,
                height: 640,
                fps: 15,
                gop: 2,
                bitrate: 500,
                video_codec: 0,
                enable_Bframe: false,
            },
            client_mix_config: {
                use_audio_mixer: true,
                video_format: 0,
            },
            layout_regions: [],
            background_color: "#000000",
            user_config_extra_info: "",
        };
        this.publicStreamViews = new Map();
        this.mixingTaskViews = new Map();
        this.plugins = new Map();
        this.previewUser = {
            userId: "preview",
        };
    }
    /** {en}
     * @brief Create an engine instance.
     * @param app_id A unique identifier for each App, randomly generated by the RTC console. Only instances created with the same app_id are able to communicate with each other.
     * @param parameters Reserved parameters. Please contact technical support fellow if needed.
     * @return + `0`: Success
     * + `-1`: Failure
     * @notes + This is the very first API that you must call if you want to use all the RTC capabilities.
     * + If there is no engine instance in current thread, calling this API will create one. If an engine instance has been created, calling this API again will have the created engine instance returned.
     */
    /** {zh}
     * @brief 创建引擎对象
     * @param app_id 每个应用的唯一标识符，由 RTC 控制台随机生成的。不同的 AppId 生成的实例在 RTC 中进行音视频通话完全独立，无法互通。 获取到当前应用的目录路径。
     * @param parameters 私有参数。如需使用请联系技术支持人员。
     * @return + `0`: 成功
     * + `-1`: 失败
     * @notes + 你应注意保持 handler 的生命周期必须大于 `RTCVideo` 的生命周期，即 handler 必须在调用 [createRTCVideo](#creatertcvideo) 之前创建，在调用 [destroyRTCVideo](#destroyrtcvideo) 之后销毁。
     * + 通常不建议在移动端设备上创建多于 2 个引擎实例。
     * + 如果当前线程中未创建引擎实例，那么你必须先使用此方法，以使用 RTC 提供的各种音视频能力。
     * + 如果当前线程中已创建了引擎实例，再次调用此方法时，会返回已创建的引擎实例。
     */
    createRTCVideo(app_id, parameters) {
        let ret = -1;
        do {
            if (utils_1.isNull(app_id) || arguments.length != 2) {
                return utils_1.errorFeedback("createRTCVideo");
            }
            if (this.instance) {
                console.warn("Call Init, but the instance is init yet");
                break;
            }
            this.instance = new NativeSDK.veRTCVideo();
            const tempParams = JSON.parse(parameters);
            //新增上报参数
            const newParams = {
                ...tempParams,
                "rtc.platform": 7,
            };
            ret = this.instance.createRTCVideo(app_id, this.cbEngine.bind(this), JSON.stringify(newParams));
        } while (false);
        return ret;
    }
    /** {en}
     * @brief Create a room for the call
     * @param room_id roomId is an non-empty string within 128 bytes. Each room created by calling this API requires a unique roomid. So that the room can be distinguished from each other.
     *        The following character sets are supported:
     * + 26 uppercase letters A~ Z
     * + 26 lowercase letters a~ z
     * + 10 numbers: 0~ 9
     * + Underscore "_", at sign "@" , and minus sign "-"
     * Do not create multiple rooms with the same roomId, otherwise the newly created room instance will replace the old one.
     * @return + `0`: Success
     * + `-1`: Failure
     * @notes + Each call of this API creates one `veRTCRoom` instance. Call this API as many times as the number of rooms you need.  And then call [joinRoom](#joinroom) of each `IRTCRoom` instance to join multiple rooms at the same time.  These enable Multi-room mode. In Multi-room mode, a user can subscribe to media streams in the joined rooms at the same time.
     * + To forward streams to the other rooms, call [startForwardStreamToRooms](#startforwardstreamtorooms) instead of enabling Multi-room mode.
     */
    /** {zh}
     * @brief 创建房间
     * @param room_id 标识通话房间的房间 ID，最大长度为 128 字节的非空字符串。支持的字符集范围为:
     * • 26个大写字母 A ~ Z
     * • 26个小写字母 a ~ z
     * • 10个数字 0 ~ 9
     * • 下划线 "_", at 符 "@", 减号 "-"
     * 请勿使用同样的 roomId 创建多个房间，否则后创建的房间实例会替换先创建的房间实例。
     * @return + `0`: 成功
     * + `-1`: 失败
     * @notes 多次调用此方法以创建多个 `veRTCRoom` 实例。分别调用各实例中的 joinRoom 方法，同时加入多个房间。多房间模式下，用户可以同时订阅各房间的音视频流。
     */
    createRTCRoom(room_id) {
        let instance = data_1.createdRooms.get(room_id);
        if (!instance) {
            instance = new room_1.default();
        }
        instance.createRTCRoom(room_id);
        return instance;
    }
    /** {en}
     * @brief Destroy the engine instance created by `createRTCVideo`, and release all related resources.
     * @notes + Call this API after all business scenarios related to the engine instance are destroyed. In a multi-thread scenario, you must not call `RTCVideo` related APIs after calling this interface, or the SDK may crash. When the API is called, RTC SDK destroys all memory associated with the engine instance and stops any interaction with the media server.
     * + Calling this API will start the SDK exit logic. The engine thread is held until the exit logic is complete. The engine thread is retained until the exit logic is complete. Therefore, do not call this API directly in the callback thread, or wait for the execution of the main thread in the callback and call this API in the main thread at the same time. Otherwise, it will cause a deadlock.
     */
    /** {zh}
     * @region 引擎管理
     * @brief 销毁引擎实例对象
     * @return + `0`: 成功
     * + `-1`: 失败
     * @notes + 请确保和需要销毁的 `RTCVideo`  实例相关的业务场景全部结束后，才调用此方法
     * + 该方法在调用之后，会销毁所有和此 `RTCVideo`  实例相关的内存，并且停止与媒体服务器的任何交互
     * + 调用本方法会启动 SDK 退出逻辑。引擎线程会保留，直到退出逻辑完成。因此，不要在回调线程中直接调用此 API，也不要在回调中等待主线程的执行，并同时在主线程调用本方法。不然会造成死锁。
     */
    destroyRTCVideo() {
        data_1.createdRooms.forEach((roomInstance, roomId) => {
            if (roomInstance) {
                roomInstance.destroy();
            }
            data_1.createdRooms.delete(roomId);
        });
        this.instance.destroyRTCVideo();
        this.instance = null;
        // 置空
        this.audioEffectPlayerIns = undefined;
        data_1.createdMediaPlayer.clear();
        return 0;
    }
    /** {en}
     * @brief  Get the current SDK version information.
     * @return Current SDK version information.
     */
    /** {zh}
     * @brief 获取当前 SDK 版本信息
     * @return 当前 SDK 版本信息
     */
    static getSDKVersion() {
        return NativeSDK.getSDKVersion();
    }
    /** {en}
     * @brief  Get the current SDK version information.
     * @return Current SDK version information.
     */
    /** {zh}
     * @brief 获取当前 SDK 版本信息
     * @return 当前 SDK 版本信息
     */
    static setLogConfig(log_config) {
        const defaultValue = {
            log_path: "",
            log_level: types_1.LocalLogLevel.kInfo,
            log_file_size: 10,
        };
        return NativeSDK.setLogConfig({
            ...defaultValue,
            ...log_config,
        });
    }
    /** {en}
     * @brief Get the description of the error code
     * @param code Needs to get the description of the error code
     * @returns The description of the error code
     * @notes This interface is a general function and does not need to rely on the engine object when calling.
     */
    /** {zh}
     * @brief 获取错误码的描述
     * @param code 需要获取描述的错误码
     * @return 错误码的描述
     * @notes 该接口是通用功能，调用时不需要依赖引擎对象。
     */
    static getErrorDescription(code) {
        return NativeSDK.getErrorDescription(code);
    }
    /** {en}
     * @brief Get process ID of the engine for commissioning
     * @returns Process ID
     */
    /** {zh}
     * @brief 获取加载引擎进程的 ID 方便调试
     * @return 进程的 ID
     */
    static getCurrentProcessId() {
        return NativeSDK.getCurrentProcessId();
    }
    /** {en}
    * @brief set render type
    * @param type render type
    * @notes
    *   + The default rendering type is WebGL rendering.
    *   + Set WebGL rendering，if WebGL rendering is not supported or WebGL rendering fails, it will automatically switch to Software rendering.
    *   + After setting the rendering type, the newly created cnavas rendering type will take effect in the new rendering mode.
    */
    /** {zh}
     * @brief 设置渲染类型
     * @param type 渲染类型
     * @notes
     *   + 默认渲染类型为 WebGL 渲染。
     *   + 设置渲染类型之后，新创建的 cnavas 渲染类型会以新的渲染方式生效
     *   + 设置 WebGL 渲染，如果不支持 WebGL 渲染或者 WebGL渲染失败的情况下，会自动切换为 Software 渲染。
     */
    static setRenderType(type) {
        yuv_render_1.YUVRender.setRenderType(type);
    }
    /** {en}
     * @brief Report the user feedback to RTC.
     * @param type List of preset problems.
     * @param info Specific description of other problems other than the preset problem.
     * @return + 0: Report successfully
     * + -1: Failed to report, not yet joined the room
     * + -2: Failed to report, data analysis error
     * + -3: Failed to report, missing fields
     * @notes + If the user is in the room when reporting, the report leads to the room / rooms where the user is currently located;
     * + If the user is not in the room when reporting, the report leads to the previously exited Room.
     */
    /** {zh}
     * @brief 将用户反馈的问题上报到 RTC
     * @param type 反馈问题类型。
     * @param info 预设问题以外的其他问题的具体描述，房间信息。
     * @return + 0: 上报成功
     * + -1: 上报失败，还没加入过房间
     * + -2: 上报失败，数据解析错误
     * + -3: 上报失败，字段缺失
     * @notes + 如果用户上报时在房间内，那么问题会定位到用户当前所在的一个或多个房间；
     * + 如果用户上报时不在房间内，那么问题会定位到引擎此前退出的房间。
     */
    feedback(type, info) {
        if (utils_1.isNull(type) || utils_1.isNull(info)) {
            return utils_1.errorFeedback("feedback");
        }
        return this.instance.feedback(type, info);
    }
    /** {en}
     * @brief  Sets the business ID
     * @param business_id Your customized businessId
     *         BusinessId is a tag, and you can customize its granularity.
     * @returns + 0: Success
     * + < 0: Failure.
     * + -6001: The user is already in the room.
     * + -6002: The input is invalid. Legal characters include all lowercase letters, uppercase letters, numbers, and four other symbols, including '.', '-','_', and '@'.
     * @notes + You can use businessId to distinguish different business scenarios. You can customize your businessId to serve as a sub AppId, which can share and refine the function of the AppId, but it does not need authentication.
     * + You must call this API before the [joinRoom](#joinroom) API, otherwise it will be invalid.
     */
    /** {zh}
     * @region 引擎管理
     * @brief 设置业务标识参数
     * @param business_id 用户设置的自己的 business_id 值。business_id 相当于一个 sub AppId，可以分担和细化现在 AppId 的逻辑划分的功能， 但不需要鉴权。business_id 只是一个标签，颗粒度需要用户自定义。
     * @return + 0： 成功。
     * + <0： 失败
     * + -6001： 用户已经在房间中。
     * + -6002： 输入非法，合法字符包括所有小写字母、大写字母和数字，除此外还包括四个独立字符分别是：英文句号，短横线，下划线和 `@`。
     * @notes 可通过 businessId 区分不同的业务场景。businessId 由客户自定义，相当于一个“标签”，可以分担和细化现在 AppId 的逻辑划分的功能，但不需要鉴权。
     */
    setBusinessId(business_id) {
        if (utils_1.isNull(business_id)) {
            return utils_1.errorFeedback("setBusinessId");
        }
        const reg = /^[0-9a-zA-Z@_\-]{1,128}$/;
        if (!reg.test(business_id)) {
            console.error("business_id is not right, please change: business_id不合规");
            return -1;
        }
        return this.instance.setBusinessId(business_id);
    }
    /** {en}
     * @private
     * @brief Set runtime parameters.
     * @param json_string JSON string
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @private
     * @region 引擎管理
     * @brief 设置运行时的参数
     * @param json_string json 序列化之后的字符串，用以覆盖全局参数。
     * @return + `0`: 成功
     * + `-1`: 失败
     */
    setRuntimeParameters(json_string) {
        if (!json_string) {
            return utils_1.errorFeedback("setRuntimeParameters");
        }
        const param = JSON.parse(json_string);
        if (param.hasOwnProperty("electron.video_sink_apply_rotation")) {
            this.instance.setVideoSinkApplyRotation(param["electron.video_sink_apply_rotation"]);
            // 如果只有"electron.video_sink_apply_rotation"配置，则不需要传入到native
            if (Object.keys(param).length == 1) {
                return 0;
            }
        }
        return this.instance.setRuntimeParameters(json_string);
    }
    /** {en}
     * @brief Set the way to use built-in encryption when transmitting
     * @param encrypt_type Built-in encryption algorithm.
     * @param key Encryption key, the length is limited to 36 bits, and the excess will be Truncate
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + Use this method when using the built-in encryption on transfer; if you need to use custom encryption on transfer.  Built-in encryption and custom encryption are mutually exclusive, and the transmission is determined to be encrypted according to the last method called.
     * + This method must be called before entering the room, and can be called repeatedly, taking the last called parameter as the effective parameter.
     */
    /** {zh}
     * @region 加密
     * @brief 设置传输时使用内置加密的方式
     * @param encrypt_type 加密算法 <li>`0`: 不使用内置加密</li><li>`1`:AES-128-CBC 加密算法</li><li>`2`:AES-256-CBC 加密算法</li><li>`3`:AES-128-ECB 加密算法</li><li>`4`:AES-256-ECB 加密算法</li>
     * @param key 加密密钥，长度限制为 36 位，超出部分将会被截断
     * @return + `0`: 成功
     * + `-1`: 失败
     * @notes 该方法必须在进房之前调用，可重复调用，以最后调用的参数作为生效参数。
     */
    setEncryptInfo(encrypt_type, key) {
        if (utils_1.isNull(encrypt_type) || utils_1.isNull(key)) {
            return utils_1.errorFeedback("setEncryptInfo");
        }
        return this.instance.setEncryptInfo(encrypt_type, key);
    }
    /** {en}
     * @region Plugin management
     * @brief Initialize the plugin manager
     * @return + `0`: Success
     * + `-1`: Failure
     * @notes This method must be called after creating the engine and before entering the room.
     */
    /** {zh}
     * @region 插件管理
     * @brief 初始化插件管理器
     * @return + `0`: 成功
     * + `-1`: 失败
     * @notes 该方法必须在创建引擎之后，进房之前调用。
     */
    initializePluginManager() {
        return this.instance.initializePluginManager();
    }
    /** {en}
     * @region Plugin management
     * @brief Release plugin manager
     * @return + `0`: Success
     * + `-1`: Failure
     * @notes This method must be called after the plugin manager is initialized and before the engine is destroyed.
     */
    /** {zh}
     * @region 插件管理
     * @brief 释放插件管理器
     * @return + `0`: 成功
     * + `-1`: 失败
     * @notes 该方法必须在初始化插件管理器之后，销毁引擎之前调用。
     */
    releasePluginManager() {
        let ret = this.instance.releasePluginManager();
        if (ret == 0) {
            this.plugins.clear();
        }
        return ret;
    }
    /** {en}
     * @region Plugin management
     * @brief Register plugin
     * @param info #RTCPluginInfo type: id is the unique identifier of the plugin, path is the path of the plugin library
     * @return + `0`: Success
     * + `-1`: Failure
     * @notes This method must be called after the plugin manager has been initialized.
     */
    /** {zh}
     * @region 插件管理
     * @brief 注册插件
     * @param info #RTCPluginInfo类型：id是插件的唯一标识，path是插件库的路径
     * @return + `0`: 成功
     * + `-1`: 失败
     * @notes 该方法必须在初始化插件管理器之后调用。
     */
    registerPlugin(info) {
        let ret = this.instance.registerPlugin(info);
        if (ret == 0) {
            this.plugins.set(info.id, {
                id: info.id,
                setEnabled: (enabled) => {
                    return this.instance.enablePlugin(info.id, enabled);
                },
                setParameter: (param) => {
                    return this.instance.setPluginParameter(info.id, param);
                },
            });
        }
        return ret;
    }
    /** {en}
     * @region Plugin management
     * @brief Get plugin instance
     * @param plugin_id is the unique identifier for the plugin
     * @return #RTCPlugin type, if the plugin does not exist, return undefined
     * @notes This method must be called after registering the plugin.
    */
    /** {zh}
     * @region 插件管理
     * @brief 获取插件实例
     * @param plugin_id 是插件的唯一标识
     * @return #RTCPlugin类型，如果插件不存在返回undefined
     * @notes 该方法必须在注册插件之后调用。
    */
    getPlugin(plugin_id) {
        return this.plugins.get(plugin_id);
    }
    /** {en}
     * @region Plugin management
     * @brief Uninstall plugin
     * @param plugin_id is the unique identifier for the plugin
     * @return + `0`: Success
     * + `-1`: Failure
     * @notes This method must be called after registering the plugin.
     */
    /** {zh}
     * @region 插件管理
     * @brief 卸载插件
     * @param plugin_id 是插件的唯一标识
     * @return + `0`: 成功
     * + `-1`: 失败
     * @notes 该方法必须在注册插件之后调用。
     */
    unregisterPlugin(plugin_id) {
        let ret = this.instance.unregisterPlugin(plugin_id);
        if (ret == 0) {
            this.plugins.set(plugin_id, undefined);
        }
        return ret;
    }
    /** {en}
     * @brief Start internal audio capture. The default is off.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + The local client will be informed via onAudioDeviceStateChanged after starting audio capture by calling this API.
     * + To enable a microphone without the user's permission will trigger onWarning.
     * + Call stopAudioCapture to stop the internal audio capture. Otherwise, the internal audio capture will sustain until you destroy the engine instance.
     * +  To mute and unmute microphones, we recommend using publishStream and unpublishStream, other than stopAudioCapture and this API. Because starting and stopping capture devices often need some time waiting for the response of the device, that may lead to a short silence during the communication.
     * + Once you create the engine instance, you can start internal audio capture regardless of the audio publishing state. The audio stream will start publishing only after the audio capture starts.
     */
    /** {zh}
     * @region 音频管理
     * @brief 开启内部音频采集。默认为关闭状态。
     * @return + 0：成功
     * + !0：失败
     * @notes + 进房前调用该方法，本地用户会收到 [onAudioDeviceStateChanged](85533#onaudiodevicestatechanged) 的回调。
     * + 若未取得当前设备的麦克风权限，调用该方法后会触发 onWarning 回调。
     * + 调用 stopAudioCapture 可以关闭音频采集设备，否则，SDK 只会在销毁引擎的时候自动关闭设备。
     * + 由于不同硬件设备初始化响应时间不同，频繁调用 stopAudioCapture 和本接口闭麦/开麦可能出现短暂无声问题，建议使用 publishStream/unpublishStream 实现临时闭麦和重新开麦。
     * + 创建引擎后，无论是否发布音频数据，你都可以调用该方法开启音频采集，并且调用后方可发布音频。
     */
    startAudioCapture() {
        return this.instance.startAudioCapture();
    }
    /** {en}
     * @brief Stop internal audio capture. The default is off.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + The local client will be informed via  onAudioDeviceStateChanged after stopping audio capture by calling this API.
     * + The remote clients in the room will be informed of the state change via onUserStopAudioCapture after the visible client stops audio capture by calling this API.
     * + Call startAudioCapture to enable the internal audio capture.
     * + Without calling this API the internal audio capture will sustain until you destroy the engine instance.
     */
    /** {zh}
     * @region 音频管理
     * @brief 关闭内部音频采集。默认为关闭状态。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 进房前调用该方法，本地用户会收到 [onAudioDeviceStateChanged](85533#onaudiodevicestatechanged) 的回调。
     * + 非隐身用户进房后调用该方法后，房间中的其他用户会收到 [onUserStopAudioCapture](85533#onuserstopaudiocapture) 的回调。
     * + 调用 [startAudioCapture](85532#startaudiocapture) 可以开启音频采集设备。
     * + 如果不调用本方法停止内部视频采集，则只有当销毁引擎实例时，内部音频采集才会停止。
     */
    stopAudioCapture() {
        return this.instance.stopAudioCapture();
    }
    /** {en}
     * @brief  Get a list of the audio playback device. When the audio playback device changes, you will receive the `onAudioDeviceStateChanged`, and you need to call this API again to get the new device list.
     * @returns A list of all audio playback devices
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 获取当前系统内音频播放设备列表。如果后续设备有变更，你会收到 `onAudioDeviceStateChanged`] 回调通知，然后需要重新调用本接口以获得新的设备列表。
     * @return 包含系统中所有音频播放设备的列表和相关信息
     */
    enumerateAudioPlaybackDevices() {
        return this.instance.enumerateAudioPlaybackDevices();
    }
    /** {en}
     * @brief  Get a list of audio acquisition devices in the current system. If there are subsequent device changes, you need to call this interface again to get a new device list.
     * @return An object that contains a list of all audio capture devices in the system.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 获取当前系统内音频采集设备列表。如果后续设备有变更，你需要重新调用本接口以获得新的设备列表。
     * @return 包含系统中所有音频采集设备列表和相关信息
     */
    enumerateAudioCaptureDevices() {
        return this.instance.enumerateAudioCaptureDevices();
    }
    /** {en}
     * @brief Sets the audio playback device.
     * @param device_id  Audio playback device's ID. You can get the ID by calling enumerateAudioPlaybackDevices
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes After you call followSystemPlaybackDevice to set the audio playback device to follow the system setting, you cannot call this API to set the audio playback device.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 设置音频播放设备。
     * @param device_id 音频播放设备 ID，可通过 [enumerateAudioPlaybackDevices](#enumerateaudioplaybackdevices) 获取。
     * @return  方法调用结果
     * + 0：方法调用成功
     * + <0：方法调用失败
     * @notes 当你调用 followSystemPlaybackDevice 设置音频播放设备跟随系统后，将无法调用此接口设置音频播放设备。
     */
    setAudioPlaybackDevice(device_id) {
        if (utils_1.isNull(device_id)) {
            return utils_1.errorFeedback("setAudioPlaybackDevice");
        }
        let ret = this.instance.setAudioPlaybackDevice(device_id);
        return ret;
    }
    /** {en}
     * @brief Set up audio capture devices
     * @param device_id Audio capture device ID, available through enumerateAudioCaptureDevices
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes After you call followSystemCaptureDevice to set the audio playback device to follow the system setting, you cannot call this API to set the audio capture device.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 设置音频采集设备。
     * @param device_id 音频采集设备 ID，可通过 [enumerateAudioPlaybackDevices](#enumerateaudioplaybackdevices) 获取。
     * @return  方法调用结果
     * + 0：方法调用成功
     * + <0：方法调用失败
     * @notes 当你调用 followSystemCaptureDevice 设置音频采集设备跟随系统后，将无法调用此接口设置音频采集设备。
     */
    setAudioCaptureDevice(device_id) {
        if (utils_1.isNull(device_id)) {
            return utils_1.errorFeedback("setAudioCaptureDevice");
        }
        let ret = this.instance.setAudioCaptureDevice(device_id);
        return ret;
    }
    /** {en}
     * @brief Gets the current audio playback device ID.
     * @returns Audio playback device ID
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 获取当前音频播放设备 ID。
     * @return  当前音频播放设备 ID
     */
    getAudioPlaybackDevice() {
        return this.instance.getAudioPlaybackDevice();
    }
    /** {en}
     * @brief Gets the current audio capture device ID.
     * @return Audio capture device ID
     */
    /** {zh}
     * @brief 获取当前音频采集设备 ID。
     * @return 当前音频采集设备 ID
     */
    getAudioCaptureDevice() {
        return this.instance.getAudioCaptureDevice();
    }
    /** {en}
     * @brief Set the current audio playback device volume
     * @param volume Audio playback device volume, the value range is [0,255], the setting beyond this range is invalid.
     * + [0,25] Is nearly silent;
     * + [25,75] Is low volume;
     * + [76,204] Is medium volume;
     * + [205,255] Is high volume.
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 设置当前音频播放设备音量
     * @param volume 音频播放设备音量，取值范围为 [0,255], 超出此范围设置无效。
     * + [0,25] 接近无声；
     * + [25,75] 为低音量；
     * + [76,204] 为中音量；
     * + [205,255] 为高音量。
     * @return  方法调用结果
     * + 0：方法调用成功
     * + <0：方法调用失败
     */
    setAudioPlaybackDeviceVolume(volume) {
        if (utils_1.isNull(volume)) {
            return utils_1.errorFeedback("setAudioPlaybackDeviceVolume");
        }
        return this.instance.setAudioPlaybackDeviceVolume(volume);
    }
    /** {en}
     * @brief Get the current audio playback device volume.
     * @returns Audio playback device volume, the range should be within [0,255].
     * + [0,25] Is nearly silent;
     * + [25,75] Is low volume;
     * + [76,204] Is medium volume;
     * + [205,255] Is high volume.
     */
    /** {zh}
     * @brief 获取当前音频播放设备音量
     * @return 音频播放设备音量，范围应在 [0,255] 内。
     * + [0,25] 接近无声；
     * + [25,75] 为低音量；
     * + [76,204] 为中音量；
     * + [205,255] 为高音量。
     */
    getAudioPlaybackDeviceVolume() {
        return this.instance.getAudioPlaybackDeviceVolume();
    }
    /** {en}
     * @brief Set the current audio capture volume
     * @param volume Audio capture volume, the value range is [0,255], the setting beyond this range is invalid.
     * + [0,25] Is nearly silent;
     * + [25,75] Is low volume;
     * + [76,204] Is medium volume;
     * + [205,255] Is high volume.
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 设置当前音频采集设备音量
     * @param volume 音频采集设备音量，取值范围为 [0,255], 超出此范围设置无效。
     * + [0,25] 接近无声；
     * + [25,75] 为低音量；
     * + [76,204] 为中音量；
     * + [205,255] 为高音量。
     * @return  方法调用结果
     * + 0：方法调用成功
     * + <0：方法调用失败
     */
    setAudioCaptureDeviceVolume(volume) {
        if (utils_1.isNull(volume)) {
            return utils_1.errorFeedback("setAudioCaptureDeviceVolume");
        }
        return this.instance.setAudioCaptureDeviceVolume(volume);
    }
    /** {en}
     * @brief Get the current audio capture volume
     * @returns Audio capture volume, the range is within [0,255].
     * + [0,25] Is nearly silent;
     * + [25,75] Is low volume;
     * + [76,204] Is medium volume;
     * + [205,255] Is high volume.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 获取当前音频采集设备音量
     * @return 范围应在 [0,255] 内。
     * + [0,25] 接近无声；
     * + [25,75] 为低音量；
     * + [76,204] 为中音量；
     * + [205,255] 为高音量。
     */
    getAudioCaptureDeviceVolume() {
        return this.instance.getAudioCaptureDeviceVolume();
    }
    /** {en}
     * @brief Mute or Unmute the current audio playback device. The default state is speaking.
     * @param mute + True: mute
     * + False: non-mute
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 设置当前音频播放设备静音状态，默认为非静音。
     * @param mute  <li>true：静音</li><li>false：非静音  </li>
     * @return  方法调用结果
     * + 0：方法调用成功
     * + <0：方法调用失败
     */
    setAudioPlaybackDeviceMute(mute) {
        if (utils_1.isNull(mute)) {
            return utils_1.errorFeedback("setAudioPlaybackDeviceMute");
        }
        return this.instance.setAudioPlaybackDeviceMute(mute);
    }
    /** {en}
     * @brief Get state of the audio playback device.
     * @returns + True: Mute
     * + False: Speaking
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 获取当前音频播放设备是否静音的信息。
     * @return mute  <li>true：静音</li><li>false：非静音  </li>
     */
    getAudioPlaybackDeviceMute() {
        return this.instance.getAudioPlaybackDeviceMute();
    }
    /** {en}
     * @brief Mute or Unmute the current audio capture device. The default state is speaking.
     * @param mute + True: Mute
     * + False: Speaking
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 设置当前音频采集设备静音状态，默认为非静音。
     * @param mute  <li>true：静音</li><li>false：非静音  </li>
     * @return  方法调用结果
     * + 0：方法调用成功
     * + <0：方法调用失败
     */
    setAudioCaptureDeviceMute(mute) {
        if (utils_1.isNull(mute)) {
            return utils_1.errorFeedback("setAudioCaptureDeviceMute");
        }
        return this.instance.setAudioCaptureDeviceMute(mute);
    }
    /** {en}
     * @brief Get state of the audio capture device.
     * @returns + True: Mute
     * + False: Speaking
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 获取当前音频采集设备是否静音的信息。
     * @return + true：静音
     * + false：非静音
     */
    getAudioCaptureDeviceMute() {
        return this.instance.getAudioCaptureDeviceMute();
    }
    /** {en}
     * @brief Adjust the audio capture volume.
     * @param index Index of the stream, whose volume needs to be adjusted.
     * @param volume Ratio of capture volume to original volume.
     *               This changes the volume property of the audio data other than the hardware volume.
     * Ranging: [0,400]. Unit: %
     * + 0: Mute
     * + 100: Original volume. To ensure the audio quality, we recommend [0, 100].
     * + 400: Four times the original volume with signal-clipping protection.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Call this API to set the volume of the audio capture before or during the audio capture.
     */
    /** {zh}
     * @region 音量管理
     * @brief 调节音频采集音量
     * @param index 流索引，指定调节主流还是调节屏幕流的音量<li>主流。包括：由摄像头/麦克风通过内部采集机制，采集到的视频/音频。</li><li>屏幕流。屏幕共享时共享的视频流，或来自声卡的本地播放音频流。</li>
     * @param volume 采集的音量值和原始音量的比值，范围是 [0, 400]，单位为 %，自带溢出保护。
     *               只改变音频数据的音量信息，不涉及本端硬件的音量调节。
     *        为保证更好的通话质量，建议将 volume 值设为 [0,100]。
     * + 0：静音
     * + 100：原始音量
     * + 400: 最大可为原始音量的 4 倍(自带溢出保护)
     * @notes 在开启音频采集前后，你都可以使用此接口设定采集音量。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 无论是采集来自麦克风的音频流，还是屏幕音频流，都可以使用此接口进行音量调节。
     * + 在开启音频采集前后，你都可以使用此接口设定采集音量。
     */
    setCaptureVolume(index, volume) {
        if (utils_1.isNull(index)) {
            return utils_1.errorFeedback("setCaptureVolume");
        }
        return this.instance.setCaptureVolume(index, volume);
    }
    /** {en}
     * @brief Adjust the playback volume of the mixed remote audios.  You can call this API before or during the playback.
     * @param volume Ratio(%) of playback volume to original volume, in the range [0, 400], with overflow protection.
     *               This changes the volume property of the audio data other than the hardware volume.
     *        To ensure the audio quality, we recommend setting the volume within `100`.
     * + 0: mute
     * + 100: original volume
     * + 400: Four times the original volume with signal-clipping protection.
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 音频管理
     * @brief 调节本地播放的所有远端用户混音后的音量。播放音频前或播放音频时，你都可以使用此接口设定播放音量。
     * @param volume 音频播放音量，取值范围： [0,400]。
     *               只改变音频数据的音量信息，不涉及本端硬件的音量调节。
     * 为保证更好的通话质量，建议将 volume 值设为 [0,100]。
     *  + 0: 静音
     *  + 100: 原始音量
     *  + 400: 最大可为原始音量的 4 倍(自带溢出保护)
     * @return + 0：成功
     * + !0：失败
     */
    setPlaybackVolume(volume) {
        return this.instance.setPlaybackVolume(volume);
    }
    /** {en}
     * @brief Adjust the audio playback volume of the remote user
     * @param room_id ID of the room from which the remote audio source is published
     * @param user_id  Remote user ID of the audio source
     * @param volume Ratio(%) of playback volume to original volume, in the range [0, 400], with overflow protection.
     *               This changes the volume property of the audio data other than the hardware volume.
     *               To ensure the audio quality, we recommend setting the volume within `100`.
     *               + 0: mute
     *               + 100: original volume. Default value.
     *               + 400: Up to 4 times the original volume (with overflow protection)
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 音频管理
     * @brief 调节来自远端用户的音频播放音量
     * @param room_id 音频来源用户所在的房间 ID
     * @param user_id 音频来源的远端用户 ID
     * @param volume 播放音量
     *               只改变音频数据的音量信息，不涉及本端硬件的音量调节。
     * 取值范围： [0,400]  <li> 0: 静音 </li> <li> 100: 原始音量 </li> <li> 400: 最大可为原始音量的 4 倍(自带溢出保护)
     * @return + 0：成功
     * + !0：失败
     */
    setRemoteAudioPlaybackVolume(room_id, user_id, volume) {
        return this.instance.setRemoteAudioPlaybackVolume(room_id, user_id, volume);
    }
    // /** {en}
    //  * @brief Play/Stop the local audio stream.
    //  * @param mute_state Playinging status to identify whether to play the local audio stream
    //  * @returns + 0: Success
    //  * + < 0: Failure.
    //  * @notes This method controls the local audio stream but does not affect the local audio playback device.
    //  */
    // /** {zh}
    //  * @region 音频管理
    //  * @brief 控制本地音频流播放状态：播放/不播放
    //  * @param mute_state 播放状态，标识是否播放本地音频流
    //  * @return + 0：成功
    //  * + !0：失败
    //  * @notes 本方法仅控制本地收到音频流的播放状态，并不影响本地音频播放设备。
    //  */
    // @checkInit
    // public muteAudioPlayback(mute_state: number): number {
    //   return this.instance.muteAudioPlayback(mute_state);
    // }
    /** {en}
     * @brief Stop the playback test for the local audio device.
     * @returns + `0`: Success
     * + `< 0`: Failure.
     * @notes Call this API to stop the playback test started by calling [startAudioPlaybackDeviceTest](#startaudioplaybackdevicetest) before moving on to the other device tests.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 停止音频播放设备测试。
     * @return  方法调用结果
     * + `0`：成功
     * + `< 0`：失败
     * @notes 调用 [startAudioPlaybackDeviceTest](#startaudioplaybackdevicetest) 后，需调用本方法停止测试。
     */
    stopAudioPlaybackDeviceTest() {
        return this.instance.stopAudioPlaybackDeviceTest();
    }
    // /** {en}
    //  * @brief Set the sound effect type
    //  * @param change_type Sound effect type
    //  * + `0`:	Unchanged
    //  * + `1`:	Giant
    //  * + `2`:	Chipmunk
    //  * + `3`:	Minions
    //  * + `4`:	Vibrato
    //  * + `5`:	Robot
    //  * @returns + 0: Success
    //  * + < 0: Failure.
    //  * @notes + You can call it before and after entering the room.
    //  * + Effective for both internal and external audio source.
    //  * + Only valid for mono-channel audio.
    //  * + Only valid in SDKs that include the ability of sound effects.
    //  * + Mutually exclusive with setVoiceReverbType, and the effects set later will override the effects set first.
    //  * + To use this feature, contact us for technical support.
    //  */
    // /** {zh}
    //  * @region 音频管理
    //  * @brief 设置变声特效类型
    //  * @param change_type 变声特效类型。
    //  * + `0`:	原声，不含特效
    //  * + `1`:	巨人
    //  * + `2`:	花栗鼠
    //  * + `3`:	小黄人
    //  * + `4`:	颤音
    //  * + `5`:	机器人
    //  * @return + 0：成功
    //  * + !0：失败
    //  * @notes + 在进房前后都可设置。
    //  * + 对 RTC SDK 内部采集的音频和自定义采集的音频都生效。
    //  * + 只对单声道音频生效。
    //  * + 只在包含美声特效能力的 SDK 中有效。
    //  * + 与 [setVoiceReverbType](#setvoicereverbtype) 互斥，后设置的特效会覆盖先设置的特效。
    //  * + 使用本接口前，请联系 RTC 技术支持了解更多详情。
    //  */
    // @checkInit 变声接口隐藏
    // public setVoiceChangerType(change_type: number): number {
    //   return this.instance.setVoiceChangerType(change_type);
    // }
    // /** {en}
    //  * @hidden
    //  * @brief Set the reverb effect type
    //  * @param voice_reverb_type Reverb effect type
    //  * + `0`:	Unchanged
    //  * + `1`:	Echo
    //  * + `2`:	Music concert
    //  * + `3`:	Ethereal
    //  * + `4`:	Karaoke
    //  * + `5`:	Recording studio
    //  * @returns + 0: Success
    //  * + < 0: Failure.
    //  * @notes + You can call it before and after entering the room.
    //  * + Effective for both internal and external audio source.
    //  * + Only valid for mono-channel audio.
    //  * + Only valid in SDKs that include the ability of sound effects.
    //  * + Mutually exclusive with setVoiceChangerType, and the effects set later will override the effects set first.
    //  * + To use this feature, contact us for technical support.
    //  */
    // /** {zh}
    //  * @hidden
    //  * @region 音频管理
    //  * @brief 设置混响特效类型
    //  * @param voice_reverb_type 混响特效类型
    //  * + `0`:	原声，不含特效
    //  * + `1`:	回声
    //  * + `2`:	演唱会
    //  * + `3`:	空灵
    //  * + `4`:	KTV
    //  * + `5`:	录音棚
    //  * @return
    //  * + 0：成功
    //  * + !0：失败
    //  * @notes + 在进房前后都可设置。
    //  * + 只对单声道音频生效。
    //  * + 只在包含美声特效能力的 SDK 中有效。
    //  * + 与 [setVoiceChangerType](#setvoicechangertype) 互斥，后设置的特效会覆盖先设置的特效。
    //  * + 使用本接口前，请联系 RTC 技术支持了解更多详情。
    //  */
    // @checkInit 变声接口隐藏
    // public setVoiceReverbType(voice_reverb_type: number): number {
    //   return this.instance.setVoiceReverbType(voice_reverb_type);
    // }
    /** {en}
     * @brief Sets the sound quality
     * @param audio_profile Sound quality
     * + `0`:	Default sound quality. The sound quality configuration of RoomProfileType set by the server or client.
     * + `1`: Fluent. Sample rate: 16 KHz. Mono-channel. Encoding bitrate: 32 Kpbs. Low resource consumption, and small network packets guarantees a smooth call. It is suitable for most game scenarios, such as team-wide voice chat, group-wide voice chat, nation-wide voice chat.
     * + `2`: Mono-channel standard. Sample rate: 24 KHz. Encoding bitrate: 48 Kpbs. For scenarios requiring distinct voice, you can choose this mode, which achieves balanced latency, consumption, and network packets. It is suitable for educational Apps and the online Mafia Games.
     * + `3`:	Dual-channel music. Sample rate: 48 KHz. Encoding bitrate: 128 Kpbs. This mode provides high-resolution audio at a cost of high latency, consumption, and large network packets. It is suitable for music Apps such as co-hosting and online talent contests. Not recommended for game Apps.
     * + `4`:	Dual-channel standard. Sample rate: 48 KHz. Encoding bitrate: 80 Kpbs
     * + `5`:	Mono-channel music. Sample rate: 48 KHz. Encoding bitrate: 64 Kpbs
     * @returns + `0`: Success
     * + `!0`: Failure.
     * @notes + Call this API to change the sound quality if the audio settings in the current RoomProfileType can not meet your requirements.
     * + You can call this API before and after entering the room.
     * + Support dynamic switching of sound quality during a call.
     */
    /** {zh}
     * @brief 设置音质档位。
     * @param audio_profile 音质档位
     * + `0`:	默认音质，服务器下发或客户端已设置的 RoomProfileType 的音质配置
     * + `1`: 流畅音质，单声道，采样率为 16 kHz，编码码率为 32 Kbps。流畅优先、低功耗、低流量消耗，适用于大部分游戏场景，如小队语音、组队语音、国战语音等。
     * + `2`: 单声道标准音质。采样率为 24 kHz，编码码率为 48 kbps。适用于对音质有一定要求的场景，同时延时、功耗和流量消耗相对适中，适合教育场景和狼人杀等游戏。
     * + `3`:	双声道音乐音质。采样率为 48kHz，编码码率为 128 kbps。超高音质，同时延时、功耗和流量消耗相对较大，适用于连麦 PK 等音乐场景。游戏场景不建议使用。
     * + `4`:	双声道标准音质。采样率为 48 KHz，编码码率最大值为 80 Kbps。
     * + `5`:	单声道音乐音质。采样率为 48 kHz，编码码率最大值为 64 Kbps
     * @return + `0`：成功
     * + `!0`：失败
     * @notes + 设置音质档位。当所选的 audioProfile 中的音频参数无法满足你的场景需求时，调用本接口切换的音质档位。
     * + 该方法在进房前后均可调用；
     * + 支持通话过程中动态切换音质档位。
     */
    setAudioProfile(audio_profile) {
        return this.instance.setAudioProfile(audio_profile);
    }
    /** {en}
     * @brief Start the playback test for the local audio device. RTC will start playing the audio file specified. And RTC will notify the audio volume via the `onAudioPlaybackDeviceTestVolume` periodically.
     * @param test_audio_file_path Specify the path of the audio file for the playback test, including *.mp3, *.aac, *.m4a, *.3gp, and *.wav.
     * @param indication_interval The time interval between each callback in milliseconds. We recommend setting it to 200 ms. The minimal value is 10 ms.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + You can call this API whether the user is in the room.
     * + Call [stopAudioPlaybackDeviceTest](#stopaudioplaybackdevicetest) to stop the playback test before moving on to the other device tests.
     */
    /** {zh}
     * @brief 启动音频播放设备测试。  该方法测试播放设备是否能正常工作。SDK 播放指定的音频文件，测试者如果能听到声音，说明播放设备能正常工作。
     * @param test_audio_file_path 音频文件的绝对路径，路径字符串使用 UTF-8 编码格式，支持以下音频格式: mp3，aac，m4a，3gp，wav。
     * @param indication_interval 设置 onAudioPlaybackDeviceTestVolume 音量回调的时间间隔，推荐设置为 200 毫秒或以上。单位为毫秒。最小值为 10 毫秒。
     * @return  方法调用结果
     * + 0：方法调用成功
     * + <0：方法调用失败
     * @notes + 该方法必须在 [joinRoom](#joinroom) 前调用，且不可与其它音频设备测试功能同时应用。
     * + 你需调用 [stopAudioPlaybackDeviceTest](#stopaudioplaybackdevicetest) 停止测试。
     */
    startAudioPlaybackDeviceTest(test_audio_file_path, indication_interval) {
        if (utils_1.isNull(test_audio_file_path) || utils_1.isNull(indication_interval)) {
            return utils_1.errorFeedback("startAudioPlaybackDeviceTest");
        }
        return this.instance.startAudioPlaybackDeviceTest(test_audio_file_path, indication_interval);
    }
    /** {en}
     * @brief Starts a call test.
     * @param echo_test_config Test configurations
     * @param play_delay_time Delayed audio/video playback time specifying how long you expect to receive the playback after starting the. The range of the value is [2,10] in seconds and the default value is 2.
     * @returns + 0: Success
     * + -1: Failure, testing in progress
     * + -2: Failure, you are in the room
     * + -3: Failure, neither video nor audio is captured
     * + -4: Failure, Parameter exception
     * + -5: Failure, the roomID is already used
     * @notes + Before entering the room, you can call this API to test whether your local audio/video equipment as well as the upstream and downstream networks are working correctly.
     * + Once the test starts, SDK will record your sound or video. If you receive the playback within the delay range you set, the test is considered normal.+ Once you start the test, you can either call [stopEchoTest](#stopechotest) or wait until the test stops automatically after 60s, to start the next test or enter the room.
     * + All APIs related to device control and stream control called before this API are invalidated during the test and are restored after the test.
     * + All APIs related to device control, stream control, and room entry called during the test do not take effect, and you will receive [onWarning](85533#onwarning) with the warning code `kWarningCodeInEchoTestMode`.
     * + You will receive the test result from [onEchoTestResult](85533#onechotestresult).
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 开始音频设备回路测试。
     * @param echo_test_config 回路测试参数设置
     * @param play_delay_time 音视频延迟播放的时间间隔，用于指定在开始检测多长时间后期望收到回放。取值范围为 [2,10]，单位为秒，默认为 2 秒。
     * @return  方法调用结果：
     * + 0：成功
     * + -1：失败，当前用户已经在检测中
     * + -2：失败，用户已进房
     * + -3：失败，音视频均未采集
     * + -4：失败，参数异常
     * + -5：失败，已经存在相同 roomId 的房间
     * @notes + 在进房前，用户可调用该接口对音视频通话全链路进行检测，包括对音视频设备以及用户上下行网络的检测，从而帮助用户判断是否可以正常发布和接收音视频流。
     * + 开始检测后，SDK 会录制你声音或视频。如果你在设置的延时范围内收到了回放，则视为音视频回路测试正常。
     * + 调用该方法开始音视频回路检测后，你可以调用 [stopEchoTest](#stopechotest) 立即结束测试，也可等待测试 60s 后自动结束，以更换设备进行下一次测试，或进房。
     * + 在该方法之前调用的所有跟设备控制、流控制相关的方法均在开始检测时失效，在结束检测后恢复生效。
     * + 在调用 [startEchoTest](#startechotest) 和 [stopEchoTest](#stopechotest) 之间调用的所有跟设备采集、流控制、进房相关的方法均不生效，并会收到 [onWarning](85533#onwarning) 回调，提示警告码为 `kWarningCodeInEchoTestMode`。
     * + 音视频回路检测的结果会通过 [onEchoTestResult](85533#onechotestresult) 回调通知。
     */
    startEchoTest(echo_test_config, play_delay_time) {
        if (utils_1.isNull(echo_test_config)) {
            return utils_1.errorFeedback("startEchoTest");
        }
        if (utils_1.isNull(play_delay_time)) {
            return utils_1.errorFeedback("startEchoTest");
        }
        return this.instance.startEchoTest(echo_test_config, play_delay_time);
    }
    /** {en}
     * @brief Stop the current call test.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + After calling [startEchoTest](#startechotest), you must call this API to stop the test.
     * + After stopping the test with this API, all the system devices and streams are restored to the state they were in before the test.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 停止音频设备回路测试。
     * @return  方法调用结果
     * + 0：方法调用成功
     * + <0：方法调用失败
     * @notes + 调用 [startEchoTest](#startechotest) 后，需调用本方法停止测试。
     * + 音视频回路检测结束后，所有对系统设备及音视频流的控制均会恢复到开始检测前的状态。
     */
    stopEchoTest() {
        return this.instance.stopEchoTest();
    }
    /** {en}
     * @brief Try to initialize the audio playback device for device test.
     * @param device_id Device ID
     * @returns + 0: Status normal.
     * + -1: Test not executed.
     * + -2: Init failed due to lack of permission.
     * + -3: The device does not exist. No device or device removed.
     * + -4: The audio format is not supported.
     * + -5: Error for other reasons
     * @notes + Call this API before the user joins the room.
     * + You may still fail to enable the device even you passed the test. Occupation by other application or shortage of CPU / memory may cause the failure.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 尝试初始化音频播放设备，可检测出设备不存在、权限被拒绝/禁用等异常问题。
     * @param device_id 设备索引号
     * @return 设备状态错误码
     * + 0: 设备检测结果正常
     * + -1: 接口状态不正确，例如在正常启动采集后再调用该接口进行检测
     * + -2: 采集设备无麦克风权限，尝试初始化设备失败
     * + -3: 设备不存在，当前没有设备或设备被移除时返回
     * + -4: 设备音频格式不支持
     * + -5: 其它原因错误
     * @notes 1. 该接口需在进房前调用；
     * 2. 检测成功不代表设备一定可以启动成功，还可能因设备被其他应用进程独占，或 CPU/内存不足等原因导致启动失败。
     */
    initAudioPlaybackDeviceForTest(device_id) {
        if (utils_1.isNull(device_id)) {
            return utils_1.errorFeedback("");
        }
        return this.instance.initAudioPlaybackDeviceForTest(device_id);
    }
    /** {en}
     * @brief Try to initialize the audio capture device for device test.
     * @param device_id Device ID
     * @returns + 0: Status normal.
     * + -1: Test not executed.
     * + -2: Init failed due to lack of permission.
     * + -3: The device does not exist. No device or device removed.
     * + -4: The audio format is not supported.
     * + -5: Error for other reasons
     * @notes + Call this API before the user joins the room.
     * + You may still fail to enable the device even you passed the test. Occupation by other application or shortage of CPU / memory may cause the failure.
     */
    /** {zh}
     * @brief 尝试初始化音频播放设备，可检测出设备不存在、权限被拒绝/禁用等异常问题。
     * @param device_id 设备索引号
     * @return 设备状态错误码
     * + 0: 设备检测结果正常
     * + -1: 接口状态不正确，例如在正常启动采集后再调用该接口进行检测
     * + -2: 采集设备无麦克风权限，尝试初始化设备失败
     * + -3: 设备不存在，当前没有设备或设备被移除时返回
     * + -4: 设备音频格式不支持
     * + -5: 其它原因错误
     * @notes 1. 该接口需在进房前调用；
     * 2. 检测成功不代表设备一定可以启动成功，还可能因设备被其他应用进程独占，或 CPU/内存不足等原因导致启动失败。
     */
    initAudioCaptureDeviceForTest(device_id) {
        if (utils_1.isNull(device_id)) {
            return utils_1.errorFeedback("");
        }
        return this.instance.initAudioCaptureDeviceForTest(device_id);
    }
    /** {en}
     * @brief Enable audio information prompts.
     * @param config Configuration for audio property prompt.
     * @notes After enable the prompt, you can:
     * + Get the information of the audio stream collected by the local microphone and screen audio stream through [onLocalAudioPropertiesReport](85533#onlocalaudiopropertiesreport).
     * + Get the information of the subscribed remote audio streams through [onRemoteAudioPropertiesReport](85533#onremoteaudiopropertiesreport).
     * + Get the information of the active speaker through [onActiveSpeaker](85533#onactivespeaker).
     */
    /** {zh}
     * @brief 启用音频信息提示。
     * @param config 音频属性信息提示的相关配置。
     * @notes 开启提示后，你可以：
     * + 通过 [onLocalAudioPropertiesReport](85533#onlocalaudiopropertiesreport) 回调获取本地麦克风和屏幕音频流采集的音频信息。
     * + 通过 [onRemoteAudioPropertiesReport](85533#onremoteaudiopropertiesreport) 回调获取订阅的远端用户的音频信息。
     * + 通过 [onActiveSpeaker](85533#onactivespeaker) 回调获取房间内的最活跃用户信息。
     */
    enableAudioPropertiesReport(config) {
        if (utils_1.isNull(config) || utils_1.isNull(config.interval)) {
            return utils_1.errorFeedback("enableAudioPropertiesReport");
        }
        const defaultValue = {
            interval: 0,
            enable_spectrum: false,
            enable_vad: false,
            local_main_report_mode: types_1.AudioReportMode.kAudioReportModeNormal,
            smooth: 1,
            audio_report_mode: types_1.AudioPropertiesMode.kAudioPropertiesModeMicrophone,
        };
        return this.instance.enableAudioPropertiesReport({
            ...defaultValue,
            ...config,
        });
    }
    /** {en}
     * @brief Enables/disables the loudness equalization function.
     * @param enable Whether to enable loudness equalization function:
     * + True: Yes
     * + False: No
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + If you call this API with the parameter set to True, the loudness of user's voice will be adjusted to -16lufs. If then you also call setAudioMixingLoudness and import the original loudness of the audio data used in audio mixing, the loudness will be adjusted to -20lufs when the audio data starts to play.
     * + You must call this API before starting to play the audio file with startAudioMixing.
     */
    /** {zh}
     * @region 音频管理
     * @brief 开启/关闭音量均衡功能。
     * @param enable 是否开启音量均衡功能：
     * @return + 0: 调用成功
     * + <0: 调用失败
     * @notes 开启音量均衡功能后，人声的响度会调整为 -16lufs。如果已调用 setAudioMixingLoudness 传入了混音音乐的原始响度，此音乐播放时，响度会调整为 -20lufs。（Linux 不支持）
     */
    enableVocalInstrumentBalance(enable) {
        if (utils_1.isNull(enable)) {
            return utils_1.errorFeedback("enableVocalInstrumentBalance");
        }
        return this.instance.enableVocalInstrumentBalance(enable);
    }
    /** {en}
     * @hidden
     * @brief Set an alternative image when the local internal video capture is not enabled.
     *        You can repeatedly call this API to update the image.
     *        You can set the path to null or open the camera to stop publishing the image.
     * @param file_path Set the path of the static image.
     *        You can use the absolute path (file://xxx). The maximum size for the path is 512 bytes.
     *        You can upload a .JPG, .JPEG, .PNG, or .BMP file.
     *        When the aspect ratio of the image is inconsistent with the video encoder configuration, the image will be proportionally resized, with the remaining pixels rendered black. The framerate and the bitrate are consistent with the video encoder configuration.
     * @return + 0: Success.
     * + -1: Failure.
     * @notes + The API is only effective when publishing an internally captured video.
     * + You cannot locally preview the image.
     * + You can call this API before and after joining an RTC room. In the multi-room mode, the image can be only displayed in the room you publish the stream.
     * + You cannot apply effects like filters and mirroring to the image, while you can watermark the image.
     * + The image is not effective for a screen-sharing stream.
     * + When you enable the simulcast mode, the image will be added to all video streams, and it will be proportionally scaled down to smaller encoding configurations.
     */
    /** {zh}
     * @hidden
     * @brief 摄像头处于关闭状态时，使用静态图片填充本地推送的视频流。
     *        可重复调用该接口来更新图片。若要停止发送图片，可传入空字符串或启用内部摄像头采集。
     * @param file_path 设置静态图片的路径。
     *        支持本地文件绝对路径，不支持网络链接，长度限制为 512 字节。
     *        静态图片支持类型为 JPEG/JPG、PNG、BMP。
     *        若图片宽高比与设置的编码宽高比不一致，图片会被等比缩放，黑边填充空白区域。推流帧率与码率与设置的编码参数一致。
     * @return + 0: 成功。
     * + -1: 失败。
     * @notes + 该接口只适用于 SDK 内部摄像头采集，不适用于自定义视频采集。
     * + 本地预览无法看到静态图片。
     * + 进入房间前后均可调用此方法。在多房间场景中，静态图片仅在发布的房间中生效。
     * + 针对该静态图片，滤镜和镜像效果不生效，水印效果生效。
     * + 只有主流能设置静态图片，屏幕流不支持设置。
     * + 开启大小流后，静态图片对大小流均生效，且针对小流进行等比例缩小。
     */
    setDummyCaptureImagePath(file_path) {
        if (utils_1.isNull(file_path)) {
            return utils_1.errorFeedback("setDummyCaptureImagePath");
        }
        return this.instance.setDummyCaptureImagePath(file_path);
    }
    /** {en}
     * @brief Enable internal video capture immediately. The default is off.
     * @returns + `0`: Success
     * + `!0`: Failure.
     * @notes + Internal video capture refers to: use the RTC SDK built-in video capture module to capture.
     * + The local client will be informed via [onVideoDeviceStateChanged](85533#onvideodevicestatechanged) after starting video capture by calling this API.
     * + The remote clients in the room will be informed of the state change via [onUserStartVideoCapture](85533#onuserstartvideocapture) after the visible client starts video capture by calling this API.
     * + Call stopVideoCapture to stop the internal video capture. Otherwise, the internal video capture will sustain until you destroy the engine instance.
     * + Once you create the engine instance, you can start internal video capture regardless of the video publishing state. The video stream will start publishing only after the video capture starts.
     * + To switch from custom to internal video capture, stop publishing before disabling the custom video capture module and then call this API to enable the internal video capture.
     */
    /** {zh}
     * @brief 开启内部视频采集。默认为关闭状态。
     * @return + `0`：成功
     * + `!0`：失败
     * @notes + 内部视频采集指：使用 RTC SDK 内置视频采集模块，进行采集。
     * + 调用该方法后，本地用户会收到 [onVideoDeviceStateChanged](85533#onvideodevicestatechanged) 的回调。
     * + 本地用户在非隐身状态下调用该方法后，房间中的其他用户会收到 [onUserStartVideoCapture](85533#onuserstartvideocapture) 的回调。
     * + 调用 stopVideoCapture 可以停止内部视频采集。否则，只有当销毁引擎实例时，内部视频采集才会停止。
     * + 创建引擎后，无论是否发布视频数据，你都可以调用该方法开启内部视频采集。
     */
    startVideoCapture() {
        return this.instance.startVideoCapture();
    }
    /** {en}
     * @brief Disable internal video capture immediately. The default is off.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + Internal video capture refers to: use the RTC SDK built-in video capture module to capture.
     * + The local client will be informed via onVideoDeviceStateChanged after stopping video capture by calling this API.
     * + The remote clients in the room will be informed of the state change via onUserStopVideoCapture after the visible client stops video capture by calling this API.
     * + Call startVideoCapture to enable the internal video capture.
     * + Without calling this API the internal video capture will sustain until you destroy the engine instance.
     */
    /** {zh}
     * @region 视频管理
     * @brief 关闭内部视频采集。默认为关闭状态。
     * @return + 0：成功
     * + !0：失败
     * @notes + 内部视频采集指：使用 RTC SDK 内置视频采集模块，进行采集。
     * + 调用该方法后，本地用户会收到 onVideoDeviceStateChanged 的回调。
     * + 非隐身用户进房后调用该方法，房间中的其他用户会收到 onUserStopVideoCapture 的回调。
     * + 调用 startVideoCapture 可以开启内部视频采集。
     * + 如果不调用本方法停止内部视频采集，则只有当销毁引擎实例时，内部视频采集才会停止。
     */
    stopVideoCapture() {
        return this.instance.stopVideoCapture();
    }
    /** {en}
     * @brief Get a list of video capture devices in the current system.
     * @returns Contains a list of all video capture devices in the system.
     */
    /** {zh}
     * @brief 获取当前系统内视频采集设备列表。
     * @return 包含系统中所有视频采集设备的列表和相关信息
     */
    enumerateVideoCaptureDevices() {
        return this.instance.enumerateVideoCaptureDevices();
    }
    /** {en}
     * @brief Set the audio playback device to follow the OS setting or not.
     * @param followed
     * + true: follow the OS setting. You can not call [setAudioPlaybackDevice](#setaudioplaybackdevice) at the same time. The default value.
     * + false: do not follow the OS setting. You can call [setAudioPlaybackDevice](#setaudioplaybackdevice) to set the audio playback device.
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 设置音频播放路由是否跟随系统。
     * @param followed 音频播放路由是否跟随系统
     * + true: 跟随。默认值。此时，调用 [setAudioPlaybackDevice](#setaudioplaybackdevice) 会失败。
     * + false: 不跟随系统。此时，可以调用 [setAudioPlaybackDevice](#setaudioplaybackdevice) 进行设置。
     * @return + 0：成功
     * + !0：失败
     */
    followSystemPlaybackDevice(followed) {
        if (utils_1.isNull(followed)) {
            return utils_1.errorFeedback("followSystemPlaybackDevice");
        }
        return this.instance.followSystemPlaybackDevice(followed);
    }
    /** {en}
     * @brief Set the audio capture device to follow the OS setting or not.
     * @param followed
     * + true: follow the OS setting. Default value. You can not call [setAudioCaptureDevice](#setaudiocapturedevice) at the same time.
     * + false: do not follow the OS setting. You can call [setAudioCaptureDevice](#setaudiocapturedevice) to set the audio capture device.
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 音频设备管理
     * @brief 设置音频采集路由是否跟随系统。
     * @param followed 音频采集路由是否跟随系统
     * + true: 跟随。默认值。此时，调用 [setAudioCaptureDevice](#setaudiocapturedevice) 会失败。
     * + false: 不跟随系统。此时，可以调用 [setAudioCaptureDevice](#setaudiocapturedevice) 进行设置。
     * @return
     * + 0：成功
     * + !0：失败
     */
    followSystemCaptureDevice(followed) {
        if (utils_1.isNull(followed)) {
            return utils_1.errorFeedback("followSystemCaptureDevice");
        }
        return this.instance.followSystemCaptureDevice(followed);
    }
    /** {en}
     * @brief  Set the current video capture device
     * @param device_id Video device ID, which can be obtained through [EnumerateVideoCaptureDevices](#enumeratevideocapturedevices)
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 视频设备管理
     * @brief 设置当前视频采集设备
     * @param device_id 视频设备 ID，可以通过 [EnumerateVideoCaptureDevices](#enumeratevideocapturedevices) 获取
     * @return
     * + 0：方法调用成功
     * + !0：方法调用失败
     */
    setVideoCaptureDevice(device_id) {
        if (utils_1.isNull(device_id)) {
            return utils_1.errorFeedback("setVideoCaptureDevice");
        }
        return this.instance.setVideoCaptureDevice(device_id);
    }
    /** {en}
     * @brief Get the video capture device information currently used by the SDK
     * @returns Device ID
     */
    /** {zh}
     * @region 视频设备管理
     * @brief 获取当前 SDK 正在使用的视频采集设备 ID
     * @return 当前 SDK 正在使用的视频采集设备 ID
     */
    getVideoCaptureDevice() {
        return this.instance.getVideoCaptureDevice();
    }
    /** {en}
     * @brief Video publisher call this API to set the configurations of each stream published, including resolution, frame rate, bitrate, scale mode, and fallback strategy in poor network conditions.
     * @param solutions List of configurations for multiple streams. You can set parameters for up to 3 streams, SDK will always take the value of the first 3 streams when parameters for more streams are set.
     *        The resolution you set is the maximum resolution of each stream, and must be arranged in descending order. The frame rates must be arranged in descending order.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + If you call this API after enabling the mode of publishing multiple streams with [enableSimulcastMode](#enablesimulcastmode), SDK will publish streams as you set, otherwise only the stream with the largest resolution you set will be published.
     * + Without calling this API to set parameters for multiple video streams, the SDK only publishes one video stream with a resolution of 640px × 360px and a frame rate of 15fps.
     * + After setting parameters for multiple video streams, SDK will automatically match the streams to be published based on the desired subscription parameters set by subscribers, see [Simulcasting](https://docs.byteplus.com/en/byteplus-rtc/docs/70139) for details.
     * + This API is applicable to the video stream captured by the camera, see [setScreenVideoEncoderConfig](#setscreenvideoencoderconfig) for setting parameters for screen sharing video stream.
     */
    /** {zh}
     * @region 视频管理
     * @brief 视频发布端设置期望发布的最大分辨率视频流参数，包括分辨率、帧率、码率、缩放模式、网络不佳时的回退策略等。
     * @param solutions 视频参数数组首地址。要推送的多路视频流的参数需注意，所设置的分辨率是各路流的最大分辨率。 最多支持 3 路参数。当设置了多路参数时，分辨率和帧率必须是依次减小，从大到小排列的。 最大分辨率没有限制。但是如果设置的分辨率无法编码，就会导致编码推流失败。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 该方法是否生效取决于是否同时调用了 [enableSimulcastMode](#enablesimulcastmode) 开启发布多路参数不同的视频流模式。若未开启推送多路流模式，但调用本方法设置了多个分辨率，SDK 默认发布分辨率最大的一条流，多个分辨率的设置会在开启推送多路流模式之后生效。
     * + 调用该方法设置多路视频流参数前，SDK 默认仅发布一条分辨率为 640px × 360px，帧率为 15fps 的视频流。
     * + 调用该方法设置分辨率不同的多条流后，SDK 会根据订阅端设置的期望订阅参数自动匹配发送的流，具体规则参看[推送多路流](https://www.volcengine.com/docs/6348/70139)文档。
     * + 该方法适用于摄像头采集的视频流，设置屏幕共享视频流参数参看 [setScreenVideoEncoderConfig](#setscreenvideoencoderconfig)
     */
    setVideoEncoderConfig(solutions) {
        if (utils_1.isNull(solutions)) {
            return utils_1.errorFeedback("setVideoEncoderConfig");
        }
        // set default value
        for (let i = 0; i < solutions.length; i++) {
            solutions[i].width = solutions[i].width || 360;
            solutions[i].height = solutions[i].height || 640;
            solutions[i].maxBitrate = solutions[i].maxBitrate || -1;
            solutions[i].minBitrate = solutions[i].minBitrate || 0;
            solutions[i].encoderPreference =
                solutions[i].encoderPreference ||
                    types_1.VideoEncodePreference.kVideoEncodePreferenceFramerate;
        }
        return this.instance.setVideoEncoderConfig(solutions);
    }
    /** {en}
     * @brief Video publisher call this API to set the parameters of the maximum resolution video stream that is expected to be published, including resolution, frame rate, bitrate, scale mode, and fallback strategy in poor network conditions.
     * @param max_solution The maximum video encoding parameter.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + If you call this API after enabling the mode of publishing multiple streams with [enableSimulcastMode](#enablesimulcastmode), SDK will automatically adjust the number of streams published and the parameters of each published stream according to the settings of subscribers. Up to 4 streams will be published, and the resolution you set in this API will be considered as the largest resolution among these 4 streams, see [Publish Multiple Streams](https://www.volcengine.com/docs/6348/70139) for details. Until you enable the mode of publishing multiple streams, SDK will only publish the stream you set.
     * + Without calling this API, SDK will only publish one stream for you with a resolution of 640px × 360px and a frame rate of 15fps.
     * + This API is applicable to the video stream captured by the camera, see [setScreenVideoEncoderConfig](#setscreenvideoencoderconfig) for setting parameters for screen sharing video stream.
     */
    /** {zh}
     * @region 视频管理
     * @brief 视频发布端设置期望发布的最大分辨率视频流参数，包括分辨率、帧率、码率、缩放模式、网络不佳时的回退策略等。
     * @param max_solution 期望发布的最大分辨率视频流参数。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 若调用该方法设置了期望发布的最大分辨率的流参数之前，已调用 [enableSimulcastMode](#enablesimulcastmode) 开启发布多路视频流的模式，SDK 会根据订阅端的设置自动调整发布的流数以及各路流的参数，其中最大分辨率为设置的分辨率，流数最多 4 条，具体参看[推送多路流](https://www.volcengine.com/docs/6348/70139)文档；否则仅发布该条最大分辨率的视频流。
     * + 调用该方法设置多路视频流参数前，SDK 默认仅发布一条分辨率为 640px × 360px，帧率为 15fps 的视频流。
     * + 该方法适用于摄像头采集的视频流，设置屏幕共享视频流参数参看 [setScreenVideoEncoderConfig](#setscreenvideoencoderconfig)
     */
    setMaxVideoEncoderConfig(max_solution) {
        if (utils_1.isNull(max_solution)) {
            return utils_1.errorFeedback("setMaxVideoEncoderConfig");
        }
        // Default
        const tempSolution = {
            frameRate: 0,
            height: 0,
            width: 0,
            maxBitrate: -1,
            minBitrate: 0,
            encoderPreference: types_1.VideoEncodePreference.kVideoEncodePreferenceFramerate,
        };
        return this.instance.setMaxVideoEncoderConfig({
            ...tempSolution,
            ...max_solution,
        });
    }
    /** {en}
     * @brief Sets the mirror mode for the captured video stream.
     * @param room_id Room ID
     * @param mirror_type Mirror type
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + Switching video streams does not affect the settings of the mirror type.
     * + This API is not applicable to screen-sharing streams.
     * + Before you call this API, the initial states of each video stream are as follows:
     *         <table>
     *            <tr><th></th><th>Front-facing camera</th><th>Back-facing camera</th><th>Custom capturing</th><th>Built-in camera</th></tr>
     *            <tr><td>Mobile device</td><td>The preview is mirrored. The published video stream is not mirrored.</td><td>The preview and the published video stream are not mirrored.</td><td>The preview and the published video stream are not mirrored.</td><td>/</td></tr>
     *            <tr><td>PC</td><td>/</td><td>/</td><td>The preview and the published video stream are not mirrored.</td><td>The preview is mirrored. The published video stream is not mirrored.</td></tr>
     *         </table>
     */
    /** {zh}
     * @region 视频管理
     * @brief 为采集到的视频流开启镜像
     * @param room_id 房间 ID
     * @param mirror_type 镜像类型
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 切换视频源不影响镜像设置。
     * + 屏幕视频流始终不受镜像设置影响。
     * + 该接口调用前，各视频源的初始状态如下：
     *        <table>
     *           <tr><th></th><th>前置摄像头</th><th>后置摄像头</th><th>自定义采集视频源</th> <th>桌面端摄像头</th> </tr>
     *           <tr><td>移动端</td><td>本地预览镜像，编码传输不镜像</td><td> 本地预览不镜像，编码传输不镜像 </td><td> 本地预览不镜像，编码传输不镜像 </td><td>/</td></tr>
     *           <tr><td>桌面端</td><td>/</td><td>/</td><td> 本地预览不镜像，编码传输不镜像 </td><td> 本地预览镜像，编码传输不镜像 </td></tr>
     *        </table>
     */
    setLocalVideoMirrorType(mirror_type) {
        var _a, _b;
        let user = this.previewUser;
        if (user) {
            if (mirror_type === types_1.MirrorType.kMirrorTypeRender) {
                user.renderOptions.mirror = true;
                (_a = user.videoRender) === null || _a === void 0 ? void 0 : _a.setMirrorType(true);
            }
            else {
                user.renderOptions.mirror = false;
                (_b = user.videoRender) === null || _b === void 0 ? void 0 : _b.setMirrorType(false);
            }
        }
        return this.instance.setLocalVideoMirrorType(mirror_type);
    }
    /** {en}
     * @brief Enables/Disables the mode of publishing multiple video streams with different encoding configuration.
     * @param enabled Whether to enable the mode of publishing multiple video streams:
     * + True: Yes
     * + False: No(Default setting)
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes You can call this API
     *  - Before entering the room, or
     *  - After entering the room but before publishing streams.
     * + After setting this API to "True", you can call [SetVideoEncoderConfig](#setvideoencoderconfig) to set encoding configuration for each stream.
     * + If this function is off, or if this function is on but you don't set the configuration of any stream, only one stream will be sent with a resolution of 640px × 360px and a frame rate of 15fps.
     */
    /** {zh}
     * @region 视频管理
     * @brief 该方法设置视频流发布端是否开启发布多路编码参数不同的视频流的模式。
     * @param enabled 是否开启推送多路视频流模式：
     * + True：开启
     * + False：关闭（默认）
     * @return
     * + 0: 调用成功
     * + <0: 调用失败
     * @notes + 你应在进房前或进房后但未发布流时，调用此方法。
     * + 开启推送多路视频流模式后，你可以调用 [SetVideoEncoderConfig](#setvideoencoderconfig) 为多路视频流分别设置编码参数。
     * + 该功能关闭时，或该功能开启但未设置多路流参数时，默认只发一路视频流，该流的编码参数为：分辨率 640px × 360px，帧率 15fps。
     */
    enableSimulcastMode(enabled) {
        if (utils_1.isNull(enabled)) {
            return utils_1.errorFeedback("enableSimulcastMode");
        }
        return this.instance.enableSimulcastMode(enabled);
    }
    /** {en}
     * @brief  Video effects license check
     * @param license_path Absolute path of license file from platforms
     * @param algo_model_dir The absolute path of the Effects SDK's models file.
     * @returns + `0`: call succeeded
     * + `1000`: not integrated cv sdk
     * + `1001`: cv function is not supported in this RTC version
     * + `< 0`: Failure Please refer to [Error Code Table](https://docs.byteplus.com/en/effects/docs/error-code-table).
     * @notes Before you start using video effects, you must first call this method for license verification
     */
    /** {zh}
     * @region 视频特效
     * @brief 视频特效许可证检查
     * @param license_path 许可证文件绝对路径
     * @param algo_model_dir 算法模型绝对路径，即存放特效 SDK 所有算法模型的目录。
     * @return + `0`: 调用成功
     * + `1000`: 未集成 CV SDK
     * + `1001`: 本版本不支持 CV 功能
     * + `<0`: 调用失败，具体错误码请参考 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     * @notes 开始使用视频特效前，你必须先调用这个方法进行许可证验证
     */
    initCVResource(license_path, algo_model_dir) {
        if (utils_1.isNull(license_path) || utils_1.isNull(algo_model_dir)) {
            return utils_1.errorFeedback("initCVResource");
        }
        return this.instance.initCVResource(license_path, algo_model_dir);
    }
    /** {en}
     * @brief Get authorization messages from the Effect SDK to obtain online licenses.
     * @returns Authorization message string address
     * @notes + You must obtain an online license for the Effect SDK before using the CV functions.
     * + After obtaining authorization messages through this API, you must refer to [Online Authorization Instructions](https://docs.byteplus.com/en/effects/docs/online-license-guide) to implement the business logic of obtaining online licenses by yourself.
     * + After obtaining the license, you must call [initCVResource](#initcvresource) to confirm that the license is valid. Then you can use the CV function.
     */
    /** {zh}
     * @brief 从 CV SDK 获取授权消息，用于获取在线许可证。
     * @return 授权消息字符串
     * @notes + 使用视频特效的功能前，你必须获取特效 SDK 的在线许可证。
     * + 使用背景分割或视频特效的功能前，你必须自行实现获取智能美化特效产品在线许可证的业务逻辑，参考 [在线授权说明](https://www.volcengine.com/docs/6705/102012)。
     * + 获取许可证后，建议调用 [initCVResource](#initcvresource) 确认许可证有效，再开始使用背景分割或视频特效功能。
     */
    getAuthMessage() {
        return this.instance.getAuthMessage();
    }
    /** {en}
     * @brief Enables video effects including beauty and color filters.
     * @return
     * + 0: Success.
     * + –1000: The Effects SDK is not integrated.
     * + –1001: This API is unavailable for your Effects SDK.
     * + –1002: Your Effects SDK's version is incompatible.
     * + < 0: Other error. See [error code table](https://docs.byteplus.com/effects/docs/error-code-table) for specific instructions.
     * @notes
     * + You must call [initCVResource](#initcvresource) before calling this API.
     * + This API does not turn on video effects directly, you must call [setEffectNodes](#seteffectnodes) or [setColorFilter](#setcolorfilter) next.
     * + Call [disableVideoEffect](#disablevideoeffect) to turn off video effects.
     */
    /** {zh}
     * @brief 开启高级美颜、滤镜等视频特效。
     * @return
     * + 0: 调用成功。
     * + –1000: 未集成特效 SDK。
     * + –1001: 特效 SDK 不支持该功能。
     * + –1002: 特效 SDK 版本不兼容。
     * + < 0: 调用失败，错误码对应具体描述参看 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     * @notes
     * + 调用本方法前，必须先调用 [initCVResource](#initcvresource) 进行初始化。
     * + 调用该方法后，特效不直接生效，你还需调用 [setEffectNodes](#seteffectnodes) 设置视频特效素材包或调用调用 [setColorFilter](#setcolorfilter) 设置滤镜。
     * + 调用 [disableVideoEffect](#disablevideoeffect) 关闭视频特效。
     */
    enableVideoEffect() {
        return this.instance.enableVideoEffect();
    }
    /** {en}
     * @brief Disables video effects.
     * @return
     * + 0: Success.
     * + –1000: The Effects SDK is not integrated.
     * + –1001: This API is unavailable for your Effects SDK.
     * + –1002: Your Effects SDK's version is incompatible.
     * + < 0: Other error. See [error code table](https://docs.byteplus.com/effects/docs/error-code-table) for specific instructions.
     * @notes Call [enableVideoEffect](#enablevideoeffect) to enable video effects.
     */
    /** {zh}
     * @brief 关闭视频特效。
     * @return + 0: 调用成功。
     * + –1000: 未集成特效 SDK。
     * + –1001: 特效 SDK 不支持该功能。
     * + –1002: 特效 SDK 版本不兼容。
     * + < 0: 调用失败，错误码对应具体描述参看 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     * @notes 调用 [enableVideoEffect](#enablevideoeffect) 开启视频特效。
     */
    disableVideoEffect() {
        return this.instance.disableVideoEffect();
    }
    /** {en}
     * @brief Enables/Disables basic beauty effects.
     * @param enabled Whether to enable basic beauty effects.
     * + true: Enables basic beauty effects.
     * + false: (Default) Disables basic beauty effects.
     * @returns + 0: Success
     * + 1000: The Effect SDK is not integrated.
     * + 1001: This API is not available for your current RTC SDK.
     * + 1002: This API is not available for your current Effect SDK. You can upgrade your Effect SDK to V4.3.1+.
     * + 1003: Contact our technical support team for further instructions.
     * + 1004: Downloading related resources. The beauty effects will take effect after downloading.
     * + <0: Failure. Effect SDK internal error. For specific error code, see [error codes](https://docs.byteplus.com/effects/docs/error-code-table).
     * @notes + You cannot use the basic beauty effects and the advanced effect features at the same time. Call [enableVideoEffect](#enablevideoeffect) to use advanced effect features.
     * + You need to integrate Effect SDK before calling this API. Effect SDK V4.3.1+ is recommended.
     * + Call [setBeautyIntensity](#setbeautyintensity) to set the beauty effect intensity. If you do not set the intensity, the brightness, smoothness, and sharpness intensity will default to 0.5.
     * + This API is not applicable to screen capturing.
     */
    /** {zh}
     * @region 视频特效
     * @brief 开启/关闭基础美颜
     * @param enabled 是否开启基础美颜强度，true: 开启，false: 关闭
     * @return
     * + 0: 开启/关闭成功。
     * + 1000: 未集成特效 SDK。
     * + 1001: RTC SDK 版本不支持此功能。
     * + 1002: 特效 SDK 当前版本不支持此功能，建议使用特效 SDK V4.3.1 版本。
     * + 1003: 联系技术支持人员。
     * + 1004: 正在下载相关资源，下载完成后生效。
     * + <0: 调用失败，特效 SDK 内部错误，具体错误码请参考[错误码表](https://www.volcengine.com/docs/6705/102042)。
     * @notes + 本方法不能与高级视频特效接口共用。如已购买高级视频特效，建议调用 [enableVideoEffect](#enablevideoeffect) 使用高级特效、贴纸功能等。
     * + 使用此功能需要集成特效 SDK，建议使用特效 SDK V4.3.1+ 版本。
     * + 调用 [setBeautyIntensity](#setbeautyintensity) 设置基础美颜强度。若在调用本方法前没有设置美颜强度，则初始美白、磨皮、锐化强度均为 0.5。
     * + 本方法仅适用于视频源，不适用于屏幕源
     */
    enableEffectBeauty(enabled) {
        if (utils_1.isNull(enabled)) {
            return utils_1.errorFeedback("");
        }
        return this.instance.enableEffectBeauty(enabled);
    }
    /** {en}
     * @brief Sets the beauty effect intensity.
     * @param beauty_mode Basic beauty effect
     * @param intensity Beauty effect intensity in range of [0,1], default to 0.5. When you set it to 0, the beauty effect will be turned off.
     * @returns + `0`: Success
     * + `-1000`: The Effect SDK is not integrated.
     * + `-1001`: This API is not available for your current RTC SDK.
     * + `<0`: Failure. Effect SDK internal error. For specific error code, see [error codes](https://docs.byteplus.com/effects/docs/error-code-table).
     * @notes + We recommend to call [initCVResource](#initcvresource) to validate the license before using video effect enhancement.
     * + If you call this API before calling [enableEffectBeauty](#enableeffectbeauty), the default settings of beauty effect intensity will adjust accordingly.
     * + If you destroy the engine, the beauty effect settings will be invalid.
     */
    /** {zh}
     * @brief 调整基础美颜强度
     * @param beauty_mode 基础美颜模式
     * @param intensity 美颜强度，取值范围为 [0,1]。强度为 0 表示关闭，默认强度为 0.5。
     * @return + `0`: 调用成功
     * + `-1000`: 未集成 CV SDK
     * + `-1001`: 本版本不支持 CV 功能
     * + `<0`: 调用失败，具体错误码请参考 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     * @notes + 获取许可证后，建议调用 [initCVResource](#initcvresource) 确认许可证有效，再开始使用背景分割或视频特效功能。
     * + 若在调用 [enableEffectBeauty](#enableeffectbeauty) 前设置美颜强度，则对应美颜功能的强度初始值会根据设置更新。
     * + 销毁引擎后，美颜功能强度恢复默认值。
     */
    setBeautyIntensity(beauty_mode, intensity) {
        if (utils_1.isNull(beauty_mode) || utils_1.isNull(intensity)) {
            return utils_1.errorFeedback("setBeautyIntensity");
        }
        return this.instance.setBeautyIntensity(beauty_mode, intensity);
    }
    /** {en}
     * @brief Set video effects material package.
     * @param effect_node_paths Array of effect material package paths. To remove the current video effect, set it to null.
     * @returns + 0: Success
     * + 1000: The Effect SDK is not integrated.
     * + 1001: This API is not available for your Effect SDK.
     * + < 0: Failure. For specific error codes
     */
    /** {zh}
     * @brief 设置视频特效素材包，支持同时设置多个素材包
     * @param effect_node_paths  特效素材包路径数组。取消当前视频特效，将此参数设置为 null。
     * @return + 0: 调用成功
     * + 1000: 未集成 CV SDK
     * + 1001: 本 RTC 版本不支持 CV 功能
     * + <0: 调用失败，具体错误码，请参考 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     */
    setEffectNodes(effect_node_paths) {
        if (effect_node_paths === null) {
            return this.instance.setEffectNodes([]);
        }
        return this.instance.setEffectNodes(effect_node_paths);
    }
    /** {en}
     * @brief Set the effect intensity
     * @param effect_node_path Special effects material package path
     * @param node_key The name of the material key to be set.
     * @param node_value The intensity value that needs to be set, the value range [0,1], and the setting is invalid when it exceeds the range.
     * @return + 0: Success.
     * –1000: The Effects SDK is not integrated.
     * –1001: This API is unavailable for your Effects SDK.
     * –1002: Your Effects SDK's version is incompatible.
     * < 0: Other error. See [error code table](https://docs.byteplus.com/effects/docs/error-code-table) for specific instructions.
     */
    /** {zh}
     * @brief 设置特效强度
     * @param effect_node_path 特效素材包路径
     * @param node_key 需要设置的素材 key 名称，取值请参考 [素材 key 对应说明](https://www.volcengine.com/docs/6705/102040)。
     * @param node_value 需要设置的强度值 取值范围 [0,1]，超出范围时设置无效。
     * @return + 0: 调用成功。
     * –1000: 未集成特效 SDK。
     * –1001: 特效 SDK 不支持该功能。
     * –1002: 特效 SDK 版本不兼容。
     * < 0: 调用失败，错误码对应具体描述参看 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     */
    updateEffectNode(effect_node_path, node_key, node_value) {
        if (utils_1.isNull(effect_node_path) || utils_1.isNull(node_key) || utils_1.isNull(node_value)) {
            return utils_1.errorFeedback("updateNode");
        }
        return this.instance.updateEffectNode(effect_node_path, node_key, node_value);
    }
    /** {en}
     * @brief Set the color filter.
     * @param res_path Filter effects package absolute path.
     * @returns + 0: Success
     * + < 0: Failure.
     * + 1000: The Effect SDK is not integrated.
     * + 1001: This API is not available for your Effect SDK.
     * + <0: Other errors.
     */
    /** {zh}
     * @region 视频特效
     * @brief 设置颜色滤镜
     * @param res_path 滤镜资源包绝对路径。
     * @return + 0: 调用成功
     * + 1000: 未集成 CV SDK
     * + 1001: 本 RTC 版本不支持 CV 功能
     * + <0: 调用失败，具体错误码，请参考 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     */
    setColorFilter(res_path) {
        if (utils_1.isNull(res_path)) {
            return utils_1.errorFeedback("setColorFilter");
        }
        return this.instance.setColorFilter(res_path);
    }
    /** {en}
     * @brief Set the intensity of the color filter enabled
     * @param intensity  Filter intensity. The value range [0,1] is set to be invalid when the range is exceeded.
     * @returns + 0: Success
     * + 1000: The Effect SDK is not integrated.
     * + 1001: This API is not available for your Effect SDK.
     * + < 0: Failure.
     */
    /** {zh}
     * @region 视频特效
     * @brief 设置已启用颜色滤镜的强度
     * @param intensity 滤镜强度。取值范围 [0,1]，超出范围时设置无效。
     * @return + 0: 调用成功
     * + 1000: 未集成 CV SDK
     * + 1001: 本 RTC 版本不支持 CV 功能
     * + <0: 调用失败，具体错误码，请参考 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     */
    setColorFilterIntensity(intensity) {
        if (utils_1.isNull(intensity)) {
            return utils_1.errorFeedback("setColorFilterIntensity");
        }
        return this.instance.setColorFilterIntensity(intensity);
    }
    /** {en}
     * @deprecated
     * @hidden
     * @brief Create a new task of pushing media streams to CDN and sets the relevant configurations.
     * @param task_id Task ID. You may want to push more than one mixed stream to CDN from the same room. When you do that, use different ID for corresponding tasks; if you will start only one task, use an empty string.
     * @param param  Configurations to be set when pushing streams to CDN.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + When pushing more than one live streams in the same task, SDK will first mix those streams into one single stream and then push it to CDN.
     * + After calling this API, you will be informed of the result and errors during the pushing process via the onStreamMixingEvent(85533#onstreammixingevent) callback.
     * + Call [stopLiveTranscoding](#stoplivetranscoding) to stop pushing streams to CDN.
     */
    /** {zh}
     * @deprecated
     * @hidden
     * @brief 开启转推直播，并设置合流的视频视图布局和音频属性。
     * @param task_id 转推直播任务 ID。你可以在同一房间内发起多个转推直播任务，并用不同的任务 ID 加以区。当你需要发起多个转推直播任务时，应使用多个 ID；当你仅需发起一个转推直播任务时，建议使用空字符串。
     * @param param 转推直播配置参数
     * @return + 0：成功
     * + !0：失败
     * @notes + 同一个任务中转推多路直播流时，SDK 会先将多路流合成一路流，然后再进行转推。
     * + 调用该方法后，关于启动结果和推流过程中的错误，会收到 onStreamMixingEvent(85533#onstreammixingevent) 回调。
     * + 调用 [stopLiveTranscoding](#stoplivetranscoding) 停止转推直播。
     */
    startLiveTranscoding(task_id, param) {
        if (!task_id || utils_1.isNull(param) || !param.room_id || !param.user_id) {
            return utils_1.errorFeedback("startLiveTranscoding");
        }
        //Default
        const tempParam = {
            app_data: "",
            expected_mix_type: 0,
            background_color: "0x000000",
            room_id: "",
            user_id: "",
            uri: "",
            audio_param: {
                i32_sample_rate: 48000,
                i32_channel_num: 2,
                i32_bitrate_kbps: 128,
                audio_codec_profile: 0,
                audio_codec_type: types_1.TranscoderAudioCodecType.kTranscodeAudioCodecAAC,
            },
            video_param: {
                i32_width: 640,
                i32_height: 360,
                i32_fps: 15,
                i32_gop: 60,
                i32_bitrate_kbps: 500,
                video_codec_type: 0,
                bFrame: false,
            },
            layout_regions: [],
        };
        return this.instance.startLiveTranscoding(task_id, {
            ...tempParam,
            ...param,
        });
    }
    /** {en}
     * @deprecated
     * @hidden
     * @brief Stops pushing media streams to CDN.
     * @param task_id Task ID. Specifys which pushing task you want to stop.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes You will be informed of the change via the [onStreamMixingEvent](85533#onstreammixingevent).
     */
    /** {zh}
     * @deprecated
     * @hidden
     * @brief 停止转推直播。
     * @param task_id 转推直播任务 ID。指定想要停止的转推直播任务。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 会收到 [onStreamMixingEvent](85533#onstreammixingevent) 回调。
     * + 关于启动转推直播，参看 [startLiveTranscoding](#startlivetranscoding)。
     */
    stopLiveTranscoding(task_id) {
        if (!task_id) {
            return utils_1.errorFeedback("stopLiveTranscoding");
        }
        return this.instance.stopLiveTranscoding(task_id);
    }
    /** {en}
     * @deprecated
     * @hidden
     * @brief Update parameters needed when pushing media streams to CDN.
     * @param task_id Task ID. Specifys of which pushing task you want to update the parameters.
     * @param param Configurations that you want to update. You can update any property for the task unless it is specified as unavailable for updates.
     *              If you left some properties blank, you can expect these properties to be set to their default values.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + You will be informed of the change via the onStreamMixingEvent(85533#onstreammixingevent).
     * + After calling [startLiveTranscoding](#startlivetranscoding) to enable the function of pushing streams to CDN, you can call this API to update the relevant configurations.
     */
    /** {zh}
     * @deprecated
     * @hidden
     * @brief 更新转推直播参数。
     * @param task_id 转推直播任务 ID。指定想要更新参数设置的转推直播任务。
     * @param param 转推直播配置参数。除特殊说明外，均支持过程中更新。
     *              调用时，结构体中没有传入值的属性，会被更新为默认值。
     * @return + 0：成功
     * + !0：失败
     * @notes + 会收到 onStreamMixingEvent(85533#onstreammixingevent) 回调。
     * + 使用 [startLiveTranscoding](#startlivetranscoding) 启用转推直播功能后，使用此方法更新功能配置参数。
     */
    updateLiveTranscoding(task_id, param) {
        if (utils_1.isNull(task_id) || utils_1.isNull(param) || !param.room_id || !param.user_id) {
            return utils_1.errorFeedback("updateLiveTranscoding");
        }
        ////Default
        const tempParam = {
            app_data: "",
            expected_mix_type: 0,
            background_color: "0x000000",
            room_id: "",
            user_id: "",
            uri: "",
            audio_param: {
                i32_sample_rate: 48000,
                i32_channel_num: 2,
                i32_bitrate_kbps: 128,
                audio_codec_profile: 0,
                audio_codec_type: types_1.TranscoderAudioCodecType.kTranscodeAudioCodecAAC,
            },
            video_param: {
                i32_width: 640,
                i32_height: 360,
                i32_fps: 15,
                i32_gop: 60,
                i32_bitrate_kbps: 500,
                video_codec_type: 0,
                bFrame: false,
            },
            layout_regions: [],
        };
        // TranscoderLayoutRegion类型，需设置apply_spatial_audio默认true
        if (param.layout_regions && param.layout_regions.length) {
            param.layout_regions = param.layout_regions.map(elem => {
                if (elem.apply_spatial_audio === undefined) {
                    elem.apply_spatial_audio = true;
                }
                return elem;
            });
        }
        return this.instance.updateLiveTranscoding(task_id, {
            ...tempParam,
            ...param,
        });
    }
    /** {en}
     * @brief Create a new task of pushing a single media stream to CDN.
     * @param task_id Task ID. You may want to start more than one task to push streams to CDN. When you do that, use different IDs for corresponding tasks; if you will start only one task, use an empty string.
     * @param param  Configurations for pushing a single stream to CDN.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + After calling this API, you will be informed of the result and errors during the pushing process with [`onStreamPushEvent`](85533#onstreampushevent).
     * + Call [`stopPushStreamToCDN`](85532#stoppushstreamtocdn) to stop the task.
     */
    /** {zh}
     * @brief 新增单流转推直播任务。
     * @param task_id 任务 ID。你可以发起多个转推直播任务，并用不同的任务 ID 加以区分。当你需要发起多个转推直播任务时，应使用多个 ID；当你仅需发起一个转推直播任务时，建议使用空字符串。
     * @param param 转推直播配置参数
     * @return + 0：成功
     * + !0：失败
     * @notes + 调用该方法后，关于启动结果和推流过程中的错误，会收到 [`onStreamPushEvent`](85533#onstreampushevent) 回调。
     * + 调用 [`stopPushStreamToCDN`](85532#stoppushstreamtocdn) 停止任务。
     */
    startPushSingleStreamToCDN(task_id, param) {
        if (utils_1.isNull(task_id) ||
            utils_1.isNull(param) ||
            utils_1.isNull(param.room_id) ||
            utils_1.isNull(param.user_id) ||
            utils_1.isNull(param.uri) ||
            utils_1.isNull(param.is_screen_stream)) {
            return utils_1.errorFeedback("startPushSingleStreamToCDN");
        }
        return this.instance.startPushSingleStreamToCDN(task_id, param);
    }
    /** {en}
     * @brief Stops the task to push a single media stream to CDN.
     * @param task_id Task ID. Specifys the task to stop.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes To start the task, refer to [`startPushStreamToCDN`](85532#rtcvideo-startpushsinglestreamtocdn) and [`startPushSingleStreamToCDN`](85532#rtcvideo-startpushsinglestreamtocdn).
     */
    /** {zh}
     * @brief 停止转推直播。
     * @param task_id 转推直播任务 ID。指定想要停止的转推直播任务。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 关于启动转推直播，参看 [`startPushStreamToCDN`](85532#rtcvideo-startpushsinglestreamtocdn) 和 [`startPushSingleStreamToCDN`](85532#rtcvideo-startpushsinglestreamtocdn)。
     */
    stopPushStreamToCDN(task_id) {
        if (utils_1.isNull(task_id)) {
            return utils_1.errorFeedback("stopPushStreamToCDN");
        }
        return this.instance.stopPushStreamToCDN(task_id);
    }
    /** {zh}
     * @brief 支持根据业务场景，设置通话中的音频降噪模式。
     * @param ans_Mode 降噪模式。
     * @notes 该接口可重复调用，仅最后一次调用生效。
     */
    /** {en}
     * @brief Set the Active Noise Cancellation(ANC) mode during audio and video communications.
     * @param ans_mode ANC modes.
     * @notes  When you repeatedly call this API, only the last call takes effect.
     */
    setAnsMode(ans_mode) {
        if (utils_1.isNull(ans_mode)) {
            return utils_1.errorFeedback("setAnsMode");
        }
        return this.instance.setAnsMode(ans_mode);
    }
    /** {en}
     * @brief Sets the super resolution mode for remote video stream.
     * @param stream_key Remote stream information that specifies the source and type of the video stream.
     * @param mode Super resolution mode.
     * @return + `0`: RETURN_STATUS_SUCCESS. It does not indicate the actual status of the super resolution mode, you should refer to [onRemoteVideoSuperResolutionModeChanged](85533#onremotevideosuperresolutionmodechanged) callback.
     * + `-1`: RETURN_STATUS_NATIVE_IN_VALID. Native library is not loaded.
     * + `-2`: RETURN_STATUS_PARAMETER_ERR. Invalid parameter.
     * + `-9`: RETURN_STATUS_SCREEN_NOT_SUPPORT. Failure. Screen stream is not supported.
     * @notes + Call this API after joining room.
     * + The original resolution of the remote video stream should not exceed 640 × 360 pixels.
     * + You can only turn on super-resolution mode for one stream.
     */
    /** {zh}
     * @brief 设置远端视频超分模式。
     * @param stream_key 远端流信息，用于指定需要设置超分的视频流来源及属性。
     * @param mode 超分模式。
     * @return + `0`: RETURN_STATUS_SUCCESS，SDK 调用成功，并不代表超分模式实际状态，需要根据回调 [onRemoteVideoSuperResolutionModeChanged](85533#onremotevideosuperresolutionmodechanged) 判断实际状态。
     * + `-1`: RETURN_STATUS_NATIVE_IN_VALID，native library 未加载。
     * + `-2`: RETURN_STATUS_PARAMETER_ERR，参数非法，指针为空或字符串为空。
     * + `-9`: RETURN_STATUS_SCREEN_NOT_SUPPORT，不支持对屏幕流开启超分。
     * @notes + 该方法须进房后调用。
     * + 远端用户视频流的原始分辨率不能超过 640 × 360 px。
     * + 支持对一路远端流开启超分，不支持对多路流开启超分。
     */
    setRemoteVideoSuperResolution(stream_key, mode) {
        if (utils_1.isNull(stream_key) ||
            utils_1.isNull(stream_key.room_id) ||
            utils_1.isNull(stream_key.stream_index) ||
            utils_1.isNull(stream_key.user_id) ||
            utils_1.isNull(mode)) {
            return utils_1.errorFeedback("setRemoteVideoSuperResolution");
        }
        return this.instance.setRemoteVideoSuperResolution(stream_key, mode);
    }
    /** {en}
     * @brief Take a snapshot of the local video.
     * @param stream_index Mainstream or screen-sharing stream.
     * @return The index of the local snapshot task, starting from `1`. You can get the snapshot from [onTakeLocalSnapshotResult](85533#ontakelocalsnapshotresult).
     * @notes + The snapshot is taken with all video effects on, like rotation, and mirroring.
     * + You can take the snapshot either using SDK internal video capture or customized capture.
     */
    /** {zh}
     * @brief 截取本地视频画面
     * @param stream_index 截图的视频流的属性，为主流还是屏幕流。
     * @return 本地截图任务的编号，从 `1` 开始递增。 调用成功后通过 [onTakeLocalSnapshotResult](85533#ontakelocalsnapshotresult) 回调快照文件。
     * @notes + 对截取的画面，包含本地视频处理的全部效果，包含旋转，镜像，美颜等。
     * + 不管采用 SDK 内部采集，还是自定义采集，都可以进行截图。
     */
    takeLocalSnapshot(stream_index) {
        if (utils_1.isNull(stream_index)) {
            return utils_1.errorFeedback("takeLocalSnapshot");
        }
        return this.instance.takeLocalSnapshot(stream_index);
    }
    /** {en}
     * @brief Take a snapshot of the remote video.
     * @param stream_key The remote stream you want to take a sanpshot from
     * @return The index of the local snapshot task, starting from `1`. You can get the snapshot from [onTakeLocalSnapshotResult](85533#ontakelocalsnapshotresult).
     * @notes + The snapshot is taken with all video effects on, like rotation, and mirroring.
     * + You can take the snapshot either using SDK internal video capture or customized capture.
     */
    /** {zh}
     * @brief 截取远端视频画面
     * @param stream_key 截图的视频流
     * @return 本地截图任务的编号，从 `1` 开始递增。 调用成功后通过 [onTakeLocalSnapshotResult](85533#ontakelocalsnapshotresult) 回调快照文件。
     * @notes + 对截取的画面，包含本地视频处理的全部效果，包含旋转，镜像，美颜等。
     * + 不管采用 SDK 内部采集，还是自定义采集，都可以进行截图。
     */
    takeRemoteSnapshot(stream_key) {
        if (utils_1.isNull(stream_key) ||
            utils_1.isNull(stream_key.room_id) ||
            utils_1.isNull(stream_key.user_id) ||
            utils_1.isNull(stream_key.stream_index)) {
            return utils_1.errorFeedback("takeRemoteSnapshot");
        }
        return this.instance.takeRemoteSnapshot(stream_key);
    }
    /** {zh}
     * @brief 通过 NTP 协议，获取网络时间。
     * @notes + 第一次调用此接口会启动网络时间同步功能，并返回 `0`。同步完成后，会收到 [onNetworkTimeSynchronized](85533#onnetworktimesynchronized)，此后，再次调用此 API，即可获取准确的网络时间。
     * + 在合唱场景下，合唱参与者应在相同的网络时间播放背景音乐。
     */
    /** {en}
     * @brief Obtain the synchronization network time information.
     * @notes + When you call this API for the first time, you starts synchornizing the network time information and receive the return value `0`. After the synchonization finishes, you will receive [onNetworkTimeSynchronized](85533#onnetworktimesynchronized). After that, calling this API will get you the correct network time.
     * + Under chorus scenario, participants shall start audio mixing at the same network time.
     */
    getNetworkTimeInfo() {
        return this.instance.getNetworkTimeInfo();
    }
    /** {en}
     * @brief Send audio stream synchronization information. The message is sent to the remote end through the audio stream and synchronized with the audio stream.
     * @param data Message content.
     * @param config Configuration related to audio stream synchronization information.
     * @return + `>= 0`: Message sent successfully. Returns the number of successful sends.
     * + `-1`: Message sending failed. Message length greater than 16 bytes.
     * + `-2`: Message sending failed. The content of the incoming message is empty.
     * + `-3`: Message sending failed. This screen stream was not published when the message was synchronized through the screen stream.
     * + `-4`: Message sending failed. This audio stream is not yet published when you synchronize messages with an audio stream captured by a microphone or custom device, as described in ErrorCode.
     * @notes + Regarding the frequency, we recommend no more than 50 calls per second.
     * + The data may be lost when the local user is muted.
     * + After the interface is successfully called, the remote user will receive a [onStreamSyncInfoReceived](85533#onstreamsyncinforeceived) callback.
     */
    /** {zh}
     * @brief 发送音频流同步信息。将消息通过音频流发送到远端，并实现与音频流同步。
     * @param data 消息内容。
     * @param config 音频流同步信息的相关配置。
     * @return + `>= 0`: 消息发送成功。返回成功发送的次数。
     * + `-1`: 消息发送失败。消息长度大于 255 字节。
     * + `-2`: 消息发送失败。传入的消息内容为空。
     * + `-3`: 消息发送失败。通过屏幕流进行消息同步时，此屏幕流还未发布。
     * + `-4`: 消息发送失败。通过用麦克风或自定义设备采集到的音频流进行消息同步时，此音频流还未发布，详见错误码 ErrorCode。
     * @notes + 调用本接口的频率建议不超过 50 次每秒。
     * + 如果本地用户未说话，此消息不一定会送达。
     * + 该接口调用成功后，远端用户会收到 [onStreamSyncInfoReceived](85533#onstreamsyncinforeceived) 回调。
     */
    sendStreamSyncInfo(data, config) {
        if (utils_1.isNull(config) ||
            utils_1.isNull(config.stream_index) ||
            utils_1.isNull(config.repeat_count) ||
            utils_1.isNull(config.stream_type) ||
            utils_1.isNull(data)) {
            return utils_1.errorFeedback("sendStreamSyncInfo");
        }
        return this.instance.sendStreamSyncInfo(data, config);
    }
    /** {en}
     * @brief  Start cloud proxy
     * @param cloud_proxies cloud proxy informarion list.
     * @notes + Call this API before joining the room.
     * + Start pre-call network detection after starting cloud proxy.
     * + After starting cloud proxy and connects the cloud proxy server successfully, receives [onCloudProxyConnected](85533#oncloudproxyconnected).
     * + To stop cloud proxy, call [stopCloudProxy](#stopcloudproxy).
     */
    /** {zh}
     * @brief 开启云代理
     * @param cloud_proxies 云代理服务器信息列表。
     * @notes + 在加入房间前调用此接口
     * + 在开启云代理后，进行通话前网络探测
     * + 开启云代理后，并成功链接云代理服务器后，会收到 [onCloudProxyConnected](85533#oncloudproxyconnected)。
     * + 要关闭云代理，调用 [stopCloudProxy](#stopcloudproxy)。
     */
    startCloudProxy(cloud_proxies = []) {
        return this.instance.startCloudProxy(cloud_proxies);
    }
    /** {en}
     * @brief Stop cloud proxy
     * @notes To start cloud proxy, call [startCloudProxy](#startcloudproxy).
     */
    /** {zh}
     * @brief 关闭云代理
     * @notes 要开启云代理，调用 [startCloudProxy](#startcloudproxy)。
     */
    stopCloudProxy() {
        return this.instance.stopCloudProxy();
    }
    /** {en}
     * @hidden
     * @brief Start publishing a public media stream.
     * @param public_stream_id ID of the public stream
     * @param param Properties of the public stream.
     *              A public stream can include a bundle of media streams and appears as the designated layout.
     * @return + 0: Success. And you will be informed by [`onPushPublicStreamResult`](85533#onpushpublicstreamresult).
     * + !0: Failure because of invalid parameter or empty parameters.
     * @notes + Users within the same `appID` can call [`startPlayPublicStream`](#startplaypublicstream) to subscribe to the public stream regardless the user has joined which room or has not joined any room.
     * + Call [`updatePublicStreamParam`](#updatepublicstreamparam) to update the properties of the public stream which is published by the same user. Calling this API with the same stream ID repeatedly by the same user can not update the existing public stream.
     * + If Users with different userID call this API with the same stream ID, the public stream will be updated with the parameters passed in the latest call.
     * + To publish multiple public streams, call this API with different stream ID respectively.
     * + To stop publishing the public stream, call [`stopPushPublicStream`](#stoppushpublicstream).
     * + Please contact ts to enable this function before using it.
     */
    /** {zh}
     * @brief 发布一路公共流。
     * @param public_stream_id 公共流 ID。
     * @param param 公共流参数。
     *              一路公共流可以包含多路房间内的媒体流，按照指定的布局方式进行聚合。
     *              如果指定的媒体流还未发布，则公共流将在指定流开始发布后实时更新。
     * @return + 0: 成功。同时将收到 [`onPushPublicStreamResult`](85533#onpushpublicstreamresult) 回调。
     * + !0: 失败。当参数不合法或参数为空，调用失败。
     * @notes + 用户可以指定房间内多个用户发布的媒体流合成一路公共流。使用同一 `appID` 的用户，可以调用 [`startPlayPublicStream`](#startplaypublicstream) 获取和播放指定的公共流。
     * + 同一用户使用同一公共流 ID 多次调用本接口无效。如果你希望更新公共流参数，调用 [`updatePublicStreamParam`](#updatepublicstreamparam) 接口。
     * + 不同用户使用同一公共流 ID 多次调用本接口时，RTC 将使用最后一次调用时传入的参数更新公共流。
     * + 使用不同的 ID 多次调用本接口可以发布多路公共流。
     * + 调用 [`stopPushPublicStream`](#stoppushpublicstream) 停止发布公共流。
     * + 关于公共流功能的介绍，详见[发布和订阅公共流](https://www.volcengine.com/docs/6348/108930)
     */
    startPushPublicStream(public_stream_id, param) {
        if (!public_stream_id || utils_1.isNull(param.room_id)) {
            return utils_1.errorFeedback("startPushPublicStream");
        }
        //默认参数
        const tempParam = {
            interpolation_mode: 0,
            room_id: "",
            background_image_uri: "",
            audio_param: {
                sample_rate: 48000,
                channel_num: 2,
                bitrate_kbps: 32,
            },
            video_param: {
                width: 360,
                height: 640,
                fps: 15,
                bitrate_kpbs: 60000,
            },
            layout_regions: [],
            layout_mode: 0,
            bg_color: "#000000",
        };
        const utralParam = {
            ...tempParam,
            ...param,
        };
        return this.instance.startPushPublicStream(public_stream_id, utralParam);
    }
    /** {en}
     * @hidden
     * @brief Stop the public stream published by the current user.
     * @param public_stream_id ID of the public stream
     *                  The public stream must be published by the current user.
     * @return + 0: Success
     * + !0: Failure
     * @notes Refer to [`startPushPublicStream`](#startpushpublicstream) for details about starting publishing a public stream.
     */
    /** {zh}
     * @brief 停止发布当前用户发布的公共流
     * @param public_stream_id 公共流 ID
     *                  指定的流必须为当前用户所发布。
     * @return + 0: 成功
     * + !0: 失败
     * @notes 关于发布公共流，查看 [`startPushPublicStream`](#startpushpublicstream)。
     */
    stopPushPublicStream(public_stream_id) {
        if (!public_stream_id) {
            return utils_1.errorFeedback("stopPushPublicStream");
        }
        return this.instance.stopPushPublicStream(public_stream_id);
    }
    /** {en}
     * @hidden
     * @brief Update the properties of the public stream published by the current user.
     * @param public_stream_id ID of the public stream
     *              The stream to be updated must be published by the current user.
     * @param param Properties of the public stream.
     * @return + 0: Success
     * + !0: Failure
     * @notes Refer to [`startPushPublicStream`](#startpushpublicstream) for details about starting publishing a public stream.
     */
    /** {zh}
     * @brief 更新公共流参数
     * @param public_stream_id 公共流 ID
     * @param param 公共流参数。
     *              指定的流必须为当前用户所发布的。
     * @return + 0: 成功
     * + !0: 失败
     * @notes 关于发布公共流，查看 [`startPushPublicStream`](#startpushpublicstream)。
     */
    updatePublicStreamParam(public_stream_id, param) {
        if (!public_stream_id || utils_1.isNull(param.room_id)) {
            return utils_1.errorFeedback("updatePublicStreamParam");
        }
        //默认参数
        const tempParam = {
            interpolation_mode: 0,
            room_id: "",
            background_image_uri: "",
            audio_param: {
                sample_rate: 48000,
                channel_num: 2,
                bitrate_kbps: 32,
            },
            video_param: {
                width: 640,
                height: 360,
                fps: 15,
                bitrate_kpbs: 60000,
            },
            layout_regions: [],
            layout_mode: 0,
            bg_color: "#000000",
        };
        return this.instance.updatePublicStreamParam(public_stream_id, {
            ...tempParam,
            ...param,
        });
    }
    /** {en}
     * @hidden
     * @brief Subscribe the public stream. A user can call this method to subscribe a public stream whether he/she has joined the room or not.
     * @param public_stream_id ID of the public stream. If the stream has not been published then, the local client will receive the public stream once it starts publishing.
     * @return
     * + 0: Success. You will also be informed by [`onPlayPublicStreamResult`](85533#onplaypublicstreamresult).
     * + !0: Failure because of invalid parameter or empty parameters.
     * @notes
     * + We recommend to bind a view for the public stream before calling this API to subscribe a public stream.
     *              - Internal renderer: By calling [`setupPublicStreamVideo`](#setuppublicstreamvideo)
     *              - Custom renderer: By calling [`setPublicStreamVideoSink`](#setpublicstreamvideosink)
     * + After calling this API, you will be informed once the first frame has been decoded successfully by [`onFirstPublicStreamVideoFrameDecoded`](85533#onfirstpublicstreamvideoframedecoded) and [`onFirstPublicStreamAudioFrame`](85533#onfirstpublicstreamaudioframe).
     * + If the public stream contains SEI information, you will be informed by [`onPublicStreamSEIMessageReceived`](85533#onpublicstreamseimessagereceived).
     * + Call [`stopPlayPublicStream`](#stopplaypublicstream) to cancel subscribing the public stream.
     */
    /** {zh}
     * @brief 订阅指定公共流。无论用户是否在房间内，都可以调用本接口获取和播放指定的公共流。
     * @param public_stream_id 公共流 ID，如果指定流暂未发布，则本地客户端将在其开始发布后接收到流数据。
     * @return + 0: 成功。同时将收到 [`onPlayPublicStreamResult`](85533#onplaypublicstreamresult) 回调。
     * + !0: 失败。当参数不合法或参数为空，调用失败。
     * @notes + 在调用本接口之前，建议先绑定渲染视图。
     *              - 调用 [`setupPublicStreamVideo`](#setuppublicstreamvideo) 绑定内部渲染视图：
     *              - 调用 [`setPublicStreamVideoSink`](#setpublicstreamvideosink) 绑定自定义渲染视图：
     * + 调用本接口后，可以通过 [`onFirstPublicStreamVideoFrameDecoded`](85533#onfirstpublicstreamvideoframedecoded) 和 [`onFirstPublicStreamAudioFrame`](85533#onfirstpublicstreamaudioframe) 回调公共流的视频和音频首帧解码情况。
     * + 调用本接口后，可以通过 [`onPublicStreamSEIMessageReceived`](85533#onpublicstreamseimessagereceived) 回调公共流中包含的 SEI 信息。
     * + 订阅公共流之后，可以通过调用 [`stopPlayPublicStream`](#stopplaypublicstream) 接口取消订阅公共流。
     */
    startPlayPublicStream(public_stream_id) {
        if (!public_stream_id) {
            return utils_1.errorFeedback("startPlayPublicStream");
        }
        return this.instance.startPlayPublicStream(public_stream_id);
    }
    /** {en}
     * @hidden
     * @brief Cancel subscribing the public stream.
     * @param public_stream_id public_stream_id ID of the public stream
     * @return
     * + 0: Success
     * + !0: Failure
     * @notes Call this method to cancel subscribing to the public stream by calling [`startPlayPublicStream`](#startplaypublicstream).
     */
    /** {zh}
     * @brief 取消订阅指定公共流
     * @param public_stream_id 公共流 ID
     * @return + 0：成功
     * + !0：失败
     * @notes 关于订阅公共流，查看 [`startPlayPublicStream`](#startplaypublicstream)。
     */
    stopPlayPublicStream(public_stream_id) {
        if (!public_stream_id) {
            return utils_1.errorFeedback("stopPlayPublicStream");
        }
        return this.instance.stopPlayPublicStream(public_stream_id);
    }
    /** {en}
     * @hidden
     * @brief Assign a internal render view to the public stream.
     * @param public_stream_id ID of the public stream
     * @param view Internal render view
     * @param renderOptions Options for rendering
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes + To set the view for the public stream, call this API as soon as you receive [onFirstPublicStreamVideoFrameDecoded](85533#onfirstpublicstreamvideoframedecoded).
     * + If you need to unbind the stream from the current view, call [`removePublicStreamVideo`](#removepublicstreamvideo).
     */
    /** {zh}
     * @brief 为公共流绑定本地视图
     * @param public_stream_id 公共流 ID
     * @param view 视图
     * @param renderOptions 渲染选项
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes + 监听到 [onFirstPublicStreamVideoFrameDecoded](85533#onfirstpublicstreamvideoframedecoded) 后，调用本 API 绑定公共流。
     * + 如果需要解除绑定，调用 [`removePublicStreamVideo`](#removepublicstreamvideo)。
     */
    setupPublicStreamVideo(public_stream_id, view, renderOptions = {
        render_mode: types_1.RenderMode.FIT,
        mirror: false,
    }) {
        let ret = -1;
        if (!public_stream_id || !view) {
            return utils_1.errorFeedback("setupPublicStreamVideo");
        }
        ret = this.setPublicStreamVideoSink(public_stream_id, types_1.PixelFormat.kI420);
        let streamRender = this.publicStreamViews.get(public_stream_id);
        if (streamRender) {
            streamRender.destroy();
        }
        streamRender = new yuv_render_1.YUVRender(view, renderOptions.render_mode, renderOptions.mirror);
        this.publicStreamViews.set(public_stream_id, streamRender);
        return ret;
    }
    /** {en}
     * @hidden
     * @brief Unbind the public stream from the view
     * @param public_stream_id ID of the public stream
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes Call this API after stopping receiving public stream.
     */
    /** {zh}
     * @brief 为公共流解绑本地视图
     * @param public_stream_id 公共流 ID
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes 停止接收公共流时解绑视图。
     */
    removePublicStreamVideo(public_stream_id) {
        let ret = -1;
        if (!public_stream_id) {
            return utils_1.errorFeedback("removePublicStreamVideo");
        }
        let streamRender = this.publicStreamViews.get(public_stream_id);
        if (streamRender) {
            streamRender.destroy();
            this.publicStreamViews.delete(public_stream_id);
        }
        ret = this.unsetPublicStreamVideoSink(public_stream_id);
        return ret;
    }
    /** {en}
     * @hidden
     * @brief Assign a custom renderer to the public stream
     * @param public_stream_id ID of the public stream
     * @param required_format Video frame encoding format that applys to custom rendering.
     * @return + 0: Success
     * + !0: Failure
     */
    /** {zh}
     * @brief 为指定公共流绑定自定义渲染器。
     * @param public_stream_id 公共流 ID
     * @param required_format 适用的视频帧编码格式
     * @return + 0：成功
     * + !0：失败
     * @notes 详见[自定义视频渲染](https://www.volcengine.com/docs/6348/81201)。
     */
    setPublicStreamVideoSink(public_stream_id, required_format) {
        if (!public_stream_id) {
            return utils_1.errorFeedback("setPublicStreamVideoSink");
        }
        let streamRender = this.publicStreamViews.get(public_stream_id);
        if (streamRender) {
            logger.warn("public stream video canvas existed, should not call setPublicStreamVideoSink!");
        }
        return this.instance.setPublicStreamVideoSink(public_stream_id, required_format);
    }
    /** {en}
     * @hidden
     * @brief Assign a custom renderer to the public stream
     * @param public_stream_id ID of the public stream
     * @return + 0: Success
     * + !0: Failure
     */
    /** {zh}
     * @brief 为指定公共解绑自定义渲染器。
     * @param public_stream_id 公共流 ID
     * @return + 0：成功
     * + !0：失败
     * @notes 详见[自定义视频渲染](https://www.volcengine.com/docs/6348/81201)。
     */
    unsetPublicStreamVideoSink(public_stream_id) {
        if (!public_stream_id) {
            return utils_1.errorFeedback("unsetPublicStreamVideoSink");
        }
        return this.instance.unsetPublicStreamVideoSink(public_stream_id);
    }
    ///屏幕共享API
    /** {en}
     * @brief When sharing the screen, start using RTC SDK internal collection method to collect screen audio
     * @param device_id ID of the virtual device. You need to pass the ID to the API only for Mac.
     * @returns + `0`: Success
     * + `!0`: Failure.
     * @notes + After collection, you also need to call [publishScreen](#publishscreen) to collect the screen audio Push to the far end.
     * + To turn off screen audio internal capture, call [stopScreenAudioCapture](#stopscreenaudiocapture).
     */
    /** {zh}
     * @region 屏幕共享
     * @brief 在屏幕共享时，开始使用 RTC SDK 内部采集方式，采集屏幕音频
     * @param device_id 设备 ID。Mac下需要传入虚拟的声卡id，windows 下不用传入
     * @return + `0`：成功
     * + `!0`：失败
     * @notes + 采集后，你还需要调用 [publishScreen](#publishscreen) 将采集到的屏幕音频推送到远端。
     * + 要关闭屏幕音频内部采集，调用 [stopScreenAudioCapture](#stopscreenaudiocapture)。
     */
    startScreenAudioCapture(device_id) {
        if (!device_id) {
            return this.instance.startScreenAudioCapture();
        }
        else {
            return this.instance.startMacScreenAudioCapture(device_id);
        }
    }
    /** {en}
     * @brief When sharing the screen, start using RTC SDK internal collection method to collect screen audio on Mac.
     * @param device_id ID of the virtual device. You need to pass the ID to the API only for Mac.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + After collection, you also need to call [publishScreen](#publishscreen) to collect the screen audio Push to the far end.
     * + To turn off screen audio internal capture, call [stopScreenVideoCapture](#stopscreenvideocapture).
     */
    /** {zh}
     * @brief 在屏幕共享时，开始使用 RTC SDK 内部采集方式，采集 Mac 屏幕音频
     * @param device_id 虚拟设备 ID
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 采集后，你还需要调用 [publishScreen](#publishscreen) 将采集到的屏幕音频推送到远端。
     * + 要关闭屏幕音频内部采集，调用 [stopScreenAudioCapture](#stopscreenaudiocapture)。
     * + mac下需要传入虚拟的声卡id，windows下不用传入
     */
    startMacScreenAudioCapture(device_id) {
        return this.instance.startMacScreenAudioCapture(device_id);
    }
    /** {en}
     * @brief  Capture screen video stream for sharing. Screen video stream includes: content displayed on the screen, in the application window, or in the virtual screen.
     * @param source_info Screen capture source information. Call [getScreenCaptureSourceList](#getscreencapturesourcelist) to get all the screen sources that can be shared.
     * @param capture_params Screen capture parameters
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + Displaying contents in virtual screens is only available on Windows.
     * + This API only starts screen capturing but does not publish the captured video. Call [publishScreen](#publishscreen) to publish the captured video.
     * + To turn off screen video capture, call stopScreenVideoCapture.
     * + Local users will receive [onVideoDeviceStateChanged](85533#onvideodevicestatechanged) on the state of screen capturing such as start, pause, resume, and error.
     * + After successfully calling this API, local users will receive [onFirstLocalVideoFrameCaptured](85533#onfirstlocalvideoframecaptured).
     * + Before calling this API, you can call [setVideoEncoderConfig](#setvideoencoderconfig) to set the frame rate and encoding resolution of the screen video stream.
     * + After receiving [onFirstLocalVideoFrameCaptured](85533#onfirstlocalvideoframecaptured), you can set the local screen sharing view by calling [setupLocalScreen](#setuplocalscreen).
     * + Get local screen video frames from [`onLocalScreenFrame`](85533#onlocalscreenframe).
     */
    /** {zh}
     * @region 屏幕共享
     * @brief 采集屏幕视频流，用于共享。屏幕视频流包括：屏幕上显示的内容，应用窗口中显示的内容，或虚拟屏幕中显示的内容。其中，虚拟屏幕中显示的内容仅在 Windows 平台上支持。
     * @param source_info 待共享的屏幕源，你可以调用 [getScreenCaptureSourceList](#getscreencapturesourcelist) 获得所有可以共享的屏幕源。
     * @param capture_params 共享参数
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 调用此方法仅开启屏幕流视频采集，不会发布采集到的视频。发布屏幕流视频需要调用 [publishScreen](#publishscreen) 。
     * + 要关闭屏幕视频源采集，调用 [stopScreenVideoCapture](#stopscreenvideocapture)。
     * + 本地用户通过 [onVideoDeviceStateChanged](85533#onvideodevicestatechanged) 的回调获取屏幕采集状态，包括开始、暂停、恢复、错误等。
     * + 调用成功后，本端会收到 [onFirstLocalVideoFrameCaptured](85533#onfirstlocalvideoframecaptured) 回调。然后通过调用 [setupLocalScreen](#setuplocalscreen) 设置本地屏幕共享视图。
     * + 调用此接口前，你可以调用 [setVideoEncoderConfig](#setvideoencoderconfig) 设置屏幕视频流的采集帧率和编码分辨率。
     * + 监听 [`onLocalScreenFrame`](85533#onlocalscreenframe) 本地屏幕视频回调事件。
     */
    startScreenVideoCapture(source_info, capture_params) {
        let newInfo = { ...source_info };
        const defaultInfo = {
            type: types_1.ScreenCaptureSourceType.kScreenCaptureSourceTypeUnknown,
            source_id: 0,
            source_name: "",
            application: "",
            pid: 0,
            primaryMonitor: false,
            region_rect: {
                x: 0,
                y: 0,
                width: 0,
                height: 0,
            },
        };
        if (!newInfo.source_name) {
            newInfo.source_name = "";
        }
        const defaultParams = {
            region_rect: { x: 0, y: 0, width: 0, height: 0 },
            capture_mouse_cursor: types_1.MouseCursorCaptureState.kMouseCursorCaptureStateOn,
            filter_config: [],
            highlight_config: {
                enable_highlight: true,
                border_color: 0xff29cca3,
                border_width: 4,
            },
        };
        if (os_1.default.platform() === "darwin") {
            // const os_version = execSync("sw_vers -ProductVersion", {
            //   encoding: "utf8",
            // }).trim();
            const os_version = utils_1.getMacVersion();
            //highlight border is  not available to mac_os_version of  10.10、10.11、10、12
            const reg = /^10\.1[0-2]/;
            if (reg.test(os_version)) {
                capture_params.highlight_config = {
                    enable_highlight: false,
                    border_color: 0xff29cca3,
                    border_width: 4,
                };
            }
        }
        return this.instance.startScreenVideoCapture({ ...defaultInfo, ...source_info }, {
            ...defaultParams,
            ...(capture_params || {}),
        });
    }
    /** {en}
     * @brief Stop recording device audio.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes To start the device audio recording, call [startScreenAudioCapture](#startscreenaudiocapture).
     */
    /** {zh}
     * @region 屏幕共享
     * @brief 在屏幕共享时，停止使用 RTC SDK 内部采集方式，采集屏幕音频。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 要开始屏幕音频内部采集，调用 [startScreenAudioCapture](#startscreenaudiocapture)。
     */
    stopScreenAudioCapture() {
        return this.instance.stopScreenAudioCapture();
    }
    /** {en}
     * @brief Stop screen video streaming.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + To turn on screen video stream capture, calling [startScreenVideoCapture](#startscreenvideocapture)
     * + Local users will receive the [onVideoDeviceStateChanged](85533#onvideodevicestatechanged) callback.
     * + Calling this interface does not affect screen video stream publishing.
     */
    /** {zh}
     * @region 屏幕共享
     * @brief 停止屏幕视频流采集。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 要开始屏幕音频内部采集，调用 [startScreenAudioCapture](#startscreenaudiocapture)。
     * + 调用后，本地用户会收到 [onVideoDeviceStateChanged](85533#onvideodevicestatechanged) 的回调。
     * + 调用此接口不影响屏幕视频流发布。
     */
    stopScreenVideoCapture() {
        return this.instance.stopScreenVideoCapture();
    }
    /** {en}
     * @brief Update the capture area when capturing screen video streams through the capture module provided by the RTC SDK.
     * @param region_rect Region to be shared. This parameter describes the acquisition area after calling this interface, and the relative relationship between the 'source_info' setting area in [startScreenVideoCapture](#startscreenvideocapture).
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Before calling this interface, internal screen stream capture must have been turned on by calling [startScreenVideoCapture](#startscreenvideocapture).
     */
    /** {zh}
     * @region 屏幕共享
     * @brief 更新屏幕共享区域。
     * @param region_rect <li>当共享屏幕时，指定待共享区域相对于虚拟屏幕的位置</li><li>当共享窗口时，指定待共享区域相对于整个窗口的位置</li>
     * 此参数描述了调用此接口后的采集区域，和 [startScreenVideoCapture](#startscreenvideocapture) 中 `source_info` 设定区域的相对关系。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 调用此接口前，必须已通过调用 [startScreenVideoCapture](#startscreenvideocapture) 开启了内部屏幕流采集。
     */
    updateScreenCaptureRegion(region_rect = { x: 0, y: 0, width: 0, height: 0 }) {
        if (utils_1.isNull(region_rect)) {
            return utils_1.errorFeedback("updateScreenCaptureRegion");
        }
        return this.instance.updateScreenCaptureRegion(region_rect);
    }
    /** {en}
     * @brief Update border highlighting settings when capturing screen video streams through the capture module provided by the RTC SDK. The default display table box.
     * @param highlight_config Border highlighting settings.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Before calling this interface, you must have turned on internal screen flow collection by calling [startScreenVideoCapture](#startscreenvideocapture).
     */
    /** {zh}
     * @region 屏幕共享
     * @brief 通过 RTC SDK 提供的采集模块采集屏幕视频流时，更新边框高亮设置。默认展示表框。
     * @param highlight_config 边框高亮设置
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 调用此接口前，必须已通过调用 [startScreenVideoCapture](#startscreenvideocapture) 开启了内部屏幕流采集。
     */
    updateScreenCaptureHighlightConfig(highlight_config = {
        enable_highlight: true,
        border_color: 0xff29cca3,
        border_width: 4,
    }) {
        if (utils_1.isNull(highlight_config)) {
            return utils_1.errorFeedback("updateScreenCaptureHighlightConfig");
        }
        return this.instance.updateScreenCaptureHighlightConfig(highlight_config);
    }
    /** {en}
     * @brief Update the processing settings for the mouse when capturing screen video streams through the capture module provided by the RTC SDK. Default acquisition mouse.
     * @param state
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Before calling this interface, internal screen stream capture must have been turned on by calling [startScreenVideoCapture](#startscreenvideocapture).
     */
    /** {zh}
     * @region 屏幕共享
     * @brief 通过 RTC SDK 提供的采集模块采集屏幕视频流时，更新对鼠标的处理设置。默认采集鼠标。
     * @param capture_mouse_cursor 内部采集屏幕视频流时，是否采集鼠标信息
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 调用此接口前，必须已通过调用 [startScreenVideoCapture](#startscreenvideocapture) 开启了内部屏幕流采集。
     */
    updateScreenCaptureMouseCursor(capture_mouse_cursor = types_1.MouseCursorCaptureState.kMouseCursorCaptureStateOn) {
        if (utils_1.isNull(capture_mouse_cursor)) {
            return utils_1.errorFeedback("updateScreenCaptureMouseCursor");
        }
        return this.instance.updateScreenCaptureMouseCursor(capture_mouse_cursor);
    }
    /** {en}
     * @brief When capturing screen video streams through the capture module provided by the RTC SDK, set the window that needs to be filtered.
     * @param filter_config Window filtering settings
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + Before calling this interface, internal screen stream capture must have been turned on by calling [startScreenVideoCapture](#startscreenvideocapture).
     * + This function only works when the screen source category is a screen rather than an application form.
     */
    /** {zh}
     * @region 屏幕共享
     * @brief 通过 RTC SDK 提供的采集模块采集屏幕视频流时，设置需要过滤的窗口。
     * @param filter_config 窗口过滤设置
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 调用此接口前，必须已通过调用 [startScreenVideoCapture](#startscreenvideocapture) 开启了内部屏幕流采集。
     * + 本函数在屏幕源类别是屏幕而非应用窗体时才起作用。
     */
    updateScreenCaptureFilterConfig(filter_config = []) {
        if (utils_1.isNull(filter_config)) {
            return utils_1.errorFeedback("updateScreenCaptureFilterConfig");
        }
        return this.instance.updateScreenCaptureFilterConfig(filter_config);
    }
    /** {en}
     * @brief Set the audio channel of the screen-sharing audio stream
     * @param channel The number of Audio channels.
     * @notes When you call [setScreenAudioStreamIndex](#setscreenaudiostreamindex) to mix the microphone audio stream and the screen-sharing audio stream, the audio channel is set by [setAudioProfile](#setaudioprofile) rather than this API.
     */
    /** {zh}
     * @brief 在屏幕共享时，设置屏幕音频流的声道数
     * @param channel 声道数
     * @notes 当你调用 [setScreenAudioStreamIndex](#setscreenaudiostreamindex) 并设置屏幕音频流和麦克风音频流混流时，此接口不生效，音频通道数由 [setAudioProfile](#setaudioprofile) 控制。
     */
    setScreenAudioChannel(channel) {
        if (utils_1.isNull(channel)) {
            return utils_1.errorFeedback("setScreenAudioChannel");
        }
        return this.instance.setScreenAudioChannel(channel);
    }
    /** {en}
     * @brief Get the item list for screen sharing.
     * @returns List of the screen-sharing objects, including application window and screens. After the user has decided which item to be shared, pass the object to RTC as an argument of [startScreenVideoCapture](#startscreenvideocapture).
     * @notes Whether to include the minimized windows is different based on platforms:
     * + The minimized windows are included in the return value for Windows;
     * + The minimized windows are not included in the return value for macOS or Linux.
     */
    /** {zh}
     * @brief 获取屏幕采集对象列表。
     * @return 屏幕采集对象列表，包括应用窗口和屏幕。由用户选择其中一个共享对象，并在调用 [startScreenVideoCapture](#startscreenvideocapture) 时作为参数传给 RTC SDK。
     * @notes 不同的平台上，对最小化的窗口的处理方式不同：在 Windows 平台上，最小化的窗口也会包含在返回列表中；在 macOS 和 Linux 平台上，最小化的窗口不会包含在返回列表中。
     */
    getScreenCaptureSourceList() {
        return this.instance.getScreenCaptureSourceList();
    }
    // share screen
    /** {en}
     * @brief Get the preview thumbnail of the screen-sharing object
     * @param type Type of the screen capture object
     * @param source_id ID of the screen-shared object
     * @param max_width Maximum width of the preview thumbnail
     * @param max_height Maximum height of the preview thumbnail
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @brief 获取共享对象缩略图
     * @region 屏幕共享
     * @param type 屏幕采集对象的类型
     * @param source_id 屏幕共享对象的 ID，可通过 [getScreenCaptureSourceList](#getscreencapturesourcelist) 枚举共享对象列表中获取。
     * @param max_width 最大宽度。保持采集对象本身的宽高比不变，将缩略图缩放到指定范围内的最大宽高。如果给出的尺寸与共享对象比例不同，得到的缩略图会有黑边。
     * @param max_height 最大高度。参见 `maxWidth` 的说明。
     * @return 共享对象缩略图
     */
    getThumbnail(type, source_id, max_width, max_height) {
        let obj = this.instance.getThumbnail(type, source_id, max_width, max_height);
        if (obj.data) {
            obj.data = "data:image/png;base64," + obj.data;
        }
        return obj;
    }
    /** {en}
     * @brief Get application window preview thumbnail for screen sharing.
     * @param source_id ID of the screen-sharing object. You can get the ID by calling [getScreenCaptureSourceList](#getscreencapturesourcelist).
     * @param max_width Maximum width of the App icon. The width is always equal to the height. SDK will set the height and width to the smaller value if the given values are unequal. RTC will return nullptr if you set the value with a number out of the valid range, [32, 256]. The default size is 100 x 100.
     * @param max_height Maximum height of the app icon. Refer to the note for  `max_width`
     * @return You can get the icon when the item to be shared is an application and the application is assigned with an icon. If not, the return value will be nullptr.
     */
    /** {zh}
     * @brief 获取应用窗体所属应用的图标。
     * @region 屏幕共享
     * @param source_id 屏幕共享对象的 ID，可通过 [getScreenCaptureSourceList](#getscreencapturesourcelist) 枚举共享对象列表中获取。
     * @param max_width 最大宽度。返回的图标将是宽高相等的，输入宽高不等时，取二者较小值。宽高范围为 [32,256]，超出该范围将返回 nullptr，默认输出 100 x 100 的图像。
     * @param max_height 最大高度。参见 `maxWidth` 的说明。
     * @return 应用窗体所属应用的图标。当屏幕共享对象为应用窗体时有效，否则返回 nullptr。
     */
    getWindowAppIcon(source_id, max_width, max_height) {
        let obj = this.instance.getWindowAppIcon(source_id, max_width, max_height);
        if (obj.data) {
            obj.data = "data:image/png;base64," + obj.data;
        }
        return obj;
    }
    /** {en}
     * @brief Set the mixing mode of the screen audio stream and the audio stream collected by the microphone when the screen is shared
     * @param index The mixing mode.
     * + 'kStreamIndexMain': Mix the audio stream collected by the screen audio stream and the microphone
     * + 'KStreamIndexScreen ': By default, it divides  the screen audio stream and the audio stream collected by the microphone into two audio streams
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes You should call this method before [publishScreen](#publishscreen). Otherwise, you will receive an error from [onWarning](85533#onwarning) : `kWarningCodeSetScreenAudioStreamIndexFailed`
     */
    /** {zh}
     * @brief 在屏幕共享时，设置屏幕音频流和麦克风采集到的音频流的混流方式
     * @param index 混流方式 <li> `0`: 将屏幕音频流和麦克风采集到的音频流混流 </li><li> `1`: 将屏幕音频流和麦克风采集到的音频流分为两路音频流</li>
     * @return + 0：成功
     * + !0：失败
     * @notes 你应该在 [publishScreen](#publishscreen) 之前，调用此方法。否则，你将收到 [onWarning](85533#onwarning) 的报错：kWarningCodeSetScreenAudioStreamIndexFailed`
     */
    setScreenAudioStreamIndex(index) {
        return this.instance.setScreenAudioStreamIndex(index);
    }
    /** {en}
     * @brief Video publisher call this API to set the expected configurations for the screen sharing video stream, including resolution, frame rate, bitrate, and fallback strategy in poor network conditions.
     * @param screen_solution You expected configurations for screen sharing video stream.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Without calling this API, the default encoding parameters for screen sharing video streams are: resolution 1920px × 1080px, frame rate 15fps.
     */
    /** {zh}
     * @brief 为发布的屏幕共享视频流设置期望的编码参数，包括分辨率、帧率、码率、网络不佳时的回退策略等。
     * @param screen_solution 屏幕共享视频流参数。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 调用该方法之前，屏幕共享视频流默认的编码参数为：分辨率 1920px × 1080px，帧率 15fps。
     */
    setScreenVideoEncoderConfig(screen_solution) {
        if (utils_1.isNull(screen_solution) ||
            utils_1.isNull(screen_solution.width) ||
            utils_1.isNull(screen_solution.height) ||
            utils_1.isNull(screen_solution.frameRate)) {
            return utils_1.errorFeedback("setScreenVideoEncoderConfig");
        }
        //Default
        const tempSolution = {
            frameRate: 0,
            height: 0,
            width: 0,
            maxBitrate: -1,
            minBitrate: 0,
            encoderPreference: types_1.ScreenVideoEncodePreference.kScreenVideoEncodePreferenceQuality,
        };
        return this.instance.setScreenVideoEncoderConfig({
            ...tempSolution,
            ...screen_solution,
        });
    }
    ///RTS
    /** {en}
     * @brief Log in to send P2P messages or send messages to a server without joining the RTC room.
     * @param token Token is required during login for authentication.
     *        This Token is different from that required by calling joinRoom. You can assign any value even null to `roomId` to generate a login token. During developing and testing, you can use temporary tokens generated on the console. Deploy the token generating application on your server.
     * @param uid User ID which is unique within one appid.
     * @returns + `0`: Success
     * + `-1`: Failure due to invalid parameter
     * + `-2`: Invalid call. RTC will return this value when you call this API after the user has been logged in to the server.
     * @notes + To log out, call [Logout](#logout).
     * + You will receive [onLoginResult](85533#onloginresult) after calling this API and log in successfully. But remote users will not receive notification about that.
     */
    /** {zh}
     * @region 实时消息通信
     * @brief 必须先登录，才能发送房间外点对点消息和向应用服务器发送消息
     * @param token 动态密钥。  用户登录必须携带的 Token，用于鉴权验证。  本 Token 与加入房间时必须携带的 Token 不同。测试时可使用控制台生成临时 Token，正式上线需要使用密钥 SDK 在你的服务端生成并下发 Token。
     * @param uid 用户 ID  用户 ID 在 appid 的维度下是唯一的。
     * @return + `0`：成功
     * + `-1`：失败。无效参数
     * + `-2`：无效调用。用户已经登录。成功登录后再次调用本接口将收到此返回值
     * @notes + 在调用本接口登录后，如果想要登出，需要调用 [Logout](#logout)。
     * + 本地用户调用此方法登录后，会收到 [onLoginResult](85533#onloginresult) 回调通知登录结果，远端用户不会收到通知。
     */
    login(token, uid) {
        if (utils_1.isNull(token) || utils_1.isNull(uid)) {
            return utils_1.errorFeedback("login");
        }
        return this.instance.login(token, uid);
    }
    /** {en}
     * @brief  Calls this interface to log out, it is impossible to call methods related to out-of-room messages and end-to-server messages or receive related callbacks.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + Before calling this interface to log out, you must call [login](85532#login) to log in.
     * + After local users call this method to log out, they will receive the result of the [onLogout](85533#onlogout) callback notification, and remote users will not receive the notification.
     */
    /** {zh}
     * @region 实时消息通信
     * @brief 调用本接口登出后，无法调用房间外消息以及端到服务器消息相关的方法或收到相关回调。
     * @return + 0: 方法调用成功
     * + <0: 方法调用失败
     * @notes + 调用本接口登出前，必须先调用 [login](85532#login) 登录。
     * + 本地用户调用此方法登出后，会收到 [onLogout](85533#onlogout) 回调通知结果，远端用户不会收到通知。
     */
    logout() {
        return this.instance.logout();
    }
    /** {en}
     * @brief Update the Token
     * @param token Token used by the user to log in has a certain valid period. When the Token expires, you need to call this method to update the login Token information.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + When calling the [login](#login) method to log in, if an expired token is used, the login will fail and you will receive an [onLoginResult](85533#onloginresult) notification with an error code of kLoginErrorCodeInvalidToken. You need to reacquire the token and call this method to update the token.
     * + If the token is invalid and the login fails, call this method. After updating the token, the SDK will automatically log back in, and the user does not need to call the [login](#login) method.
     * + Token expires, if you have successfully logged in, it will not be affected. An expired Token error will be notified to the user the next time you log in with an expired Token, or when you log in again due to a disconnection due to poor local network conditions.
     */
    /** {zh}
     * @region 实时消息通信
     * @brief 更新用户用于登录的 Token。
     * @param token Token 有一定的有效期，当 Token 过期时，需调用此方法更新登录的 Token 信息。
     * @return + 0: 方法调用成功
     * + <0: 方法调用失败
     * @notes + 调用 [login](85532#login) 方法登录时，如果使用了过期的 Token 将导致登录失败，并会收到 [onLoginResult](85533#onloginresult) 回调通知，错误码为 kLoginErrorCodeInvalidToken。此时需要重新获取 Token，并调用此方法更新 Token。
     * + 如果 Token 无效导致登录失败，则调用此方法更新 Token 后，SDK 会自动重新登录，而用户不需要自己调用 [login](85532#login) 方法。
     * + Token 过期时，如果已经成功登录，则不会受到影响。Token 过期的错误会在下一次使用过期 Token 登录时，或因本地网络状况不佳导致断网重新登录时通知给用户。
     */
    updateLoginToken(token) {
        if (utils_1.isNull(token)) {
            return utils_1.errorFeedback("updateLoginToken");
        }
        return this.instance.updateLoginToken(token);
    }
    /** {en}
     * @brief Set application server parameters
     * @param signature Dynamic signature. The service server uses this signature to authenticate the request.
     * @param url The address of the application server
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + Client side calls [sendServerMessage](#sendservermessage) or [sendServerBinaryMessage](#sendserverbinarymessage) Before sending a message to the application server, a valid signature and application server address must be set.
     * + The user must call [login](#login) to log in before calling this interface.
     * + After calling this interface, the SDK will use [onServerParamsSetResult](85533#onserverparamssetresult) to return the corresponding result.
     */
    /** {zh}
     * @region 实时消息通信
     * @brief 设置业务服务器参数。
     * @param signature 动态签名  业务服务器会使用该签名对请求进行鉴权验证。
     * @param url 业务服务器的地址
     * @return + 0: 方法调用成功
     * + <0: 方法调用失败
     * @notes + 客户端调用 [sendServerMessage](#sendservermessage) 或 [sendServerBinaryMessage](#sendserverbinarymessage) 发送消息给业务服务器之前，必须设置有效签名和业务服务器地址。
     * + 用户必须调用 [login](85532#login) 登录后，才能调用本接口。
     * + 调用本接口后，SDK 会使用 [onServerParamsSetResult](85533#onserverparamssetresult) 返回相应结果。
     */
    setServerParams(signature, url) {
        if (utils_1.isNull(signature) || utils_1.isNull(url)) {
            return utils_1.errorFeedback("setServerParams");
        }
        return this.instance.setServerParams(signature, url);
    }
    /** {en}
     * @brief Query the login status of the opposite or local user
     * @param peer_user_id User ID to be queried
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes * + [login](#login) must be called before this interface can be called.
     * + After calling this interface, the SDK notifies the query result using the [onGetPeerOnlineStatus](85533#ongetpeeronlinestatus) callback.
     * + Before sending an out-of-room message, the user can know whether the peer user is logged in through this interface to decide whether to send a message. You can also check your login status through this interface.
     */
    /** {zh}
     * @region 实时消息通信
     * @brief 查询对端用户或本端用户的登录状态
     * @param peer_user_id 需要查询的用户 ID
     * @return + 0: 方法调用成功
     * + <0: 方法调用失败
     * @notes + 必须调用 [login](85532#login) 登录后，才能调用本接口。
     * + 调用本接口后，SDK 会使用 [onGetPeerOnlineStatus](85533#ongetpeeronlinestatus) 回调通知查询结果。
     * + 在发送房间外消息之前，用户可以通过本接口了解对端用户是否登录，从而决定是否发送消息。也可以通过本接口查询自己查看自己的登录状态。
     */
    getPeerOnlineStatus(peer_user_id) {
        if (!peer_user_id) {
            return utils_1.errorFeedback("getPeerOnlineStatus");
        }
        return this.instance.getPeerOnlineStatus(peer_user_id);
    }
    /** {en}
     * @brief Send a text message (P2P) to a specified user outside the room
     * @param uid Message receiving user's ID
     * @param message Text message content sent. Message does not exceed 64 KB.
     * @param config Message type
     * @returns + > 0: Sent successfully, return the number of the sent message, increment from 1
     * + -1: Sent failed, IRTCVideo instance not created
     * + -2: Sent failed, uid is empty
     * @notes + You must call [login](#login) to complete the login before you can send a message in a foreign text of the room.
     * + After the user calls this interface to send a text message, he will receive an [onUserMessageSendResultOutsideRoom](85533#onusermessagesendresultoutsideroom) callback to know whether the message was successfully sent.
     * + If the text message is sent successfully, the user specified by uid receives the message via the [onUserMessageReceivedOutsideRoom](85533#onusermessagereceivedoutsideroom) callback.
     */
    /** {zh}
     * @region 实时消息通信
     * @brief 给房间外指定的用户发送文本消息（P2P）
     * @param uid 消息接收用户的 ID
     * @param message 发送的文本消息内容，消息不超过 64 KB。
     * @param config 消息类型
     * @return
     * + `>0`：发送成功，返回这次发送消息的编号，从 1 开始递增
     * + `-1`：发送失败，RtcEngine 实例未创建
     * + `-2`：发送失败，uid 为空
     * @notes + 在发送房间外文本消息前，必须先调用 [login](85532#login) 完成登录。
     * + 用户调用本接口发送文本信息后，会收到一次 [onUserMessageSendResultOutsideRoom](85533#onusermessagesendresultoutsideroom) 回调，得知消息是否成功发送。
     * + 若文本消息发送成功，则 uid 所指定的用户会通过 [onUserMessageReceivedOutsideRoom](85533#onusermessagereceivedoutsideroom) 回调收到该消息。
     */
    sendUserMessageOutsideRoom(uid, message, config) {
        if (utils_1.isNull(uid) || utils_1.isNull(message)) {
            return utils_1.errorFeedback("sendUserMessageOutsideRoom");
        }
        return this.instance.sendUserMessageOutsideRoom(uid, message, config);
    }
    /** {en}
     * @brief Send binary messages (P2P) to a specified user outside the room
     * @param uid ID of the user receiving the message
     * @param length Length of the binary string
     * @param message Content of the binary message sent. Message does not exceed 64 KB.
     * @param config Message type
     * @returns + > 0: sent successfully, return the number of the sent message, increment from 1
     * + -1: Sent failed, IRTCVideo instance not created
     * + -2: Sent failed, uid is empty
     * @notes + [login](#login) must be called before sending out-of-room binary messages.
     * + After the user calls this interface to send a binary message, he will receive an [onUserMessageSendResultOutsideRoom](85533#onusermessagesendresultoutsideroom) callback to notify whether the message was sent successfully.
     * + If the binary message is sent successfully, the user specified by uid will receive the message through the [onUserMessageReceivedOutsideRoom](85533#onusermessagereceivedoutsideroom) callback.
     */
    /** {zh}
     * @brief 给房间外指定的用户发送二进制消息（P2P）
     * @param uid 消息接收用户的 ID
     * @param length 二进制字符串的长度
     * @param message 发送的二进制消息内容，每条消息不超过 64 KB。
     * @param config 消息类型
     * @return
     * + `>0`：发送成功，返回这次发送消息的编号，从 1 开始递增
     * + `-1`：发送失败，RtcEngine 实例未创建
     * + `-2`：发送失败，uid 为空
     * @notes + 在发送房间外二进制消息前，必须先调用 [login](85532#login) 完成登录。
     * + 用户调用本接口发送二进制消息后，会收到一次 [onUserMessageSendResultOutsideRoom](85533#onusermessagesendresultoutsideroom) 回调，通知消息是否发送成功。
     * + 若二进制消息发送成功，则 uid 所指定的用户会通过 [onUserMessageReceivedOutsideRoom](85533#onusermessagereceivedoutsideroom) 回调收到该条消息。
     */
    sendUserBinaryMessageOutsideRoom(uid, length, message, config) {
        if (utils_1.isNull(uid) || utils_1.isNull(length) || utils_1.isNull(message)) {
            return utils_1.errorFeedback("sendUserBinaryMessageOutsideRoom");
        }
        return this.instance.sendUserBinaryMessageOutsideRoom(uid, length, message, config);
    }
    /** {en}
     * @brief The client side sends a text message to the application server (P2Server)
     * @param message The content of the text message sent. The message does not exceed 64 KB.
     * @returns + > 0: Sent successfully, return the number of the sent message, increment from 1
     * + -1: Sent failed, IRTCVideo instance not created
     * @notes * + Before sending a text message to the application server, you must first call [login](#login) to complete the login, and then call [setServerParams](85532#setserverparams)) Set up the application server.
     * + After calling this interface, you will receive an [onServerMessageSendResult](85533#onservermessagesendresult) callback to inform the message sender whether the message was sent successfully.
     * + If the text message is sent successfully, the application server that previously called [setServerParams](85532#setserverparams) will receive the message.
     */
    /** {zh}
     * @region 实时消息通信
     * @brief 客户端给业务服务器发送文本消息（P2Server）
     * @param message 发送的文本消息内容，消息不超过 64 KB。
     * @return
     * + `>0`：发送成功，返回这次发送消息的编号，从 1 开始递增
     * + `-1`：发送失败，Video 实例未创建
     * @notes + 在向业务服务器发送文本消息前，必须先调用 [login](85532#login) 完成登录，随后调用 [setServerParams](85532#setserverparams) 设置业务服务器。
     * + 调用本接口后，会收到一次 [onServerMessageSendResult](85533#onservermessagesendresult) 回调，通知消息发送方是否发送成功。
     * + 若文本消息发送成功，则之前调用 [setServerParams](85532#setserverparams) 设置的业务服务器会收到该条消息。
     */
    sendServerMessage(message) {
        if (utils_1.isNull(message)) {
            return utils_1.errorFeedback("sendServerMessage");
        }
        return this.instance.sendServerMessage(message);
    }
    /** {en}
     * @brief Client side sends binary messages to the application server (P2Server)
     * @param length Length of binary string
     * @param message Binary message content sent
     *        Message does not exceed 46KB.
     * @returns + > 0: Sent successfully, return the number of the sent message, increment from 1
     * + -1: Sent failed, IRTCVideo instance not created
     * @notes
     * + Before sending a binary message to the application server, you must first call [login](#login) to complete the login, and then call [setServerParams](85532#setserverparams) Set up the application server.
     * + After calling this interface, you will receive an [onServerMessageSendResult](85533#onservermessagesendresult) callback to inform the message sender that the sending succeeded or failed.
     * + If the binary message is sent successfully, the application server that previously called [setServerParams](85532#setserverparams) will receive the message.
     */
    /** {zh}
     * @region 实时消息通信
     * @brief 客户端给业务服务器发送二进制消息（P2Server）
     * @param length 二进制字符串的长度
     * @param message 发送的二进制消息内容，消息不超过 46KB。
     * @return
     * + `>0`：发送成功，返回这次发送消息的编号，从 1 开始递增
     * + `-1`：发送失败，RtcEngine 实例未创建
     * @notes + 在向业务服务器发送二进制消息前，必须先调用 [login](85532#login) 完成登录，随后调用 [setServerParams](85532#setserverparams) 设置业务服务器。
     * + 调用本接口后，会收到一次 [onServerMessageSendResult](85533#onservermessagesendresult) 回调，通知消息发送方发送成功或失败。
     * + 若二进制消息发送成功，则之前调用 [setServerParams](85532#setserverparams) 设置的业务服务器会收到该条消息。
     */
    sendServerBinaryMessage(length, message) {
        if (utils_1.isNull(length) || utils_1.isNull(message)) {
            return utils_1.errorFeedback("sendServerBinaryMessage");
        }
        return this.instance.sendServerBinaryMessage(length, message);
    }
    /** {en}
     * @brief Sends SEI data.
     * @param stream_index Specifys the type of media stream that carries SEI data.
     *        In a voice call, you should set this parameter to `kStreamIndexMain`, otherwise the SEI data is discarded and cannot be sent to the remote user.
     * @param message SEI data.  The message would be discarded if it exceeds 4 KB.
     * @param repeat_count Number of times a message is sent repeatedly. The value range is [0, max{29, %{video frame rate}-1}]. Recommended range: [2,4].
     *                    This value specifies how many consecutive video frames, starting with the current video frame, the SEI data will be added to after calling this API.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + We recommend the number of SEI messages per second should not exceed the current video frame rate. Because each SEI is sent with a video frame. While in a voice call, SDK will automatically publish a blank video stream with a resolution of 16px × 16px at a frame rate of 15 fps to carry SEI data.
     * + In a voice call scenario, this API can be called to send SEI data only in internal capture mode and with a frequency of 15/repeat_count FPS.
     * + Each video frame carrys only the SEI data received within 2s before and after. In a voice call scenario, if no SEI data is sent within 1min after calling this API, SDK will automatically cancel publishing black frames.
     * + After the message is sent successfully, the remote user who subscribed your video stream will receive [onSEIMessageReceived](85533#onseimessagereceived).
     * + When you switch from a voice call to a video call, SEI data transmission will stop and you will need to call this API again to resume the transmission.
     */
    /** {zh}
     * @region 视频管理
     * @brief 通过视频帧发送 SEI 数据。
     * @param stream_index 媒体流类型<li>主流。包括：由摄像头/麦克风通过内部采集机制，采集到的视频/音频。</li><li>屏幕流。屏幕共享时共享的视频流，或来自声卡的本地播放音频流。</li>
     * @param message SEI 消息。超过 4KB 的消息会被丢弃。
     * @param repeat_count 消息发送重复次数。取值范围是 [0, max{29, %{视频帧率}-1}]。推荐范围 [2,4]。
     *                     调用此接口后，这些 SEI 数据会添加到从当前视频帧开始的连续 `%{repeat_count}` 个视频帧中。
     * @return
     * + \>=0: 将被添加到视频帧中的 SEI 的数量
     * + < 0: 发送失败
     * @notes + SEI 数据会随视频帧发送。每秒发送的 SEI 消息数量建议不超过当前的视频帧率。在语音通话场景下，SDK 会自动生成一路 16px × 16px 的黑帧视频流用来发送 SEI 数据，帧率为 15 fps。
     * + 如果调用此接口之后的 2s 内，没有可带 SEI 的视频帧（比如没有开启视频采集和传输），那么，SEI 数据不会被加进视频帧中。
     * + 消息发送成功后，远端会收到 [onSEIMessageReceived](85533#onseimessagereceived) 回调。
     * + 语音通话切换至视频通话时，会停止 SEI 数据发送，你需再次调用该接口方可恢复发送。
     */
    sendSEIMessage(stream_index, message, repeat_count, mode) {
        if (utils_1.isNull(stream_index) ||
            utils_1.isNull(message) ||
            utils_1.isNull(repeat_count) ||
            utils_1.isNull(mode)) {
            return utils_1.errorFeedback("sendSEIMessage");
        }
        return this.instance.sendSEIMessage(stream_index, message, repeat_count, mode);
    }
    /** {en}
     * @brief  Set the video capture parameters for internal capture of the RTC SDK.
     * @param config Video capture parameters.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes
     *  + This interface can be called after the engine is created and takes effect immediately after being called. It is recommended to call this interface before calling [startVideoCapture](85532#startvideocapture).
     *  + It is recommended that different Engines on the same device use the same video capture parameters.
     *  + If you used the internal module to start video capture before calling this interface, the capture parameters default to Auto.
     */
    /** {zh}
     * @region 共享屏幕管理
     * @brief 设置 RTC SDK 内部采集时的视频采集参数。指定视频采集参数包括模式、分辨率、帧率。
     * @param config 视频采集参数
     * @return 方法调用结果：
     *         0：成功
     *         !0：失败
     * @notes + 本接口在引擎创建后即可调用，建议在调用 [startVideoCapture](85532#startvideocapture) 前调用本接口。
     * + 建议同一设备上的不同 Engine 使用相同的视频采集参数。
     * + 如果调用本接口前使用内部模块开始视频采集，采集参数默认为 Auto 模式。
     */
    setVideoCaptureConfig(video_capture_config) {
        //Default
        const tempConfig = {
            capturePreference: types_1.CapturePreference.KAuto,
            width: 0,
            height: 0,
            frameRate: 0,
        };
        return this.instance.setVideoCaptureConfig({
            ...tempConfig,
            ...(video_capture_config || {}),
        });
    }
    /** {en}
     * @brief Start mixing audio files.
     * @param mix_id ID of the mixing task. Used to identify the mixing task.
     *         If this method is repeatedly called with the same ID, the previous mixing task will be stopped and a new task will start. When the previous task is stopped, you will receive `onAudioMixingStateChanged`.
     *         To mixing multiple audio files at the same time, you can call this method with different mixIDs.
     * @param file_path The path of the mixing audio file.
     *        You can use the URL of the online file, and the absolute path of the local file. For the URL of the online file, only https protocol is supported.
     *        Recommended audio sample rates: 8KHz, 16KHz, 22.05KHz, 44.1KHz, 48KHz.
     *        Local audio file formats supported by different platforms:
     *        <table>
     *           <tr><th></th><th>mp3</th><th>mp4</th><th>aac</th><th>m4a</th><th>3gp</th><th>wav</th><th>ogg</th><th>ts</th><th>wma</th></tr>
     *           <tr><td>macOS</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td></td><td></td><td></td></tr>
     *           <tr><td>Windows</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td></td><td>Y</td><td>Y</td></tr>
     *           <tr><td>Linux</td><td></td><td></td><td></td><td></td><td></td><td>Y</td><td></td><td></td><td></td></tr>
     *        </table>
     *        Online audio file formats supported by different platforms:
     *        <table>
     *           <tr><th></th><th>mp3</th><th>mp4</th><th>aac</th><th>m4a</th><th>3gp</th><th>wav</th><th>ogg</th><th>ts</th><th>wma</th></tr>
     *           <tr><td>macOS</td><td>Y</td><td></td><td>Y</td><td>Y</td><td></td><td>Y</td><td></td><td></td><td></td></tr>
     *           <tr><td>Windows</td><td>Y</td><td></td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td></td><td>Y</td><td>Y</td></tr>
     *        </table>
     * @param config Mixing configuration
     *         You can set the number of times the file is played, whether the file is played locally or remotely.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + If you have already loaded the file in memory with [preloadAudioMixing](#preloadaudiomixing), ensure that the mixID is the same.
     * + After calling this method, you will receive `onAudioMixingStateChanged` about the current mixing status.
     * + Call [stopAudioMixing](#stopaudiomixing) to stop the mixing task.
     * + You can call this API with different conbinations of ID and file_path to mix multiple audio files at the same time.
     */
    /** {zh}
     * @brief 开始播放音乐文件及混音
     * @param mix_id  混音 ID，用于标识混音，请保证混音 ID 唯一性。  如果已经通过 [preloadAudioMixing](#preloadaudiomixing) 将音效加载至内存，确保此处的 ID 与 [preloadAudioMixing](#preloadaudiomixing) 设置的 ID 相同。  如果使用相同的 ID 重复调用本方法，前一次混音会停止，后一次混音开始，且 SDK 会使用 [onAudioMixingStateChanged](85533#onaudiomixingstatechanged) 回调通知前一次混音已停止。
     * @param file_path 用于混音文件路径。
     *        支持在线文件的 URL、和本地文件的绝对路径。对于在线文件的 URL，仅支持 https 协议。
     *        推荐的音频文件采样率：8KHz、16KHz、22.05KHz、44.1KHz、48KHz。
     *        不同平台支持的本地音频文件格式:
     *        <table>
     *           <tr><th></th><th>mp3</th><th>mp4</th><th>aac</th><th>m4a</th><th>3gp</th><th>wav</th><th>ogg</th><th>ts</th><th>wma</th></tr>
     *           <tr><td>macOS</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td></td><td></td><td></td></tr>
     *           <tr><td>Windows</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td></td><td>Y</td><td>Y</td></tr>
     *           <tr><td>Linux</td><td></td><td></td><td></td><td></td><td></td><td>Y</td><td></td><td></td><td></td></tr>
     *        </table>
     *        不同平台支持的在线音频文件格式:
     *        <table>
     *           <tr><th></th><th>mp3</th><th>mp4</th><th>aac</th><th>m4a</th><th>3gp</th><th>wav</th><th>ogg</th><th>ts</th><th>wma</th></tr>
     *           <tr><td>macOS</td><td>Y</td><td></td><td>Y</td><td>Y</td><td></td><td>Y</td><td></td><td></td><td></td></tr>
     *           <tr><td>Windows</td><td>Y</td><td></td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td></td><td>Y</td><td>Y</td></tr>
     *        </table>
     * @param config 混音配置，设置混音的播放次数、是否本地播放混音、以及是否将混音发送至远端
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 调用本方法成功播放音乐文件后，SDK 会向本地回调当前的混音状态，见 [onAudioMixingStateChanged](85533#onaudiomixingstatechanged)。
     * + 开始播放音乐文件及混音后，可以调用 [stopAudioMixing](#stopaudiomixing) 方法停止播放音乐文件。
     * + 可以通过传入不同的 ID 和 file_path 多次调用本方法，以实现同时播放多个音乐文件，实现混音叠加。
     */
    startAudioMixing(mix_id, file_path, config) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("startAudioMixing");
        }
        if (utils_1.isNull(file_path)) {
            return utils_1.errorFeedback("startAudioMixing");
        }
        if (utils_1.isNull(config) ||
            utils_1.isNull(config.play_count) ||
            utils_1.isNull(config.position) ||
            utils_1.isNull(config.type)) {
            return utils_1.errorFeedback("startAudioMixing");
        }
        const defaultValue = {
            callback_on_progress_interval: 0,
            sync_progress_to_record_frame: false,
        };
        return this.instance.startAudioMixing(mix_id, file_path, {
            ...defaultValue,
            ...config,
        });
    }
    /** {en}
     * @brief  Stop playing music files and mixes
     * @param mix_id ID of the mixing task
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + After calling the [startAudioMixing](#startaudiomixing) method to start playing music files and mixes, you can call this method to stop playing music files and mixes.
     * + After calling this method to stop playing the music file, the SDK notifies the local callback that the mixing has been stopped. See `onAudioMixingStateChanged`.
     * + After calling this method to stop playing the music file, the music file will be automatically uninstalled.
     */
    /** {zh}
     * @region 混音
     * @brief 停止播放音乐文件及混音
     * @param mix_id 混音 ID
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 调用 [startAudioMixing](#startaudiomixing) 方法开始播放音乐文件及混音后，可以调用本方法停止播放音乐文件及混音。
     * + 调用本方法停止播放音乐文件后，SDK 会向本地回调通知已停止混音，见 [onAudioMixingStateChanged](85533#onaudiomixingstatechanged)。
     * + 调用本方法停止播放音乐文件后，该音乐文件会被自动卸载。
     */
    stopAudioMixing(mix_id) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("stopAudioMixing");
        }
        return this.instance.stopAudioMixing(mix_id);
    }
    /** {en}
     * @brief  Pause playing music files and mixes
     * @param mix_id ID of the mixing task
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes
     * + After calling the [startAudioMixing](#startaudiomixing) method to start playing music files and mixes, you can call this method to pause playing music files and mixes.
     * + After calling this method to pause playing music files and mixing, you can call the [resumeAudioMixing](#resumeaudiomixing) method to resume playing and mixing.
     * + After calling this method to pause playing the music file, the SDK will notify the local callback that the mixing has been suspended.
     */
    /** {zh}
     * @brief 暂停播放音乐文件及混音
     * @param mix_id 混音 ID
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 调用 [startAudioMixing](#startaudiomixing) 方法开始播放音乐文件及混音后，可以通过调用本方法暂停播放音乐文件及混音。
     * + 调用本方法暂停播放音乐文件及混音后，可调用 [resumeAudioMixing](#resumeaudiomixing) 方法恢复播放及混音。
     * + 调用本方法暂停播放音乐文件后，SDK 会向本地回调通知已暂停混音，见 [onAudioMixingStateChanged](85533#onaudiomixingstatechanged)。
     */
    pauseAudioMixing(mix_id) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("pauseAudioMixing");
        }
        return this.instance.pauseAudioMixing(mix_id);
    }
    /** {en}
     * @brief  Resume playing music files and mixing
     * @param mix_id mix_id
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + After calling the [pauseAudioMixing](#pauseaudiomixing) method to pause playing music files and mixing, you can resume playing and mixing by calling this method.
     * + After calling this method to resume playing the music file and mixing, the SDK will notify the local callback that the music file is playing.
     */
    /** {zh}
     * @brief 恢复播放音乐文件及混音
     * @param mix_id 混音 ID
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 调用 [pauseAudioMixing](#pauseaudiomixing) 方法暂停播放音乐文件及混音后，可以通过调用本方法恢复播放及混音。
     * + 调用本方法恢复播放音乐文件及混音后，SDK 会向本地回调通知音乐文件正在播放中，见 [onAudioMixingStateChanged](85533#onaudiomixingstatechanged)。
     */
    resumeAudioMixing(mix_id) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("resumeAudioMixing");
        }
        return this.instance.resumeAudioMixing(mix_id);
    }
    /** {en}
     * @brief Preload the audio file into memory to minimize the loading cost of playing repeatedly.
     * @param mix_id ID of the mixing task. Used to identify the mixing task.
     *        If this method is repeatedly called with the same ID, the previous file will be unloaded and the new file will be loaded.
     *         If you call [startAudioMixing](#startaudiomixing) and then call this method with the same ID, the previous mixing task will be stopped, and then the next file will be loaded.
     *         After calling this method to preload A.mp3, if you need to call [startAudioMixing](#startaudiomixing) to play B.mp3 with the same ID, call [unloadAudioMixing](#unloadaudiomixing) to unload A.mp3 first.
     * @param file_path The path of the file to preload.
     *        You can use the URL of the online file, and the absolute path of the local file. For the URL of the online file, only https protocol is supported. You can only perload the audio file of length less than 20s.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + After preloaded, call [startAudioMixing](#startaudiomixing) to play the audio file.
     * + After calling this method, you will receive `onAudioMixingStateChanged` about the current mixing status.
     * + Unload the preloaded file with [unloadAudioMixing](#unloadaudiomixing).
     */
    /** {zh}
     * @region 混音
     * @brief 预加载指定音乐文件到内存中，以避免频繁播放同一文件时的重复加载，减少 CPU 占用。
     * @param mix_id 混音 ID  应用调用者维护，请保证唯一性。  如果使用相同的 ID 调用本方法，后一次会覆盖前一次。 如果先调用 [startAudioMixing](#startaudiomixing) ，再使用相同的 ID 调用本方法 ，会先回调 [onAudioMixingStateChanged](85533#onaudiomixingstatechanged) 上一个混音停止，然后加载后一个混音。  使用一个 ID 调用本方法预加载 A.mp3 后，如果需要使用相同的 ID 调用 [startAudioMixing](#startaudiomixing) 播放 B.mp3，请先调用 [unloadAudioMixing](#unloadaudiomixing) 卸载 A.mp3 ，否则会报错 kAudioMixingErrorLoadConflict。
     * @param file_path  指定需要混音的本地文件的绝对路径，支持音频文件格式有: mp3，aac，m4a，3gp，wav。  预加载的文件长度不得超过 20s。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 需要频繁播放某个音乐文件的时候，调用本方法预加载该文件，在播放的时候可以只加载一次该文件，减少 CPU 占用。
     * + 本方法只是预加载指定音乐文件，只有调用 [startAudioMixing](#startaudiomixing) 方法才开始播放指定音乐文件。
     * + 调用本方法预加载音乐文件后，SDK 会回调通知音乐文件已加载，见 [onAudioMixingStateChanged](85533#onaudiomixingstatechanged)。
     * + 调用本方法预加载的指定音乐文件可以通过 [unloadAudioMixing](#unloadaudiomixing) 卸载。
     */
    preloadAudioMixing(mix_id, file_path) {
        if (utils_1.isNull(mix_id) || utils_1.isNull(file_path)) {
            return utils_1.errorFeedback("preloadAudioMixing");
        }
        return this.instance.preloadAudioMixing(mix_id, file_path);
    }
    /** {en}
     * @brief Uninstall the specified music file
     * @param mix_id ID of the mixing task
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Whether the music file is playing or not, after calling this method to uninstall the file, the SDK will call back to notify that the mix has stopped. See `onAudioMixingStateChanged`.
     */
    /** {zh}
     * @region 混音
     * @brief 卸载指定音乐文件
     * @param mix_id 混音 ID
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 不论音乐文件是否播放，调用本方法卸载该文件后，SDK 会回调通知混音已停止，见 [onAudioMixingStateChanged](85533#onaudiomixingstatechanged)。
     */
    unloadAudioMixing(mix_id) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("unloadAudioMixing");
        }
        return this.instance.unloadAudioMixing(mix_id);
    }
    /** {en}
     * @brief Adjust the volume of audio mixing, including audio files and PCM data.
     * @param mix_id ID of the mixing task
     * @param volume The ratio of the mixing volume to the original volume. The range is `[0, 400]`. The recommended range is `[0, 100]`.
     * + 0: Mute
     * + 100: Original volume
     * + 400: Maximum volume (with overflow protection)
     * @param type Mixing type
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 混音
     * @brief 调节音乐文件在本地和远端播放的音量大小
     * @param mix_id 混音 ID
     * @param volume 音乐文件播放音量范围为 0~400。 <li> 0：静音 </li> <li> 100：原始音量  </li><li> 400: 最大可调音量 (自带溢出保护)</li>
     * @param type 混音播放类型 设置音乐文件是否本地播放、以及是否发送到远端，由此控制音乐文件本地或远端播放的音量
     * + `0`: 仅本地播放
     * + `1`: 仅发送到远端
     * + `2`: 在本地播放并发送到远端
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 调用本方法设置音量前，请先调用 [preloadAudioMixing](#preloadaudiomixing) 或 [startAudioMixing](#startaudiomixing)。
     * + 为保证更好的音质，建议将 volume 值设为 [0,100]。
     */
    setAudioMixingVolume(mix_id, volume, type) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("setAudioMixingVolume");
        }
        return this.instance.setAudioMixingVolume(mix_id, volume, type);
    }
    /** {en}
     * @brief Get the duration of the music file
     * @param mix_id ID of the mixing task
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Before calling this method to get the length of the music file, you need to call [preloadAudioMixing](#preloadaudiomixing) or [startAudioMixing](#startaudiomixing).
     */
    /** {zh}
     * @region 混音
     * @brief 获取音乐文件时长
     * @param mix_id 混音 ID
     * @return
     * + `>0`: 成功, 音乐文件时长，单位为毫秒。
     * + `<0`: 失败
     * @notes 调用本方法获取音乐文件时长前，需要先调用 [preloadAudioMixing](#preloadaudiomixing) 或 [startAudioMixing](#startaudiomixing)。
     */
    getAudioMixingDuration(mix_id) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("getAudioMixingDuration");
        }
        return this.instance.getAudioMixingDuration(mix_id);
    }
    /** {en}
     * @brief Get the music file playback progress
     * @param mix_id ID of the mixing task
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Before calling this method to get the progress of music file playback, you need to call [startAudioMixing](#startaudiomixing) to start playing music files.
     */
    /** {zh}
     * @region 混音
     * @brief 获取音乐文件播放进度
     * @param mix_id 混音 ID
     * @return
     * + `>0`: 成功, 音乐文件播放进度，单位为毫秒。
     * + `<0`: 失败
     * @notes 调用本方法获取音乐文件播放进度前，需要先调用 [startAudioMixing](#startaudiomixing) 开始播放音乐文件。
     */
    getAudioMixingCurrentPosition(mix_id) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("getAudioMixingCurrentPosition");
        }
        return this.instance.getAudioMixingCurrentPosition(mix_id);
    }
    /** {en}
     * @brief Set the starting position of the audio file for audio mixing
     * @param mix_id ID of the mixing task
     * @param position The starting position in ms.
     *        You can get the length of the file with [getAudioMixingDuration](#getaudiomixingduration). The value of the position must be less than the length of the file.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes When mixing online files, calling this API may cause mixing delay.
     */
    /** {zh}
     * @region 混音
     * @brief 设置音乐文件的播放位置
     * @param mix_id 混音 ID
     * @param position 音频文件起始播放位置，单位为毫秒。
     *        你可以通过 [getAudioMixingDuration](#getaudiomixingduration) 获取音频文件总时长，position 的值应小于音频文件总时长。
     * @return + 0：成功
     * + !0：失败
     * @notes 在播放在线文件时，调用此接口可能造成播放延迟的现象。
     */
    setAudioMixingPosition(mix_id, position) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("setAudioMixingPosition");
        }
        if (utils_1.isNull(position)) {
            return utils_1.errorFeedback("setAudioMixingPosition");
        }
        return this.instance.setAudioMixingPosition(mix_id, position);
    }
    /** {en}
     * @brief Get the duration of the music file
     * @param mix_id Mixing ID
     * @return + `> 0`: Success, the duration of the music file, in milliseconds.
     * + `< 0`: Failed
     * @notes  Before calling this method to get the length of the music file, you need to call [preloadAudioMixing](#preloadaudiomixing) or [startAudioMixing](#startaudiomixing).
     */
    /** {zh}
     * @brief 获取混音音频文件的实际播放时长（单位：毫秒）。
     * @param mix_id 混音 ID
     * @return + `> 0`: 实际播放时长。
     * + `< 0`: 失败
     * @notes + 实际播放时长指的是歌曲不受停止、跳转、倍速、卡顿影响的播放时长。例如，若歌曲正常播放到 1:30 时停止播放 30s 或跳转进度到 2:00, 随后继续正常播放 2分钟，则实际播放时长为 3分30秒。
     * + 调用本接口前，需要先调用 startAudioMixing 开始播放指定音频文件。
     */
    getAudioMixingPlaybackDuration(mix_id) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("getAudioMixingPlaybackDuration");
        }
        return this.instance.getAudioMixingPlaybackDuration(mix_id);
    }
    /** {en}
     * @brief Set the channel mode of the current audio file
     * @param mix_id ID of the mixing task
     * @param mode Channel mode. The default channel mode is the same as the source file.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Before calling this method to set the channel mode of the audio file, you need to call [startAudioMixing](#startaudiomixing) to start playing the audio file.
     */
    /** {zh}
     * @region 混音
     * @brief 设置当前音频文件的声道模式
     * @param mix_id 混音 ID
     * @param mode 声道模式。默认的声道模式和源文件一致，详见 AudioMixingDualMonoMode。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 调用本方法设置音频文件的声道模式前，需要先调用 startAudioMixing 开始播放音频文件。
     */
    setAudioMixingDualMonoMode(mix_id, mode) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("setAudioMixingDualMonoMode");
        }
        if (utils_1.isNull(mode)) {
            return utils_1.errorFeedback("setAudioMixingDualMonoMode");
        }
        return this.instance.setAudioMixingDualMonoMode(mix_id, mode);
    }
    /** {en}
     * @brief Enables local playback of music files in a different key, mostly used in Karaoke scenarios.  You can adjust the pitch of locally played music files such as ascending or descending with this method.
     * @param mix_id ID of the mixing task
     * @param pitch The value that is higher or lower than the original pitch of the audio file within a range from -12 to 12. The default value is 0, i.e. No adjustment is made.
     *        The difference in pitch between two adjacent values within the value range is a semitone, with positive values indicating an ascending tone and negative values indicating a descending tone, and the larger the absolute value set, the more the pitch is raised or lowered.
     *        Out of the value range, the setting fails and triggers the `onAudioMixingStateChanged` callback, indicating `AUDIO_MIXING_STATE_FAILED` for playback failure with AudioMixingState, and `AUDIO_MIXING_ERROR_ID_TYPE_ INVALID_PITCH` for invalid value setting with AudioMixingError.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes This method needs to be used after calling [startAudioMixing](#startaudiomixing) to start playing the audio file and before calling [`stopAudioMixing`](#stopaudiomixing) to stop playing the audio file, otherwise the `onAudioMixingStateChanged` callback will be triggered.
     */
    /** {zh}
     * @brief 开启本地播放音乐文件变调功能，多用于 K 歌场景。
     * @param mix_id 混音 ID
     * @param pitch 相对于音乐文件原始音调的升高/降低值，取值范围[-12，12]，默认值为 0，即不做调整。
                  取值范围内每相邻两个值的音高距离相差半音，正值表示升调，负值表示降调，设置的绝对值越大表示音调升高或降低越多。
                  超出取值范围则设置失败，并且会触发 onAudioMixingStateChanged 回调，提示 AudioMixingState 状态为 AUDIO_MIXING_STATE_FAILED 混音播放失败，AudioMixingError 错误码为 AUDIO_MIXING_ERROR_ID_TYPE_INVALID_PITCH 设置混音文件音调不合法
     * @return + 0：成功
     * + !0：失败
     * @notes 本方法需要在调用 [`startAudioMixing`](#startaudiomixing) 开始播放音频文件后、调用 [`stopAudioMixing`](#stopaudiomixing) 停止播放音频文件前使用，否则会触发 [`onAudioMixingStateChanged`](85533#onaudiomixingstatechanged) 回调报错
     */
    setAudioMixingPitch(mix_id, pitch) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("setAudioMixingPitch");
        }
        if (utils_1.isNull(pitch)) {
            return utils_1.errorFeedback("setAudioMixingPitch");
        }
        return this.instance.setAudioMixingPitch(mix_id, pitch);
    }
    /** {en}
     * @brief Sets the playback speed of the current audio file.
     * @param mix_id Audio mixing task ID
     * @param speed
     * @returns + 0: Success
     * + < 0: Failure.Ratio of playback speed to original speed in percentage. The range is [50,200], the default value is 100.
     *        If the value you set is out of range, the setting fails, and you will receive an `onAudioMixingStateChanged` callback, in which the AudioMixingState is `kAudioMixingStateFailed` and the AudioMixingError is `kAudioMixingErrorInValidPlaybackSpeed`.
     * @notes + You should call this API after calling [startAudioMixing](#startaudiomixing) and receiving an `onAudioMixingStateChanged` callback indicating that the AudioMixingState is `kAudioMixingStatePlaying` and the AudioMixingError is `kAudioMixingErrorOk`.
     * + If you call this API after calling [stopAudioMixing](#stopaudiomixing) or [unloadAudioMixing](#unloadaudiomixing), you will receive an `onAudioMixingStateChanged` callback indicating that the AudioMixingState is `kAudioMixingStateFailed` and the AudioMixingError is `kAudioMixingErrorIdNotFound`.
     */
    /** {zh}
     * @brief 设置混音时音频文件的播放速度
     * @param mix_id 混音 ID
     * @param speed 播放速度与原始文件速度的比例，单位：%，取值范围为 [50,200]，默认值为 100。
              超出取值范围则设置失败，你会收到 onAudioMixingStateChanged 回调，提示 AudioMixingState 状态为 kAudioMixingStateFailed 混音播放失败，AudioMixingError 错误码为 kAudioMixingErrorInValidPlaybackSpeed 设置混音文件的播放速度不合法。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes + 你需要在调用 startAudioMixing 开始混音，并且收到onAudioMixingStateChanged 回调提示 AudioMixingState 状态为 kAudioMixingStatePlaying，AudioMixingError 错误码为 kAudioMixingErrorOk 之后调用该方法。
     * + 在 [stopAudioMixing](#stopaudiomixing) 停止混音或 [unloadAudioMixing](#unloadaudiomixing) 卸载音频文件后调用该 API，会收到状态为 kAudioMixingStateFailed 错误码为 kAudioMixingErrorIdNotFound 的 onAudioMixingStateChanged 回调。
     */
    setAudioMixingPlaybackSpeed(mix_id, speed) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("setAudioMixingPlaybackSpeed");
        }
        if (utils_1.isNull(speed)) {
            return utils_1.errorFeedback("setAudioMixingPlaybackSpeed");
        }
        return this.instance.setAudioMixingPlaybackSpeed(mix_id, speed);
    }
    /** {en}
     * @brief If you need to call `enableVocalInstrumentBalance` to adjust the volume of the audio file or PCM data used for audio mixing, you must import the original loudness value of the audio file or PCM data via this API.
     * @param mix_id Audio ID of the mixing task
     * @param loudness Original loudness of the audio file in lufs. The range is [-70.0, 0.0].
     *        If the value is set to be less than -70.0lufs, it is automatically adjusted to -70.0lufs. If the value is set to be greater than 0.0lufs, SDK will not equalize the loudness. The default value is 1.0lufs, i.e. No loudness equalization effect.
     * @notes To avoid sudden volume changes during audio file playback, we recommend that you call this API before starting to play the audio file with [startAudioMixing](#startaudiomixing).
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @region 混音
     * @brief  如果你需要使用 enableVocalInstrumentBalance 对混音使音频文件/PCM 音频数据进行音量调整，你必须通过此接口传入其原始响度。
     * @param mix_id 混音 ID
     * @param loudness 原始响度，单位：lufs，取值范围为 [-70.0, 0.0]。
               当设置的值小于 -70.0lufs 时，则默认调整为 -70.0lufs，大于 0.0lufs 时，则不对该响度做音均衡处理。默认值为 1.0lufs，即不做处理。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 建议在 startAudioMixing 开始播放音频文件之前调用该接口，以免播放过程中的音量突变导致听感体验下降。
     */
    setAudioMixingLoudness(mix_id, loudness) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("setAudioMixingLoudness");
        }
        if (utils_1.isNull(loudness)) {
            return utils_1.errorFeedback("setAudioMixingLoudness");
        }
        return this.instance.setAudioMixingLoudness(mix_id, loudness);
    }
    /** {en}
     * @brief Set the interval of audio file playback progress callbacks during audio mixing
     * @param mix_id ID of the mixing task
     *        You can set the interval for multiple IDs by calling this method multiple times and passing in different IDs.
     * @param interval The time interval (ms) of the audio file playback progress callback in milliseconds.
     * + The value of interval is a multiple of 10 greater than 0. When the value set is not divisible by 10, the default is rounded up by 10. For example, if the value is set to 52ms, it will be automatically adjusted to 60ms, then the SDK will trigger `onAudioMixingPlayingProgress` callback at the set interval.
     * + If the value is less than or equals to 0, the callback will not be triggered.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes This method needs to be used after calling [startAudioMixing](#startaudiomixing) to start playing the audio file, and before calling [stopAudioMixing](#stopaudiomixing) to stop playing the audio file, otherwise an error callback `onAudioMixingStateChanged` will be triggered.
     *        If you want to set the interval of playback progress callbacks before the music file starts playing, you need to call [startAudioMixing](#startaudiomixing) to set the interval in AudioMixingConfig, and you can update the callback interval through this method after the audio file starts playing.
     */
    /** {zh}
     * @region 混音
     * @brief 设置混音时音频文件播放进度回调的间隔
     * @param mix_id 混音 ID。可以通过多次调用本接口传入不同的 ID 对多个 ID 进行间隔设置。
     * @param interval 音频文件播放进度回调的时间间隔，单位毫秒。
              •   interval 的值为大于 0 的 10 的倍数，当设置的值不能被 10 整除时，则默认向上取整 10，如设为 52ms 时会默认调整为 60ms。设置完成后 SDK 将会按照设置的时间间隔触发 onAudioMixingPlayingProgress 回调。
              • interval 的值小于等于 0 时，不会触发进度回调。
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 本方法需要在调用 [startAudioMixing](#startaudiomixing) 开始播放音频文件后、调用 [stopAudioMixing](#stopaudiomixing) 停止播放音频文件前使用，否则会触发 onAudioMixingStateChanged 回调报错。 若想在音乐文件开始播放前设置播放进度回调间隔，你需调用 startAudioMixing 在 AudioMixingConfig 中设置时间间隔，开始播放后可以通过此接口更新回调间隔。
     */
    setAudioMixingProgressInterval(mix_id, interval) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("setAudioMixingProgressInterval");
        }
        if (utils_1.isNull(interval)) {
            return utils_1.errorFeedback("setAudioMixingProgressInterval");
        }
        return this.instance.setAudioMixingProgressInterval(mix_id, interval);
    }
    /** {en}
     * @brief Get the track index of the current audio file
     * @param mix_id Mixding ID
     * @returns + >=0: Succeeded, the SDK will return the track index of the current audio file.
     * + < 0: Failed
     * @notes Before using this method, you should call [startAudioMixing](#startaudiomixing) to start playing the audio file.
     */
    /** {zh}
     * @region 混音
     * @brief 获取当前音频文件的音轨索引
     * @param mix_id 混音 ID
     * @return
     * + ≥ 0：成功，返回当前音频文件的音轨索引
     * + < 0：方法调用失败
     * @notes 调用本方法获取音频文件的音轨前，需要先调用 [startAudioMixing](#startaudiomixing) 开始播放音频文件。
     */
    getAudioTrackCount(mix_id) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("getAudioTrackCount");
        }
        return this.instance.getAudioTrackCount(mix_id);
    }
    /** {en}
     * @brief Specify the playback track of the current audio file
     * @param mix_id ID of the mixing task
     * @param audio_track_index The specified playback track.
     *        The set parameter value needs to be less than or equal to the return value of [getAudioTrackCount](#getaudiotrackcount).
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Before using this method, you should call [startAudioMixing](#startaudiomixing) to start playing the audio file.
     */
    /** {zh}
     * @brief 指定当前音频文件的播放音轨
     * @param mix_id 混音 ID
     * @param audio_track_index 指定的播放音轨
              设置的参数值需要小于或等于 [getAudioTrackCount](#getaudiotrackcount) 的返回值
     * @return + 0：成功
     * + !0：失败
     * @notes 调用本方法设置音频文件的音轨前，需要先调用 [startAudioMixing](#startaudiomixing) 开始播放音频文件。
     */
    selectAudioTrack(mix_id, audio_track_index) {
        if (utils_1.isNull(mix_id)) {
            return utils_1.errorFeedback("selectAudioTrack");
        }
        if (utils_1.isNull(audio_track_index)) {
            return utils_1.errorFeedback("selectAudioTrack");
        }
        return this.instance.selectAudioTrack(mix_id, audio_track_index);
    }
    /** {en}
     * @brief Change local voice to a different key, mostly used in Karaoke scenarios.  You can adjust the pitch of local voice such as ascending or descending with this method.
     * @param pitch The value that is higher or lower than the original local voice within a range from -12 to 12. The default value is 0, Unchanged.
     *        The difference in pitch between two adjacent values within the value range is a semitone, with positive values indicating an ascending tone and negative values indicating a descending tone, and the larger the absolute value set, the more the pitch is raised or lowered.
     *        Out of the value range, the setting fails and triggers [onWarning](85533#onwarning) callback, indicating `WARNING_CODE_SET_SCREEN_STREAM_INVALID_VOICE_PITCH` for invalid value setting with WarningCode.
     * @returns + 0: Success
     * + < 0: Failure.
     */
    /** {zh}
     * @brief 开启本地语音变调功能，多用于 K 歌场景。使用该方法，你可以对本地语音的音调进行升调或降调等调整。
     * @param pitch 相对于语音原始音调的升高/降低值，取值范围[-12，12]，默认值为 0，即不做调整。
     *        取值范围内每相邻两个值的音高距离相差半音，正值表示升调，负值表示降调，设置的绝对值越大表示音调升高或降低越多。
     *        超出取值范围则设置失败，并且会触发 [onWarning](85533#onwarning) 回调，提示码为 `WARNING_CODE_SET_SCREEN_STREAM_INVALID_VOICE_PITCH` 设置语音音调不合法
     * @return + 0：成功
     * + !0：失败
     */
    setLocalVoicePitch(pitch) {
        if (utils_1.isNull(pitch)) {
            return utils_1.errorFeedback("setLocalVoicePitch");
        }
        return this.instance.setLocalVoicePitch(pitch);
    }
    /** {en}
     * @brief This method records the audio & video data during the call to a local file.
     * @param type Stream attribute, specify whether to record mainstream or screen stream.
     * @param config Local recording parameter configuration.
     * @param recording_type Recording stored file format
     * @returns + 0: normal
     * + -1: Parameter setting exception
     * + -2: The current version of the SDK does not support this Feature, please contact technical support staff
     * @notes + After calling this method, you will receive an [onRecordingStateUpdate](85533#onrecordingstateupdate) callback.
     * + If the recording is normal, the system will notify the recording progress through [onRecordingProgressUpdate](85533#onrecordingprogressupdate) callback every second.
     */
    /** {zh}
     * @region 本地录制
     * @brief 该方法将通话过程中的音视频数据录制到本地的文件中。
     * @param type 流属性，指定录制主流还是屏幕流<li>主流。包括：由摄像头/麦克风通过内部采集机制，采集到的视频/音频。</li><li>屏幕流。屏幕共享时共享的视频流，或来自声卡的本地播放音频流。</li>
     * @param config 本地录制参数配置
     * @param recording_type 录制存储文件格式
     * @returns
     * + 0: 正常
     * + -1: 参数设置异常
     * + -2: 当前版本 SDK 不支持该特性，请联系技术支持人员
     * @notes + 调用该方法后，你会收到 [onRecordingStateUpdate](85533#onrecordingstateupdate) 回调。
     * + 如果录制正常，系统每秒钟会通过 [onRecordingProgressUpdate](85533#onrecordingprogressupdate) 回调通知录制进度。
     */
    startFileRecording(type, config, recording_type) {
        if (utils_1.isNull(type) ||
            utils_1.isNull(config) ||
            utils_1.isNull(config.dir_path) ||
            utils_1.isNull(config.file_type) ||
            utils_1.isNull(recording_type)) {
            return utils_1.errorFeedback("startFileRecording");
        }
        return this.instance.startFileRecording(type, config, recording_type);
    }
    /** {en}
     * @brief Stop local recording
     * @param type Stream attribute, specify to stop mainstream or screen stream recording.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + Call [startFileRecording](#startfilerecording) After starting local recording, you must call this method to stop recording.
     * + After calling this method, you will receive an [onRecordingStateUpdate](85533#onrecordingstateupdate) callback prompting you to record the result.
     */
    /** {zh}
     * @region 本地录制
     * @brief 停止本地录制
     * @param type 流属性，指定停止主流或者屏幕流录制<li>主流。包括：由摄像头/麦克风通过内部采集机制，采集到的视频/音频。</li><li>屏幕流。屏幕共享时共享的视频流，或来自声卡的本地播放音频流。</li>
     * @return + 0: 方法调用成功
     * + <0: 方法调用失败
     * @notes + 调用 [startFileRecording](#startfilerecording) 开启本地录制后，你必须调用该方法停止录制。
     * + 调用该方法后，你会收到 [onRecordingStateUpdate](85533#onrecordingstateupdate) 回调提示录制结果。
     */
    stopFileRecording(type) {
        if (utils_1.isNull(type)) {
            return utils_1.errorFeedback("stopFileRecording");
        }
        return this.instance.stopFileRecording(type);
    }
    /** {en}
     * @brief Sets the fallback option for published audio & video streams. You can call this API to set whether to automatically lower the resolution you set of the published streams under limited network conditions.
     * @param option Fallback option
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + This API only works after you call [enableSimulcastMode](#enablesimulcastmode) to enable the mode of publishing multiple streams.
     * + You must call this API before entering the room.
     * + After you allow video stream to fallback, your stream subscribers will receive [onSimulcastSubscribeFallback](85533#onsimulcastsubscribefallback) when the resolution of your published stream are lowered or restored.
     * + You can alternatively set fallback options with distrubutions from server side, which is of higher priority.
     */
    /** {zh}
     * @region 音视频回退
     * @brief 设置发布的音视频流回退选项 。你可以调用这个接口来设置网络情况不佳或设备性能不足时只发送小流，以保证通话质量。
     * @param option 本地发布的音视频流回退选项  <li>0：（默认）上行网络较弱或性能不佳时，不对音视频流作回退处理。  <li></li>>1：上行网络较弱或性能不佳时，只发送视频小流。</li>
     * @return
     * + 0: 方法调用成功
     * + <0: 方法调用失败
     * @notes + 该方法仅在调用 [enableSimulcastMode](#enablesimulcastmode) 开启了发送多路视频流的情况下生效。
     * + 你必须在进房前设置，进房后设置或更改设置无效。
     * + 设置回退选项后，本端发布的音视频流发生回退或从回退中恢复时，订阅该音视频流的客户端会收到 [onSimulcastSubscribeFallback](85533#onsimulcastsubscribefallback) 回调通知。
     * + 你可以调用 API 或者在服务端下发策略设置回退。当使用服务端下发配置实现时，下发配置优先级高于在客户端使用 API 设定的配置。
     */
    setPublishFallbackOption(option) {
        if (utils_1.isNull(option)) {
            return utils_1.errorFeedback("setPublishFallbackOption");
        }
        return this.instance.setPublishFallbackOption(option);
    }
    /** {en}
     * @brief Sets the fallback option for subscribed RTC streams.   You can call this API to set whether to lower the resolution of currently subscribed stream under limited network conditions.
     * @param option Fallback option
     * @returns + 0: Success
     * + < 0: Failure.
     *  @notes + You must call this API before enterting the room.
     * + After you enables the fallback, you will receive [onSimulcastSubscribeFallback](85533#onsimulcastsubscribefallback) and [onRemoteVideoSizeChanged](85533#onremotevideosizechanged) when the resolution of your subscribed stream is lowered or restored.
     * + You can alternatively set fallback options with distrubutions from server side, which is of higher priority.
     */
    /** {zh}
     * @region 音视频回退
     * @brief 设置订阅的音视频流回退选项。 你可以通过调用该接口来设置网络情况不佳或性能不足时只订阅小流或音频流，以保证通话质量。
     * @param option 远端订阅流回退处理选项<li>`0`: 关闭订阅音视频流时的性能回退功能 </li><li>`1`: 只接收视频小流</li><li>`2`: 先尝试只接收视频小流；如果网络环境无法显示视频，则再回退到只接收远端订阅的音频流</li>
     * @return  方法调用结果
     * + 0：方法调用成功
     * + <0：方法调用失败
     *  @notes + 你必须在进房前设置，进房后设置或更改设置无效。
     * + 设置回退选项后，本端订阅的音视频流发生回退或从回退中恢复时,会收到 [onSimulcastSubscribeFallback](85533#onsimulcastsubscribefallback) 回调通知。
     * + 设置回退选项后，本端订阅的视频流因为回退分辨率发生变化时,会收到 [onRemoteVideoSizeChanged](85533#onremotevideosizechanged) 回调通知。
     * + 你可以调用 API 或者在服务端下发策略设置回退。当使用服务端下发配置实现时，下发配置优先级高于在客户端使用 API 设定的配置。
     */
    setSubscribeFallbackOption(option) {
        if (utils_1.isNull(option)) {
            return utils_1.errorFeedback("setSubscribeFallbackOption");
        }
        return this.instance.setSubscribeFallbackOption(option);
    }
    /** {en}
     * @brief  Set user priority
     * @param room_id Room ID
     * @param user_id Remote user's ID
     * @param priority Remote user's requirement priority.
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + 1. This method is used with [setSubscribeFallbackOption](#setsubscribefallbackoption).
     * + 2. If the subscription flow fallback option is turned on, weak connections or insufficient performance will give priority to ensuring the quality of the flow received by high-priority users.
     * + 3. This method can be used before and after entering the room, and the priority of the remote user can be modified.
     */
    /** {zh}
     * @region 音视频回退
     * @brief 设置用户优先级
     * @param room_id 房间 ID
     * @param user_id 远端用户的 ID
     * @param priority 远端用户的需求优先级
     * @return + 0: 方法调用成功
     * + <0: 方法调用失败
     * @notes + 1. 该方法与 [setSubscribeFallbackOption](#setsubscribefallbackoption) 搭配使用。
     * + 2. 如果开启了订阅流回退选项，弱网或性能不足时会优先保证收到的高优先级用户的流的质量。
     * + 3. 该方法在进房前后都可以使用，可以修改远端用户的优先级。
     */
    setRemoteUserPriority(room_id, user_id, priority) {
        if (utils_1.isNull(room_id) || utils_1.isNull(user_id) || utils_1.isNull(priority)) {
            return utils_1.errorFeedback("setRemoteUserPriority");
        }
        return this.instance.setRemoteUserPriority(room_id, user_id, priority);
    }
    /** {en}
     * @brief Pre-call network detection
     * @param is_test_uplink Whether to detect uplink bandwidth
     * @param expected_uplink_bitrate Expected uplink bandwidth, unit: kbpsRange: {0, [100-10000]}, `0`: Auto, that RTC will set the highest bite rate.
     * @param is_test_downlink Whether to detect downlink bandwidth
     * @param expected_downlink_biterate Expected downlink bandwidth, unit: kbpsRange: {0, [100-10000]}, `0`: Auto, that RTC will set the highest bite rate.
     * @returns + 0: Network probing enabled successfully.
     * + 1: Failed to start probing. Parameter error, both uplink and downlink probes are 'false ', or the expected bandwidth exceeds the range [100,10000]
     * + 2: Failed to start probing. The reason for the failure is that the local push-pull flow has started.
     * + 3: Detection has started, no need to open it again.
     * + 4: Do not support this feature.
     * @notes + After calling this interface, you will receive [onNetworkDetectionResult](85533#onnetworkdetectionresult) within 3s and every 2s thereafter notifying the probe result;
     * + If the probe stops, you will receive [onNetworkDetectionStopped](85533#onnetworkdetectionstopped) notify that probing has stopped.
     */
    /** {zh}
     * @region 网络探测
     * @brief 开启通话前网络探测
     * @param is_test_uplink  是否探测上行带宽
     * @param expected_uplink_bitrate  期望上行带宽，单位：kbps范围为 {0, [100-10000]}，其中， 0 表示由 SDK 指定最高码率。
     * @param is_test_downlink  是否探测下行带宽
     * @param expected_downlink_biterate  期望下行带宽，单位：kbps范围为 {0, [100-10000]}，其中， 0 表示由 SDK 指定最高码率。
     * @return + 0: 成功开启网络探测。
     * + 1: 开始探测失败。参数错误，上下行探测均为 `false`，或期望带宽超过了范围 [100,10000]
     * + 2: 开始探测失败。失败原因为，本地已经开始推拉流
     * + 3: 已经开始探测，无需重复开启
     * + 4: 不支持该功能
     * @notes + 成功调用本接口后，会在 3s 内收到一次 [onNetworkDetectionResult](85533#onnetworkdetectionresult) 回调，此后每 2s 会收到一次该回调，通知探测结果；
     * + 若探测停止，则会收到一次 [onNetworkDetectionStopped](85533#onnetworkdetectionstopped)  通知探测停止。
     */
    startNetworkDetection(is_test_uplink, expected_uplink_bitrate, is_test_downlink, expected_downlink_biterate) {
        return this.instance.startNetworkDetection(is_test_uplink, expected_uplink_bitrate, is_test_downlink, expected_downlink_biterate);
    }
    /** {en}
     * @brief Stop pre-call network probe
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes After calling this interface, you will receive [onNetworkDetectionStopped](85533#onnetworkdetectionstopped) notifying that the the probing has stopped.
     */
    /** {zh}
     * @brief 停止通话前网络探测
     * @return
     * + 0：成功
     * + !0：失败
     * @notes 调用本接口后，会收到一次 [onNetworkDetectionStopped](85533#onnetworkdetectionstopped) 回调通知探测停止。
     */
    stopNetworkDetection() {
        return this.instance.stopNetworkDetection();
    }
    /////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////
    // /** {en}
    //  * @brief  Remove the background
    //  * @returns + 0: Success
    //  * + < 0: Failure.
    //  */
    // /** {zh}
    //  * @hidden
    //  * @brief 关闭背景
    //  * @return + 0: 方法调用成功
    //  * + <0: 方法调用失败
    //  */
    // @checkInit
    // public disableBackground(): number {
    //   return this.instance.disableBackground();
    // }
    /** {en}
     * @brief Set the original background to a specified image or a solid color. To disable this effect, set the modelPath parameter to null.
     * @param background_sticker_path The absolute path of virtual background effects
     * @param source Virtual background source
     * @returns + `0`: Success
     * + `-1000`：The BytePlus Effects SDK is not integrated.
     * + `-1001`：This feature is not supported in the BytePlus Effects SDK.
     * + `–1002`: Your Effects SDK's version is incompatible.
     * + `<0`：Other errors. See [error code table](https://docs.byteplus.com/effects/docs/error-code-table) for specific instructions.
     * @notes + You must call [initCVResource](#initcvresource) before calling this API.
     * + Call [disableVirtualBackground](#disablevirtualbackground) to turn off the virtual background.
     */
    /** {zh}
     * @brief 将摄像头采集画面中的人像背景替换为指定图片或纯色背景。
     * @param background_sticker_path 背景贴纸特效素材绝对路径。
     * @param source 背景贴纸对象。
     * @return + `0`: 调用成功
     * + `-1000`: 未集成 CV SDK
     * + `-1001`: 本版本不支持 CV 功能
     * + `–1002`: 特效 SDK 版本不兼容
     * + `<0`: 调用失败，具体错误码请参考 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     * @notes + 调用本方法前，必须先调用 [initCVResource](#initcvresource)。
     * + 调用 [disableVirtualBackground](#disablevirtualbackground) 关闭虚拟背景。
     */
    enableVirtualBackground(background_sticker_path, source) {
        if (utils_1.isNull(background_sticker_path) ||
            utils_1.isNull(source) ||
            utils_1.isNull(source.source_path)) {
            return utils_1.errorFeedback("enableVirtualBackground");
        }
        const defaultSource = {
            source_color: 0xffffffff,
            source_type: types_1.VirtualBackgroundSourceType.kVirtualBackgroundSourceColor,
        };
        return this.instance.enableVirtualBackground(background_sticker_path, {
            ...defaultSource,
            ...source,
        });
    }
    /** {en}
     * @brief Turns off the virtual background.
     * @return + `0`: Success.
     * + `–1000`: The Effects SDK is not integrated.
     * + `–1001`: This API is unavailable for your Effects SDK.
     * + `–1002`: Your Effects SDK's version is incompatible.
     * + `< 0`: Other error. See [error code table](https://docs.byteplus.com/effects/docs/error-code-table) for specific instructions.
     * @notes After calling [enableVirtualBackground](#enablevirtualbackground) to enable the virtual background function, you can call this API to turn it off.
     */
    /** {zh}
     * @brief 关闭虚拟背景。
     * @return + `0`: 调用成功。
     * + `–1000`: 未集成特效 SDK。
     * + `–1001`: 特效 SDK 不支持该功能。
     * + `–1002`: 特效 SDK 版本不兼容。
     * + `< 0`: 调用失败，错误码对应具体描述参看 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     * @notes 调用 [enableVirtualBackground](#enablevirtualbackground) 开启虚拟背景后，可以调用此接口关闭虚拟背景。
     */
    disableVirtualBackground() {
        return this.instance.disableVirtualBackground();
    }
    /** {en}
     * @brief Starts face detection and registers the observer for the result.
     * @param interval_ms The minimum time interval between two callbacks in milliseconds. The value should be greater than 0. The actual time interval is between `interval_ms` and `interval_ms+the time slot of a captured video frame`.
     * @param face_model_path The absolute path of the face detection algorithm file. Typically it is the tt_face_vXXX.model file in the ttfacemodel folder.
     * @return + `0`: Success.
     * + `–1000`: The Effects SDK is not integrated.
     * + `–1001`: This API is unavailable for your Effects SDK.
     * + `–1002`: Your Effects SDK's version is incompatible.
     * + `-1004`: Initializing. This function will be available when the initialization is completed.
     * + `<0`: Other error. See [error code table](https://docs.byteplus.com/effects/docs/error-code-table) for specific instructions.
     * @notes With this observer, you will receive [onFaceDetectResult](85533#onfacedetectresult) periodically.
     */
    /** {zh}
     * @brief 开启人脸识别功能，并设置人脸检测结果回调观察者。
     * @param interval_ms 两次回调之间的最小时间间隔，必须大于 0，单位为毫秒。实际收到回调的时间间隔大于 `interval_ms`，小于 `interval_ms+视频采集帧间隔`。
     * @param face_model_path 人脸检测算法模型文件路径，一般为 ttfacemodel 文件夹中 tt_face_vXXX.model 文件的绝对路径。
     * @return + `0`: 调用成功。
     * + `–1000`: 未集成特效 SDK。
     * + `–1001`: 特效 SDK 不支持该功能。
     * + `–1002`: 特效 SDK 版本不兼容。
     * + `-1004`: 初始化中，初始化完成后启动此功能。
     * + `<0`: 调用失败，错误码对应具体描述参看 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     * @notes 此观察者后，你会周期性收到 [onFaceDetectResult](85533#onfacedetectresult) 回调。
     */
    enableFaceDetection(interval_ms, face_model_path) {
        if (utils_1.isNull(interval_ms) || utils_1.isNull(face_model_path)) {
            return utils_1.errorFeedback("enableFaceDetection");
        }
        return this.instance.enableFaceDetection(interval_ms, face_model_path);
    }
    /** {en}
     * @brief Stops face detection.
     * @return + `0`: Success.
     * + `–1000`: The Effects SDK is not integrated.
     * + `–1001`: This API is unavailable for your Effects SDK.
     * + `–1002`: Your Effects SDK's version is incompatible.
     * + `<0`: Other error. See [error code table](https://docs.byteplus.com/effects/docs/error-code-table) for specific instructions.
     */
    /** {zh}
     * @brief 关闭人脸识别功能。
     * @return + `0`: 调用成功。
     * + `–1000`: 未集成特效 SDK。
     * + `–1001`: 特效 SDK 不支持该功能。
     * + `–1002`: 特效 SDK 版本不兼容。
     * + `<0`: 调用失败，错误码对应具体描述参看 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     */
    disableFaceDetection() {
        return this.instance.disableFaceDetection();
    }
    /** {en}
     * @brief Adds watermark to designated video stream.
     * @param stream_index The index of the target stream.
     * @param image_path File path of the watermark image. You can use the absolute path or the asset path(/assets/xx.png). The path should be less than 512 bytes.
     *        The watermark image should be in PNG or JPG format.
     * @param config Watermark configurations
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes + Call [clearVideoWatermark](#clearvideowatermark) to remove the watermark from the designated video stream.
     * + You can only add one watermark to one video stream. The newly added watermark replaces the previous one. You can call this API multiple times to add watermarks to different streams.
     * + If you mirror the preview, or the preview and the published stream, the watermark will also be mirrored locally, but the published watermark will not be mirrored.
     * + When you enable simulcast mode, the watermark will be added to all video streams, and it will be scaled down to smaller encoding configurations accordingly.
     */
    /** {zh}
     * @brief 在指定视频流上添加水印。
     * @param stream_index 需要添加水印的视频流属性。
     * @param image_path 水印图片路径，支持本地文件绝对路径和Asset 资源路径（/assets/xx.png），长度限制为 512 字节。
     *         水印图片为 PNG 或 JPG 格式。
     * @param config 水印参数
     * @return + 0: 调用成功
     * + 1000: 未集成 CV SDK
     * + 1001: 本版本不支持 CV 功能
     * + <0: 调用失败，具体错误码请参考 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     * @notes + 调用 [clearVideoWatermark](#clearvideowatermark) 移除指定视频流的水印。
     * + 同一路流只能设置一个水印，新设置的水印会代替上一次的设置。你可以多次调用本方法来设置不同流的水印。
     * + 进入房间前后均可调用此方法。
     * + 若开启本地预览镜像，或开启本地预览和编码传输镜像，则远端水印均不镜像；在开启本地预览水印时，本端水印会镜像。
     * + 开启大小流后，水印对大小流均生效，且针对小流进行等比例缩小。
     */
    setVideoWatermark(stream_index, image_path, config) {
        if (utils_1.isNull(image_path) ||
            utils_1.isNull(config) ||
            utils_1.isNull(config.positionInLandscapeMode) ||
            utils_1.isNull(config.positionInPortraitMode)) {
            return utils_1.errorFeedback("setVideoWatermark");
        }
        if (utils_1.isNull(config.visibleInPreview)) {
            config.visibleInPreview = true;
        }
        return this.instance.setVideoWatermark(stream_index, image_path, config);
    }
    /** {en}
     * @brief Removes video watermark from designated video stream.
     * @param stream_index Targeting stream index of the watermark.
     * @return + 0: Succeed.
     * + 1000: Integrating CV SDK failed.
     * + 1001: Invalid SDK version
     * + <0: Failed.
     */
    /** {zh}
     * @brief 移除指定视频流的水印。
     * @param stream_index 需要移除水印的视频流属性，参看 StreamIndex。
     * @return + 0: 调用成功
     * + 1000: 未集成 CV SDK
     * + 1001: 本版本不支持 CV 功能
     * + <0: 调用失败，具体错误码请参考 [错误码表](https://www.volcengine.com/docs/6705/102042)。
     */
    clearVideoWatermark(stream_index) {
        return this.instance.clearVideoWatermark(stream_index);
    }
    //////////////////////////////////////////////
    // JS Render Frame
    /** {en}
     * @brief Set the view for the local video.
     * @param view View
     * @param render_options Render options
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes If you need to unbind the video stream from the current view, call [`removeLocalVideo`](#removelocalvideo).
     */
    /** {zh}
     * @brief 设置本地视频渲染时使用的视图，并设置渲染模式。
     * @param view 视图
     * @param room_id 房间 ID
     * @param render_options 渲染选项
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes 如果需要解除绑定，调用 [`removeLocalVideo`](#removelocalvideo)。
     */
    setupLocalVideo(view, render_options = {
        render_mode: types_1.RenderMode.FIT,
        mirror: false,
    }) {
        let ret = -1;
        do {
            if (!view) {
                logger.warn("setupLocalVideo, view is null");
                break;
            }
            ret = this.setLocalVideoSink(types_1.StreamIndex.kStreamIndexMain, types_1.PixelFormat.kI420);
            //预览
            let user = this.previewUser;
            user.renderOptions = render_options;
            if (user.videoRender) {
                user.videoRender.destroy();
            }
            user.videoRender = new yuv_render_1.YUVRender(view, render_options.render_mode, render_options.mirror);
        } while (false);
        return ret;
    }
    /** {en}
     * @brief Unbind the local video from the view.
     * @returns + `0`: Success
     * + `-1`: Failure.
     */
    /** {zh}
     * @brief 解绑本地视频流已绑定的渲染视图
     * @return + `0`：成功
     * + `-1`: 失败
     */
    removeLocalVideo() {
        //删除预览视图
        let user = this.previewUser;
        if (user && user.videoRender) {
            user.videoRender.destroy();
            user.videoRender = null;
        }
        return this.unsetLocalVideoSink(types_1.StreamIndex.kStreamIndexMain);
    }
    /** {en}
     * @brief Set the view for the remote video.
     * @param user_id User ID
     * @param room_id Room ID
     * @param view View
     * @param render_options Render options
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes + To set the view for the remote video stream, call this API as soon as you receive [onUserPublishStream](85533#onuserpublishstream).
     * + If you need to unbind the remote video stream from the current view, call [`removeRemoteVideo`](#removeremotevideo) or [`removeAllRemoteVideo`](#removeallremotevideo).
     * + The setting expires as the local user leaves the room. The remote user leaving the room does not affect the setting.
     */
    /** {zh}
     * @brief 为远端视频流绑定本地渲染视图，并设置渲染模式。
     * @param user_id 远端用户 ID
     * @param room_id 房间 ID
     * @param view 视图
     * @param render_options 渲染选项
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes + 监听到 [onUserPublishStream](85533#onuserpublishstream) 后，调用本 API 绑定远端流。
     * + 如果需要解除绑定，调用 [`removeRemoteVideo`](#removeremotevideo) 或 [`removeAllRemoteVideo`](#removeallremotevideo)。
     * + 本地用户离开房间时，会解除调用此 API 建立的绑定关系；远端用户离开房间则不会影响。
     */
    setupRemoteVideo(user_id, room_id, view, render_options = {
        render_mode: types_1.RenderMode.FIT,
        mirror: false,
    }) {
        if (utils_1.isNull(user_id) || utils_1.isNull(room_id) || !view) {
            return utils_1.errorFeedback("setupRemoteVideo");
        }
        let ret = -1;
        do {
            if (!view) {
                logger.warn("SetupRemoteVideo, view is null");
                break;
            }
            const streamKey = {
                room_id,
                user_id,
                stream_index: types_1.StreamIndex.kStreamIndexMain,
            };
            ret = this.setRemoteVideoSink(streamKey, types_1.PixelFormat.kI420);
            let user = this.findUser(user_id, room_id);
            if (user) {
                if (user.videoRender) {
                    user.videoRender.destroy();
                }
                user.videoRender = new yuv_render_1.YUVRender(view, render_options.render_mode, render_options.mirror);
            }
        } while (false);
        return ret;
    }
    /** {en}
     * @brief Unbind the remote video from the view
     * @param user_id User ID
     * @param room_id Room ID
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes Call this API after stopping receiving the remote video.
     */
    /** {zh}
     * @brief 解绑指定远端视频流已绑定的本地视图
     * @param user_id 远端用户 ID
     * @param room_id 房间 ID
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes 停止接收远端视频流时应解绑视图
     */
    removeRemoteVideo(user_id, room_id) {
        if (utils_1.isNull(user_id) || utils_1.isNull(room_id)) {
            return utils_1.errorFeedback("removeRemoteVideo");
        }
        let user = this.findUser(user_id, room_id);
        if (user && user.videoRender) {
            user.videoRender.destroy();
            user.videoRender = null;
        }
        const streamKey = {
            room_id,
            user_id,
            stream_index: types_1.StreamIndex.kStreamIndexMain,
        };
        return this.unsetRemoteVideoSink(streamKey);
    }
    /** {en}
     * @brief Unbind all remote videos from the views
     * @param room_id Room ID
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes Call this API after stopping receiving the remote video.
     */
    /** {zh}
     * @brief 解绑所有已绑定本地视图的指定远端视频流
     * @param room_id 房间 ID
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes 停止接收远端视频流时应解绑视图
     */
    removeAllRemoteVideo(room_id) {
        var _a, _b;
        if (utils_1.isNull(room_id)) {
            return utils_1.errorFeedback("removeAllRemoteVideo");
        }
        (_b = (_a = data_1.default
            .get(room_id)) === null || _a === void 0 ? void 0 : _a.remoteUsers) === null || _b === void 0 ? void 0 : _b.forEach((user) => {
            if (user && user.videoRender) {
                user.videoRender.destroy();
                user.videoRender = null;
            }
            const streamKey = {
                room_id,
                user_id: user.userId,
                stream_index: types_1.StreamIndex.kStreamIndexMain,
            };
            return this.unsetRemoteVideoSink(streamKey);
        });
        return 0;
    }
    /** {en}
     * @brief Set the view for the local screen-sharing stream to preview the sharings.
     * @param view View
     * @param render_options
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes + Call this API before starting screen sharing.
     * + If you need to unbind the stream from the current view, call [`removelocalScreen`](#removeremotescreen).
     */
    /** {zh}
     * @brief 为本地屏幕共享流绑定视图，实现预览
     * @param view 视图
     * @param render_options 渲染选项
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes + 本地发起屏幕共享需要先绑定视图
     * + 如果需要解除绑定，调用 [`removeLocalScreen`](#removelocalscreen)。
     */
    setupLocalScreen(view, render_options = {
        render_mode: types_1.RenderMode.FIT,
        mirror: false,
    }) {
        let ret = -1;
        do {
            if (!view) {
                logger.warn("SetupLocalScreen, view is null");
                break;
            }
            ret = this.setLocalVideoSink(types_1.StreamIndex.kStreamIndexScreen, types_1.PixelFormat.kI420);
            //预览屏幕
            let user = this.previewUser;
            user.renderOptions = render_options;
            if (user.screenRender) {
                user.screenRender.destroy();
            }
            user.screenRender = new yuv_render_1.YUVRender(view, render_options.render_mode, render_options.mirror);
        } while (false);
        return ret;
    }
    /** {en}
     * @brief Unbind the screen-sharing stream from the view
     * @param roomId Room ID
     * @returns + 0: Success
     * + < 0: Failure.
     * @notes Call this API after stopping screen sharing.
     */
    /** {zh}
     * @brief 解绑屏幕共享流已绑定的视图
     * @param roomId 房间 ID
     * @return 0：成功
     *         !0: 失败
     * @notes 本地停止屏幕共享时解绑视图
     */
    removeLocalScreen() {
        let user = this.previewUser;
        if (user && user.screenRender) {
            user.screenRender.destroy();
            user.screenRender = null;
        }
        return this.unsetLocalVideoSink(types_1.StreamIndex.kStreamIndexScreen);
    }
    /** {en}
     * @brief Set the view for the remote screen-sharing stream
     * @param user_id User ID
     * @param room_id Room ID
     * @param view View
     * @param render_options Render options
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes + To set the view for the remote screen-sharing stream, call this API as soon as you receive [onUserPublishScreen](85533#onuserpublishscreen).
     * +  If you need to unbind the local video stream from the current view, call [`removeRemoteScreen`](#removeremotescreen).
     */
    /** {zh}
     * @brief 为远端屏幕共享流绑定本地视图
     * @param user_id 远端用户 ID
     * @param room_id 房间 ID
     * @param view 视图
     * @param render_options 渲染选项
     * @return 0：成功
     *         -1: 失败
     * @notes + 监听到 [onUserPublishScreen](85533#onuserpublishscreen) 后，调用本 API 绑定远端屏幕共享流。
     * + 如果需要解除绑定，调用 [`removeRemoteScreen`](#removeremotescreen)。
     */
    setupRemoteScreen(user_id, room_id, view, render_options = {
        render_mode: types_1.RenderMode.FIT,
        mirror: false,
    }) {
        if (utils_1.isNull(room_id) || utils_1.isNull(user_id) || !view) {
            return utils_1.errorFeedback("setupRemoteScreen");
        }
        let ret = -1;
        do {
            if (!view) {
                logger.warn("SetupRemoteScreen, view is null");
                break;
            }
            const streamKey = {
                room_id,
                user_id,
                stream_index: types_1.StreamIndex.kStreamIndexScreen,
            };
            ret = this.setRemoteVideoSink(streamKey, types_1.PixelFormat.kI420);
            let user = this.findUser(user_id, room_id);
            if (user) {
                if (user.screenRender) {
                    user.screenRender.destroy();
                }
                user.screenRender = new yuv_render_1.YUVRender(view, render_options.render_mode, render_options.mirror);
            }
        } while (false);
        return ret;
    }
    /** {en}
     * @brief Unbind the remote screen sharing stream from the view
     * @param user_id ID of the remote user
     * @param room_id Room ID
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes Call this API after stopping receiving screen sharing.
     */
    /** {zh}
     * @brief 解绑远端屏幕共享流已绑定的本地视图
     * @param user_id 远端用户 ID
     * @param room_id 房间 ID
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes 停止接收屏幕共享流时应解绑视图
     */
    removeRemoteScreen(user_id, room_id) {
        if (utils_1.isNull(user_id) || utils_1.isNull(room_id)) {
            return utils_1.errorFeedback("removeRemoteScreen");
        }
        let user = this.findUser(user_id, room_id);
        if (user && user.screenRender) {
            user.screenRender.destroy();
            user.screenRender = null;
        }
        const streamKey = {
            room_id,
            user_id,
            stream_index: types_1.StreamIndex.kStreamIndexScreen,
        };
        return this.unsetRemoteVideoSink(streamKey);
    }
    /** {en}
     * @brief Get local video stream
     * @param index Mainstream or screen-sharing stream.
     * @param required_format Video frame encoding format that applys to custom rendering.
     * @returns + `0`: Success
     * + `-1`: Failure.
     */
    /** {zh}
     * @brief 获取本地视频流。
     * @param index 视频流属性。采集的视频流/屏幕视频流
     * @param required_format 适用的视频帧编码格式
     * @return + `0`：成功
     * + `-1`: 失败
     */
    setLocalVideoSink(index, required_format) {
        if (utils_1.isNull(index)) {
            return utils_1.errorFeedback("setLocalVideoSink");
        }
        let user = this.previewUser;
        if (index == types_1.StreamIndex.kStreamIndexMain && user.videoRender) {
            logger.warn("local video canvas existed, should not call setLocalVideoSink!");
        }
        else if (index == types_1.StreamIndex.kStreamIndexScreen && user.screenRender) {
            logger.warn("local screen canvas existed, should not call setLocalVideoSink!");
        }
        return this.instance.setLocalVideoSink(index, required_format);
    }
    /** {en}
     * @brief Stop get local video stream
     * @param index Mainstream or screen-sharing stream.
     * @returns + `0`: Success
     * + `-1`: Failure.
     */
    /** {zh}
     * @brief 停止获取本地视频流。
     * @param index 视频流属性。采集的视频流/屏幕视频流
     * @return + `0`：成功
     * + `-1`: 失败
     */
    unsetLocalVideoSink(stream_index) {
        if (utils_1.isNull(stream_index)) {
            return utils_1.errorFeedback("unsetLocalVideoSink");
        }
        return this.instance.unsetLocalVideoSink(stream_index);
    }
    /** {en}
     * @brief Get remote video stream
     * @param stream_key Remote stream information that specifies the source and type of the video stream.
     * @param required_format Video frame encoding format that applys to custom rendering.
     * @returns + `0`: Success
     * + `-1`: Failure.
     */
    /** {zh}
     * @brief 获取远端视频流。
     * @param stream_key 远端流信息，用于指定需要设置超分的视频流来源及属性。
     * @param required_format 适用的视频帧编码格式
     * @return + `0`：成功
     * + `-1`: 失败
     */
    setRemoteVideoSink(stream_key, required_format) {
        if (utils_1.isNull(stream_key) ||
            utils_1.isNull(stream_key.room_id) ||
            utils_1.isNull(stream_key.stream_index) ||
            utils_1.isNull(stream_key.user_id)) {
            return utils_1.errorFeedback("setRemoteVideoSink");
        }
        let user = this.findUser(stream_key.user_id, stream_key.room_id);
        if (user) {
            if (stream_key.stream_index == types_1.StreamIndex.kStreamIndexMain && user.videoRender) {
                logger.warn("local video canvas existed, should not call setRemoteVideoSink!");
            }
            else if (stream_key.stream_index == types_1.StreamIndex.kStreamIndexScreen && user.screenRender) {
                logger.warn("local screen canvas existed, should not call setRemoteVideoSink!");
            }
        }
        return this.instance.setRemoteVideoSink(stream_key, required_format);
    }
    /** {en}
     * @brief Stop get remote video stream
     * @param stream_key Remote stream information that specifies the source and type of the video stream.
     * @returns + `0`: Success
     * + `-1`: Failure.
     */
    /** {zh}
     * @brief 停止获取远端视频流。
     * @param stream_key 远端流信息，用于指定需要设置超分的视频流来源及属性。
     * @return + `0`：成功
     * + `-1`: 失败
     */
    unsetRemoteVideoSink(stream_key) {
        if (utils_1.isNull(stream_key) ||
            utils_1.isNull(stream_key.room_id) ||
            utils_1.isNull(stream_key.stream_index) ||
            utils_1.isNull(stream_key.user_id)) {
            return utils_1.errorFeedback("unsetRemoteVideoSink");
        }
        return this.instance.unsetRemoteVideoSink(stream_key);
    }
    /** {en}
     * @hidden
     * @brief Plays the music.
     * @param music_id Music ID.
     *        If the song with the same music_id is playing when you call this API, the music will restart from the starting position. An error will be triggered if the audio file corresponding to music_id does not exist.
     * @param track_type Audio track type of the KTV player.
     * @param play_type Audio play type.
     * @returns + `0`: Success
     * + `<0`: Failure.
     * @notes + After calling this API, you will receive the music play state through [onPlayStateChanged](85533#onPlayStateChanged) callback.
     * +If the music ID is invalid, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3023 and a play_state of 4.
     * +If you didn't join the room, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3022 and a play_state of 4.
     * +If the music file does not exist, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3020 and a play_state of 4.
     */
    /** {zh}
     * @brief 播放歌曲。
     * @param music_id 音乐 ID。
     *        若同一 music_id 的歌曲正在播放，再次调用接口会从开始位置重新播放。若 music_id 对应的音频文件不存在会触发报错。
     * @param track_type 原唱伴唱类型。
     * @param play_type 音乐播放类型。
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes + 调用接口后，你会收到 [onPlayStateChanged](85533#onPlayStateChanged) 回调歌曲播放状态。
     * + 若音乐 ID 错误，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3023，play_state 为 4。
     * + 若未进房，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3022，play_state 为 4。
     * + 若音乐文件不存在，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3020，play_state 为 4。
     */
    playMusic(music_id, track_type, play_type) {
        if (utils_1.isNull(music_id) || utils_1.isNull(track_type) || utils_1.isNull(play_type)) {
            return utils_1.errorFeedback("playMusic");
        }
        return this.instance.playMusic(music_id, track_type, play_type);
    }
    /** {en}
     * @hidden
     * @brief Pauses the music.
     * @param music_id Music ID.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + After calling this API, you will receive the music play state through [onPlayStateChanged](85533#onPlayStateChanged) callback.
     * + If the music ID is invalid, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3023 and a play_state of 4.
     * + If you didn't join the room, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3022 and a play_state of 4.
     */
    /** {zh}
     * @brief 暂停播放歌曲。
     * @param music_id 音乐 ID。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes + 调用接口后，你会收到 [onPlayStateChanged](85533#onPlayStateChanged) 回调歌曲播放状态。
     * + 若音乐 ID 错误，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3023，play_state 为 4。
     * + 若未进房，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3022，play_state 为 4。
     */
    pauseMusic(music_id) {
        if (utils_1.isNull(music_id)) {
            return utils_1.errorFeedback("pauseMusic");
        }
        return this.instance.pauseMusic(music_id);
    }
    /** {en}
     * @hidden
     * @brief Resumes playing the music.
     * @param music_id Music ID.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + After calling this API, you will receive the music play state through [onPlayStateChanged](85533#onPlayStateChanged) callback.
     * + If the music ID is invalid, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3023 and a play_state of 4.
     * + If you didn't join the room, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3022 and a play_state of 4.
     */
    /** {zh}
     * @brief 继续播放歌曲。
     * @param music_id 音乐 ID。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes + 调用接口后，你会收到 [onPlayStateChanged](85533#onPlayStateChanged) 回调歌曲播放状态。
     * + 若音乐 ID 错误，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3023，play_state 为 4。
     * + 若未进房，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3022，play_state 为 4。
     */
    resumeMusic(music_id) {
        if (utils_1.isNull(music_id)) {
            return utils_1.errorFeedback("resumeMusic");
        }
        return this.instance.resumeMusic(music_id);
    }
    /** {en}
     * @hidden
     * @brief Stops playing the music.
     * @param music_id Music ID.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + After calling this API, you will receive the music play state through [onPlayStateChanged](85533#onPlayStateChanged) callback.
     * + If the music ID is invalid, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3023 and a play_state of 4.
     * + If you didn't join the room, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3022 and a play_state of 4.
     */
    /** {zh}
     * @brief 停止播放歌曲。
     * @param music_id 音乐 ID。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes + 调用接口后，你会收到 [onPlayStateChanged](85533#onPlayStateChanged) 回调歌曲播放状态。
     * + 若音乐 ID 错误，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3023，play_state 为 4。
     * + 若未进房，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3022，play_state 为 4。
     */
    stopMusic(music_id) {
        if (utils_1.isNull(music_id)) {
            return utils_1.errorFeedback("stopMusic");
        }
        return this.instance.stopMusic(music_id);
    }
    /** {en}
     * @hidden
     * @brief Sets the starting position of the music file.
     * @param music_id Music ID.
     * @param position The starting position of the music file in milliseconds. The value must be less than the total length of the music.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + The music must be playing when you call this API.
     * + After calling this API, you will receive the music play state through [onPlayStateChanged](85533#onPlayStateChanged) callback.
     * + If the music ID is invalid, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3023 and a play_state of 4.
     * + If you didn't join the room, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3022 and a play_state of 4.
     */
    /** {zh}
     * @brief 设置音乐文件的起始播放位置。
     * @param music_id 音乐 ID。
     * @param position 音乐起始位置，单位为毫秒，取值小于音乐文件总时长。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes + 调用本接口时音乐必须处于播放中状态。
     * + 调用接口后，你会收到 [onPlayStateChanged](85533#onPlayStateChanged) 回调歌曲播放状态。
     * + 若音乐 ID 错误，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3023，play_state 为 4。
     * + 若未进房，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3022，play_state 为 4。
     */
    seekMusic(music_id, position) {
        if (utils_1.isNull(music_id) || utils_1.isNull(position)) {
            return utils_1.errorFeedback("seekMusic");
        }
        return this.instance.seekMusic(music_id, position);
    }
    /** {en}
     * @hidden
     * @brief Sets the volume of the playing music. The music must be playing when you set the volume.
     * @param music_id Music ID.
     * @param volume Volume. Adjustment range: [0,400].
     * + `0`: Mute.
     * + `100`: Original volume.
     * + `400`: 4 times the original volume (with overflow protection).
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + The music must be playing when you call this API.
     * + If the set volume is greater than 400, it will be adjusted by the maximum value of 400; if the set volume is less than 0, it will be adjusted by the minimum value of 0.
     * + If the music ID is invalid, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3023 and a play_state of 4.
     * + If you didn't join the room, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3022 and a play_state of 4.
     */
    /** {zh}
     * @brief 设置歌曲播放音量，只能在开始播放后进行设置。
     * @param music_id 音乐 ID。
     * @param volume 歌曲播放音量，调节范围：[0,400]。
     * + `0`：静音。
     * + `100`：原始音量。
     * + `400`: 原始音量的 4 倍(自带溢出保护)。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes + 调用本接口时音乐必须处于播放中状态。
     * + 若设置的音量大于 400，则按最大值 400 进行调整；若设置的音量小于 0，则按最小值 0 进行调整。
     * + 若音乐 ID 错误，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3023，play_state 为 4。
     * + 若未进房，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3022，play_state 为 4。
     */
    setMusicVolume(music_id, volume) {
        if (utils_1.isNull(music_id) || utils_1.isNull(volume)) {
            return utils_1.errorFeedback("setMusicVolume");
        }
        return this.instance.setMusicVolume(music_id, volume);
    }
    /** {en}
     * @hidden
     * @brief Switches the audio track type between the original track and the instrumental track.
     * @param music_id Music ID.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes The music must be playing when you call this API.
     */
    /** {zh}
     * @brief 切换歌曲原唱伴唱。
     * @param music_id 音乐 ID。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes 调用本接口时音乐必须处于播放中状态。
     */
    switchAudioTrackType(music_id) {
        if (utils_1.isNull(music_id)) {
            return utils_1.errorFeedback("switchAudioTrackType");
        }
        return this.instance.switchAudioTrackType(music_id);
    }
    /** {en}
     * @hidden
     * @brief Transposes up/down the music being played.
     * @param music_id Music ID.
     * @param pitch The pitch up/down value relative to the original pitch, in the range of [-12, 12], with the default value of 0.
     *              The difference in pitch between two adjacent values is a semitone. A positive value indicates an increase in pitch, and a negative value indicates a decrease in pitch. A larger absolute value means more pitch increase or decrease.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + The music must be in the playing when you call this API.
     * + If the set pitch is greater than 12, it will be adjusted by the maximum value of 12; if the set pitch is less than –12, it will be adjusted by the minimum value of –12.
     * + If the music ID is invalid, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3023 and a play_state of 4.
     * + If you didn't join the room, you will receive the [onPlayStateChanged](85533#onPlayStateChanged) callback, with an error_code of -3022 and a play_state of 4.
     */
    /** {zh}
     * @brief 对播放中的音乐设置升降调信息。
     * @param music_id 音乐 ID。
     * @param pitch 相对于音乐文件原始音调的升高/降低值，取值范围 [-12，12]，默认值为 0，即不做调整。
     *              取值范围内每相邻两个值的音高距离相差半音，正值表示升调，负值表示降调，设置的绝对值越大表示音调升高或降低越多。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes + 调用本接口时音乐必须处于播放中状态。
     * + 若设置的 pitch 大于 12，则按最大值 12 进行调整；若设置的 pitch 小于 –12，，则按最小值 –12 进行调整。
     * + 若音乐 ID 错误，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3023，play_state 为 4。
     * + 若未进房，会触发 [onPlayStateChanged](85533#onPlayStateChanged) 回调，error_code 为 –3022，play_state 为 4。
     */
    setMusicPitch(music_id, pitch) {
        if (utils_1.isNull(music_id) || utils_1.isNull(pitch)) {
            return utils_1.errorFeedback("setMusicPitch");
        }
        return this.instance.setMusicPitch(music_id, pitch);
    }
    /** {en}
     * @hidden
     * @brief Sets the maximum cache for storing music files.
     * @param max_cache_size_MB The maximum cache to be set in MB.
     *        If the setting value is less than or equal to 0, it will be adjusted to 1,024 MB.
     * @return + `0`: Success
     * + `<0`: Failure.
     */
    /** {zh}
     * @brief 设置歌曲文件最大占用的本地缓存。
     * @param max_cache_size_MB 本地缓存，单位 MB。
     *        设置值小于等于 0 时，使用默认值 1024 MB。
     * @return + `0`：成功
     * + `<0`: 失败
     */
    setMaxCacheSize(max_cache_size_MB) {
        if (utils_1.isNull(max_cache_size_MB)) {
            return utils_1.errorFeedback("setMaxCacheSize");
        }
        return this.instance.setMaxCacheSize(max_cache_size_MB);
    }
    /** {en}
     * @hidden
     * @brief Gets the music list.
     * @param page_num Page number. The default value is 1.
     * @param page_size The number of the music that displays on one page.
     * @param filters The filter type of the music list. Multiple filters can be combined by the bitwise-or operator.
     *                + `0`: No filter.
     *                + `1<<0`: Remove music that does not have lyrics.
     *                + `1<<1`: Remove music that does not support scoring.
     *                + `1<<2`: Remove music that does not support accompany mode.
     *                + `1<<3`: Remove music that does not have a climax part.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes After calling this API, you will receive the music list through [onMusicListResult](85533#onmusiclistresult) callback.
     */
    /** {zh}
     * @brief 获取歌曲列表。
     * @param page_num 页码，默认从 1 开始。
     * @param page_size 每页显示歌曲的最大数量，取值范围 [1,99]。
     * @param filters 歌曲过滤方式。多个过滤方式可以按位或组合。
     *                + `0`: 不过滤。
     *                + `1<<0`: 过滤没有歌词的歌曲。
     *                + `1<<1`: 过滤不支持打分的歌曲。
     *                + `1<<2`: 过滤不支持伴唱切换的歌曲。
     *                + `1<<3`: 过滤没有高潮片段的歌曲。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes 调用接口后，你会收到 [onMusicListResult](85533#onmusiclistresult) 回调歌曲列表。
     */
    getMusicList(page_num, page_size, filters) {
        if (utils_1.isNull(page_num) || utils_1.isNull(page_size) || utils_1.isNull(filters)) {
            return utils_1.errorFeedback("getMusicList");
        }
        return this.instance.getMusicList(page_num, page_size, filters);
    }
    /** {en}
     * @hidden
     * @brief Search music by keywords.
     * @param key_word Keyword. The string should be no more than 20 characters.
     * @param page_num Page number. The default value is 1.
     * @param page_size The number of the music that displays on one page.
     * @param filters The filter type of the music list. Multiple filters can be combined by the bitwise-or operator.
     *                + `0`: No filter.
     *                + `1<<0`: Remove music that does not have lyrics.
     *                + `1<<1`: Remove music that does not support scoring.
     *                + `1<<2`: Remove music that does not support accompany mode.
     *                + `1<<3`: Remove music that does not have a climax part.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes After calling this API, you will receive the music list through [onSearchMusicResult](85533#onsearchmusicresult) callback.
     */
    /** {zh}
     * @brief 根据关键词搜索歌曲。
     * @param key_word 关键词，字符串长度最大为 20 个字符。
     * @param page_num 页码，默认从 1 开始。
     * @param page_size 每页显示歌曲的最大数量，取值范围 [1,99]。
     * @param filters 歌曲过滤方式。多个过滤方式可以按位或组合。
     *                + `0`: 不过滤。
     *                + `1<<0`: 过滤没有歌词的歌曲。
     *                + `1<<1`: 过滤不支持打分的歌曲。
     *                + `1<<2`: 过滤不支持伴唱切换的歌曲。
     *                + `1<<3`: 过滤没有高潮片段的歌曲。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes 调用接口后，你会收到 [onSearchMusicResult](85533#onsearchmusicresult) 回调歌曲列表。
     */
    searchMusic(key_word, page_num, page_size, filters) {
        if (utils_1.isNull(page_num) || utils_1.isNull(page_size) || utils_1.isNull(filters)) {
            return utils_1.errorFeedback("searchMusic");
        }
        const keyWords = key_word.length <= 20 ? key_word : key_word.slice(0, 20);
        return this.instance.searchMusic(keyWords, page_num, page_size, filters);
    }
    /** {en}
     * @hidden
     * @brief Gets hot music according to music types.
     * @param hot_types Hot music type. Multiple hot music types can be combined by the bitwise-or operator.
     *                + `1<<0`: Hot music in the content center.
     *                + `1<<1`: Hot music of the project.
     * @param filters The filter type of the music list. Multiple filters can be combined by the bitwise-or operator.
     *                + `0`: No filter.
     *                + `1<<0`: Remove music that does not have lyrics.
     *                + `1<<1`: Remove music that does not support scoring.
     *                + `1<<2`: Remove music that does not support accompany mode.
     *                + `1<<3`: Remove music that does not have a climax part.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes After calling this API, you will receive the music list through [onHotMusicResult](85533#onhotmusicresult) callback.
     */
    /** {zh}
     * @brief 根据热榜类别获取每个榜单的歌曲列表。
     * @param hot_types 热榜类别。多个热榜类别可以按位或组合。
     *                + `1<<0`: 火山内容中心热歌榜。
     *                + `1<<1`: 项目热歌榜。
     * @param filters 歌曲过滤方式。多个过滤方式可以按位或组合。
     *                + `0`: 不过滤。
     *                + `1<<0`: 过滤没有歌词的歌曲。
     *                + `1<<1`: 过滤不支持打分的歌曲。
     *                + `1<<2`: 过滤不支持伴唱切换的歌曲。
     *                + `1<<3`: 过滤没有高潮片段的歌曲。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes 调用接口后，你会收到 [onHotMusicResult](85533#onhotmusicresult) 回调歌曲列表。
     */
    getHotMusic(hot_types, filters) {
        if (utils_1.isNull(hot_types) || utils_1.isNull(filters)) {
            return utils_1.errorFeedback("getHotMusic");
        }
        return this.instance.getHotMusic(hot_types, filters);
    }
    /** {en}
     * @hidden
     * @brief Gets music detail.
     * @param music_id Music ID.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes After calling this API, you will receive the music detial through [onMusicDetailResult](85533#onmusicdetailresult) callback.
     */
    /** {zh}
     * @brief 获取音乐详细信息。
     * @param music_id 音乐 ID。
     * @return + `0`：成功
     * + `<0`: 失败
     * @notes 调用接口后，你会收到 [onMusicDetailResult](85533#onmusicdetailresult) 回调。
     */
    getMusicDetail(music_id) {
        if (utils_1.isNull(music_id)) {
            return utils_1.errorFeedback("getMusicDetail");
        }
        return this.instance.getMusicDetail(music_id);
    }
    /** {en}
     * @hidden
     * @brief Download music.
     * @param music_id Music ID.
     * @return Download task ID.
     * @notes + If the music is successfully downloaded, you will receive [onDownloadSuccess](85533#ondownloadsuccess).
     * + If the music fails to download, you will receive [onDownloadFailed](85533#ondownloadfailed).
     * + When the music download progress is updated, you will receive onDownloadMusicProgress(85533#onDownloadMusicProgress).
     */
    /** {zh}
     * @brief 下载音乐。
     * @param music_id 音乐 ID。
     * @return 下载任务 ID。
     * @notes + 若音乐下载成功，你会收到 [onDownloadSuccess](85533#ondownloadsuccess) 回调。
     * + 若音乐下载失败，你会收到 [onDownloadFailed](85533#ondownloadfailed) 回调。
     * + 音乐下载进度更新时，你会收到 onDownloadMusicProgress(85533#onDownloadMusicProgress) 回调。
     */
    downloadMusic(music_id) {
        if (utils_1.isNull(music_id)) {
            return utils_1.errorFeedback("downloadMusic");
        }
        return this.instance.downloadMusic(music_id);
    }
    /** {en}
     * @hidden
     * @brief Download lyrics.
     * @param music_id Music ID.
     * @param type The lyrics file's format.
     * @return Download task ID.
     * @notes + If the lyrics are successfully downloaded, you will receive [onDownloadSuccess](85533#ondownloadsuccess).
     * + If the lyrics fail to download, you will receive [onDownloadFailed](85533#ondownloadfailed).
     */
    /** {zh}
     * @brief 下载歌词。
     * @param music_id 音乐 ID。
     * @param type 歌词文件类型。
     * @return 下载任务 ID。
     * @notes + 若歌词下载成功，你会收到 [onDownloadSuccess](85533#ondownloadsuccess) 回调。
     * + 若歌词下载失败，你会收到 [onDownloadFailed](85533#ondownloadfailed) 回调。
     */
    downloadLyric(music_id, type) {
        if (utils_1.isNull(music_id) || utils_1.isNull(type)) {
            return utils_1.errorFeedback("downloadLyric");
        }
        return this.instance.downloadLyric(music_id, type);
    }
    /** {en}
     * @hidden
     * @brief Download MIDI files.
     * @param music_id Music ID.
     * @return Download task ID.
     * @notes + If the file is successfully downloaded, you will receive [onDownloadSuccess](85533#ondownloadsuccess).
     * + If the file fails to download, you will receive [onDownloadFailed](85533#ondownloadfailed).
     */
    /** {zh}
     * @brief 下载 MIDI 文件。
     * @param music_id 音乐 ID。
     * @return 下载任务 ID。
     * @notes + 若文件下载成功，你会收到 [onDownloadSuccess](85533#ondownloadsuccess) 回调。
     * + 若文件下载失败，你会收到 [onDownloadFailed](85533#ondownloadfailed) 回调。
     */
    downloadMidi(music_id) {
        if (utils_1.isNull(music_id)) {
            return utils_1.errorFeedback("downloadMidi");
        }
        return this.instance.downloadMidi(music_id);
    }
    /** {en}
     * @hidden
     * @brief Cancels download task.
     * @param download_id Download task ID.
     * @return + `0`: Success
     * + `<0`: Failure.
     */
    /** {zh}
     * @brief 取消下载任务。
     * @param download_id 下载任务 ID。
     * @return + `0`：成功
     * + `<0`: 失败
     */
    cancelDownload(download_id) {
        if (utils_1.isNull(download_id)) {
            return utils_1.errorFeedback("cancelDownload");
        }
        return this.instance.cancelDownload(download_id);
    }
    /** {en}
     * @hidden
     * @brief Clear music cache, including music and lyrics.
     * @return 0：成功
     *         -1: 失败
     */
    /** {zh}
     * @brief 清除当前音乐缓存文件，包括音乐音频和歌词。
     * @return + `0`: Success
     * + `<0`: Failure.
     */
    clearCache() {
        return this.instance.clearCache();
    }
    /** {en}
     * @hidden
     * @brief Initialize karaoke scoring feature.
     * @param sing_scoring_appkey The key for karaoke scoring, used to authenticate whether the karaoke scoring is enabled.
     * @param sing_scoring_token The key for karaoke scoring, used to authenticate whether the karaoke scoring is enabled.
     * @notes Enter two keys to enable karaoke scoring. Authentication is done offline, bind the Appkey and Token according to the package name (bundleID). Please contact technical support to apply for the key.
     * @return + `0`: Success
     * + `<0`: Failure.
     */
    /** {zh}
     * @brief 初始化 K 歌评分。
     * @param sing_scoring_appkey K 歌评分密钥，用于鉴权验证 K 歌功能是否开通。
     * @param sing_scoring_token K 歌评分密钥，用于鉴权验证 K 歌功能是否开通。
     * @notes 输入正确的鉴权信息才可以使用 K 歌评分相关的功能，鉴权方式为离线鉴权，根据包名（bundleID）绑定 Appkey 及 Token，K 歌评分密钥请联系技术支持同学申请。
     * @return + `0`: 成功。
     * + `<0`: 失败。
     */
    initSingScoring(sing_scoring_appkey, sing_scoring_token) {
        if (utils_1.isNull(sing_scoring_appkey) || utils_1.isNull(sing_scoring_token)) {
            return utils_1.errorFeedback("initSingScoring");
        }
        return this.instance.initSingScoring(sing_scoring_appkey, sing_scoring_token);
    }
    /** {en}
     * @hidden
     * @brief Set the configuration of karaoke scoring.
     * @param config The parameters of karaoke scoring.
     * @return  + `0`：Success.
     * + `-1`：Interface call failed.
     * + `-2`： Karaoke scoring module not integrated.
     */
    /** {zh}
     * @brief 设置 K 歌评分参数。
     * @param config K 歌评分的各项参数
     * @return + `0`：配置成功。
     * + `-1`：接口调用失败。
     * + `-2`：未集成 K 歌评分模块。
     */
    setSingScoringConfig(config) {
        if (utils_1.isNull(config) ||
            utils_1.isNull(config.sample_rate) ||
            utils_1.isNull(config.mode) ||
            utils_1.isNull(config.lyrics_filepath) ||
            utils_1.isNull(config.midi_filepath)) {
            return utils_1.errorFeedback("setSingScoringConfig");
        }
        return this.instance.setSingScoringConfig(config);
    }
    /** {en}
     * @brief Get the number of audio & video devices in the current system.
     * @return Number of audio & video devices
     */
    /** {zh}
     * @brief 获取当前系统内音视频设备数量
     * @return 音视频设备数量
     */
    getStandardPitchCount() {
        return this.instance.getStandardPitchCount();
    }
    /** {en}
     * @brief Get the standard pitch information of each lyric.
     * @param index Number of lines, of which the range is from 0 to the total number of lines obtained by calling [getStandardPitchCount](85532#rtcvideo-getstandardpitchcount) minus 1.
     * @return Standard pitch information of each lyric
     */
    /** {zh}
     * @brief 获取每句歌词的标准音高信息
     * @param index 歌词句子数，取值范围为 0 到调用 [getStandardPitchCount](85532#rtcvideo-getstandardpitchcount) 获取到的句子总数减 1。
     * @return 标准音高数据
     */
    getStandardPitchInfo(index) {
        if (utils_1.isNull(index)) {
            return utils_1.errorFeedback("getStandardPitchInfo");
        }
        return this.instance.getStandardPitchInfo(index);
    }
    /** {en}
     * @hidden
     * @brief Start karaoke scoring.
     * @param position You can get the playback position where you start karaoke scoring. Unit: ms.
     * @param scoring_info_interval Time interval between two real-time callbacks. Unit: ms; Default interval: 50 ms. Minimum interval: 20 ms.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + You can call this API after calling [initSingScoring](#initsingscoring) to initialize karaoke scoring.
     * + After this interface is called, you will receive the scoring result [onCurrentScoringInfo](85533#oncurrentscoringinfo) at set interval.
     * + If you call the [startAudioMixing](#startaudiomixing) to play an audio file, call this interface after you receive [onAudioMixingStateChanged](85533#onaudiomixingstatechanged)(AUDIO_MIXING_STATE_PLAYING(1)).
     */
    /** {zh}
     * @brief 开始 K 歌评分。
     * @param position 开始评分时，音乐的播放进度，单位：ms。
     * @param scoring_info_interval 实时回调的时间间隔，单位：ms；默认 50 ms。最低间隔为 20 ms。
     * @return + `0`: 成功。
     * + `<0`: 失败。
     * @notes + 在调用 [initSingScoring](#initsingscoring) 初始化 K 歌评分功能后调用该接口。
     * + 调用该接口后，将会根据设置的回调时间间隔，收到评分结果 [onCurrentScoringInfo](85533#oncurrentscoringinfo) 回调。
     * + 如果调用 [startAudioMixing](#startaudiomixing) 接口播放音频文件，请在收到 [onAudioMixingStateChanged](85533#onaudiomixingstatechanged)(AUDIO_MIXING_STATE_PLAYING(1)) 之后调用此接口。
     */
    startSingScoring(position, scoring_info_interval) {
        if (utils_1.isNull(position) || utils_1.isNull(scoring_info_interval)) {
            return utils_1.errorFeedback("startSingScoring");
        }
        return this.instance.startSingScoring(position, scoring_info_interval);
    }
    /** {en}
     * @hidden
     * @brief Stop karaoke scoring.
     * @return + `0`: Success
     * + `<0`: Failure.
     */
    /** {zh}
     * @brief 停止 K 歌评分。
     * @return + `0`: 成功。
     * + `<0`: 失败。
     */
    stopSingScoring() {
        return this.instance.stopSingScoring();
    }
    /** {en}
     * @hidden
     * @brief Get the score for the previous lyric.
     * @return + `<0`：Failed to get the score for the previous lyric.
     * + `>=0`：The score for the previous lyric.
     * @notes You can call this API after [startSingScoring](#startsingscoring) is called.
     */
    /** {zh}
     * @brief 获取上一句的演唱评分。
     * @return+ `<0`：获取评分失败。
     * + `>=0`：上一句歌词的演唱评分。
     * @notes 调用 [startSingScoring](#startsingscoring) 开始评分后可以调用该接口。
     */
    getLastSentenceScore() {
        return this.instance.getLastSentenceScore();
    }
    /** {en}
     * @hidden
     * @brief Get the total score for the user's current performance.
     * @return + <0：Failed to get the total score.
     * + >=0：The current total score.
     * @notes You can call this API after [startSingScoring](#startsingscoring) is called.
     */
    /** {zh}
     * @brief 获取当前演唱总分。
     * @return + `<0`：获取总分失败。
     * + `>=0`：当前演唱总分。
     * @notes 调用 [startSingScoring](#startsingscoring) 开始评分后可以调用该接口。
     */
    getTotalScore() {
        return this.instance.getTotalScore();
    }
    /** {en}
     * @hidden
     * @brief Get the average score for the user's current performance.
     * @return + `<0`：Failed to get the average score.
     * + `>=0`：The average score.
     */
    /** {zh}
     * @brief 获取当前演唱歌曲的平均分。
     * @return + `<0`：获取平均分失败。
     * + `>=0`：当前演唱平均分。
     */
    getAverageScore() {
        return this.instance.getAverageScore();
    }
    /** {en}
     * @brief Set the equalization effect for the local captured audio. The audio includes both internal captured audio and external captured voice, but not the mixing audio file.
     * @param config Voice equalization config
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes According to the Nyquist acquisition rate, the audio acquisition rate must be greater than twice the set center frequency. Otherwise, the setting will not be effective.
     */
    /** {zh}
     * @brief 设置本地采集语音的均衡效果。包含内部采集和外部采集，但不包含混音音频文件。
     * @param config 语音均衡效果
     * @return + `0`: 成功。
     * + `<0`: 失败。
     * @notes 根据奈奎斯特采样率，音频采样率必须大于等于设置的中心频率的两倍，否则，设置不生效。
     */
    setLocalVoiceEqualization(config) {
        if (utils_1.isNull(config) || utils_1.isNull(config.frequency) || utils_1.isNull(config.gain)) {
            return utils_1.errorFeedback("setLocalVoiceEqualization");
        }
        return this.instance.setLocalVoiceEqualization(config);
    }
    /** {en}
     * @brief Set the equalization effect for the local captured audio. The audio includes both internal captured audio and external captured voice, but not the mixing audio file.
     * @param param Equalization settings
     * @return + `0`: Success.
     * + `<0`: Failure.
     * @notes According to the Nyquist acquisition rate, the audio acquisition rate must be greater than twice the set center frequency. Otherwise, the setting will not be effective.
     */
    /** {zh}
     * @brief 设置本地采集语音的均衡效果。包含内部采集和外部采集，但不包含混音音频文件。
     * @param param 语音均衡效果
     * @return + `0`： 成功。
     * + `<0`： 失败。
     * @notes 根据奈奎斯特采样率，音频采样率必须大于等于设置的中心频率的两倍，否则，设置不生效。
     */
    setLocalVoiceReverbParam(param) {
        const defaultParam = {
            room_size: 50,
            decay_time: 50,
            damping: 50,
            wet_gain: 0,
            dry_gain: 0,
            pre_delay: 0,
        };
        const utralParam = { ...defaultParam, ...param };
        return this.instance.setLocalVoiceReverbParam(utralParam);
    }
    /** {en}
     * @brief Enable the reverb effect for the local captured voice.
     * @param enable
     * @return + `0`: Success.
     * + `<0`: Failure.
     * @notes Call [setLocalVoiceReverbParam](#setlocalvoicereverbparam) to set the reverb effect.
     */
    /** {zh}
     * @brief 开启本地音效混响效果
     * @param enable 是否开启
     * @return + `0`： 成功。
     * + `<0`： 失败。
     * @notes 调用 [setLocalVoiceReverbParam](#setlocalvoicereverbparam) 设置混响效果。
     */
    enableLocalVoiceReverb(enable) {
        if (utils_1.isNull(enable)) {
            return utils_1.errorFeedback("enableLocalVoiceReverb");
        }
        return this.instance.enableLocalVoiceReverb(enable);
    }
    /** {en}
     * @brief Start recording audio communication, and generate the local file.
     * @param config Recording configuration
     * @return + `0`: `kReturnStatusSuccess`: Success
     * + `-2`: `kReturnStatusParameterErr`: Invalid parameters
     * + `-3`: `kReturnStatusWrongState`: Not valid in this SDK. Please contact the technical support.
     * @notes + All audio effects are valid in the file. Mixed audio file is not included in the file.
     * + Call [stopAudioRecording](#stopaudiorecording) to stop recording.
     * + Call this API after joining the room. If you join multiple rooms, audio from all rooms are recorded in one file. After you leave the last room, the recording task ends automatically.
     * + After calling the API, you'll receive onAudioRecordingStateUpdate(85533#onaudiorecordingstateupdate).
     */
    /** {zh}
     * @brief 开启录制语音通话，生成本地文件。
     * @param config 录制参数
     * @return + `0`: 正常
     * + `-2`: 参数设置异常
     * + `-3`: 当前版本 SDK 不支持该特性，请联系技术支持人员
     * @notes + 录制包含各种音频效果。但不包含背景音乐。
     * + 调用 [stopAudioRecording](#stopaudiorecording) 关闭录制。
     * + 加入房间后才可调用。如果加入了多个房间，录制的文件中会包含各个房间的音频。离开最后一个房间后，录制任务自动停止。
     * + 调用该方法后，你会收到 onAudioRecordingStateUpdate(85533#onaudiorecordingstateupdate) 回调。
     */
    startAudioRecording(config) {
        if (utils_1.isNull(config) ||
            utils_1.isNull(config.frame_source) ||
            utils_1.isNull(config.sample_rate) ||
            utils_1.isNull(config.channel) ||
            utils_1.isNull(config.quality) ||
            utils_1.isNull(config.absolute_file_name)) {
            return utils_1.errorFeedback("startAudioRecording");
        }
        return this.instance.startAudioRecording(config);
    }
    /** {en}
     * @brief Stop audio recording.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes Call [startAudioRecording](#startaudiorecording) to start the recording task.
     */
    /** {zh}
     * @brief 停止音频文件录制
     * @return
     * + 0: 正常
     * + -3: 当前版本 SDK 不支持该特性，请联系技术支持人员
     * @notes 调用 [startAudioRecording](#startaudiorecording) 开启本地录制。
     */
    stopAudioRecording() {
        return this.instance.stopAudioRecording();
    }
    /** {en}
     * @brief Enables/disables the silent device filter function.
     * @param enabe Whether to enable the silent device filter function:
     * + 1: true
     * + 0: false
     * @return + `0`: Success
     * + `<0`: Failure.
     */
    /** {zh}
     * @brief 开启/关闭过滤无声设备功能。
     * @param enable 是否开启过滤无声设备功能:
     * + 1: 是
     * + 0: 否
     * @return + `0`: 成功。
     * + `<0`: 失败。
     */
    enableFilterSilentDevice(enable) {
        if (utils_1.isNull(enable)) {
            return utils_1.errorFeedback("enableFilterSilentDevice");
        }
        return this.instance.enableFilterSilentDevice(enable);
    }
    /** {en}
     * @brief Stop playing all audio files and mixes.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + After calling [startAudioMixing](#startaudiomixing) to play audio files and mixes, you can call this api to stop playing all the files.
     * + After calling this api to stop playing all audio and mixes, you will receive `onAudioMixingStateChanged` callback to inform you that the playing and mixing has been stopped.
     * + After you call this api to stop playing all audio and mixes, the files will be automatically uninstalled.
     */
    /** {zh}
     * @brief 停止播放所有音频文件及混音。
     * @return + `0`: 成功。
     * + `<0`: 失败。
     * @notes
     * + 调用 [startAudioMixing](#startaudiomixing) 方法开始播放音频文件及混音后，可以调用本方法停止播放所有音频文件及混音。
     * + 调用本方法停止播放所有音频文件及混音后，会收到 `onAudioMixingStateChanged` 回调，通知已停止播放和混音。
     * + 调用本方法停止播放所有音频文件及混音后，该音频文件会被自动卸载。
     */
    stopAllAudioMixing() {
        return this.instance.stopAllAudioMixing();
    }
    /** {en}
     * @brief Pause all audio files and mixes.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + After calling [startAudioMixing](#startaudiomixing) to play audio files and mixes, you can call this api to pause all the files.
     * + After calling this api to pause all audio and mixes, you can call [resumeAllAudioMixing](#resumeallaudiomixing) to resume the playing and mixing.
     * + After calling this api to pause all audio and mixes, you will receive `onAudioMixingStateChanged` callback to inform you that the playing and mixing has been paused.
     */
    /** {zh}
     * @brief 暂停播放所有音频文件及混音。
     * @return + `0`: 成功。
     * + `<0`: 失败。
     * @notes + 调用 [startAudioMixing](#startaudiomixing) 方法开始播放音频文件及混音后，可以通过调用本方法暂停播放所有音频文件及混音。
     * + 调用本方法暂停播放所有音频文件及混音后，可调用 [resumeAllAudioMixing](#resumeallaudiomixing) 方法恢复所有播放及混音。
     * + 调用本方法暂停播放所有音频文件及混音后，会收到 `onAudioMixingStateChanged` 回调，通知已暂停播放和混音。
     */
    pauseAllAudioMixing() {
        return this.instance.pauseAllAudioMixing();
    }
    /** {en}
     * @brief Resume playing all audio files and mixes.
     * @return + `0`: Success
     * + `<0`: Failure.
     * @notes + After calling [pauseAllAudioMixing](#pauseallaudiomixing) , you can call this api to resume playing all the files.
     * + After calling this api to resume all audio and mixes, you will receive `onAudioMixingStateChanged` callback to inform you that the playing and mixing has been resumed.
     */
    /** {zh}
     * @brief 恢复播放所有音频文件及混音。
     * @return + `0`: 成功。
     * + `<0`: 失败。
     * @notes + 调用 [pauseAllAudioMixing](#pauseallaudiomixing) 方法暂停所有正在播放音频文件及混音后，可以通过调用本方法恢复播放及混音。
     * + 调用本方法恢复播放所有音频文件及混音后，会收到 `onAudioMixingStateChanged` 回调，通知已恢复播放和混音。
     */
    resumeAllAudioMixing() {
        return this.instance.resumeAllAudioMixing();
    }
    /** {en}
     * @brief Turns on/ off AGC(Analog Automatic Gain Control). After AGC is enabled, SDK can automatically adjust mircrophone pockup volume to keep the output volume at a steady level.
     * @param enable whether to turn on AGC.
     * + true: AGC is turned on.
     * + false: AGC is turned off.
     * @return + 0: Success.
     * + -1: Failure.
     * @notes + You can call this method before and after joining the room. To turn on AGC before joining the room, you need to contact the technical support to get a private parameter to set [RoomProfileType](85535#roomprofiletype).
     * + To enable AGC after joining the room, you must set [RoomProfileType](85535#roomprofiletype) to `kRoomProfileTypeMeeting`, `kRoomProfileTypeMeetingRoom` or `kRoomProfileTypeClassroom`.
     * + It is not recommended to call [setAudioCaptureDeviceVolume](85532#rtcvideo-setaudiocapturedevicevolume) to adjust microphone pickup volume with AGC on.
     */
    /** {zh}
     * @brief 打开/关闭 AGC(Automatic Gain Control) 自动增益控制功能。开启该功能后，SDK 会自动调节麦克风的采集音量，确保音量稳定。
     * @param enable 是否打开 AGC 功能:
     * + true: 打开 AGC 功能。
     * + false: 关闭 AGC 功能。
     * @return +  0: 调用成功。
     * + -1: 调用失败。
     * @notes + 该方法在进房前后均可调用。如果你需要在进房前使用 AGC 功能，请联系技术支持获得私有参数，传入对应 [RoomProfileType](85535#roomprofiletype)。
     * + 要想在进房后开启 AGC 功能，你需要把 [RoomProfileType](85535#roomprofiletype) 设置为 `kRoomProfileTypeMeeting` 、`kRoomProfileTypeMeetingRoom` 或 `kRoomProfileTypeClassroom` 。
     * + AGC 功能生效后，不建议再调用 [setAudioCaptureDeviceVolume](85532#rtcvideo-setaudiocapturedevicevolume) 来调节设备麦克风的采集音量。
     */
    enableAGC(enable) {
        if (utils_1.isNull(enable)) {
            return utils_1.errorFeedback("enableAGC");
        }
        return this.instance.enableAGC(enable);
    }
    /** {en}
     * @brief Set the rotation of the local video images. Call this API to rotate the videos when the camera is fixed upside down or tilted.
     * @param rotation It defaults to `VIDEO_ROTATION_0(0)`, which means not to rotate.
     * @notes + This API affects the external-sourced videos. The final rotation would be the original rotation angles adding up with the rotation set by calling this API.
     * + This API would not rotate the background added by calling [enableVirtualBackground](85532#rtcvideo-enablevirtualbackground).
     * + The rotation would not be applied to the Stream pushed to CDN.
     */
    /** {zh}
     * @brief 设置本端采集的视频帧的旋转角度。当外接摄像头倒置或者倾斜安装时，调用本接口进行调整。
     * @param rotation 相机朝向角度，默认为 `VIDEO_ROTATION_0(0)`，无旋转角度。
     * @notes + 调用本接口也将对自定义采集视频画面生效，在原有的旋转角度基础上叠加本次设置。
     * + 通过 [enableVirtualBackground](85532#rtcvideo-enablevirtualbackground) 增加的虚拟背景，不会跟随本接口的设置进行旋转。
     * + 通过本接口设置的旋转角度不会应用到转推直播中。
     */
    setVideoCaptureRotation(rotation) {
        if (utils_1.isNull(rotation)) {
            return utils_1.errorFeedback("setVideoCaptureRotation");
        }
        return this.instance.setVideoCaptureRotation(rotation);
    }
    /** {en}
     * @brief Set the step size for each digital zooming control to the local videos.
     * @param type Required. Identifying which type the `size` is referring to.
     * @param size Required. Reserved to three decimal places. It defaults to `0`.
     *                  The meaning and range vary from different `type`s. If the scale or moving distance exceeds the range, the limit is taken as the result.
     *                  + `kZoomFocusOffset`: Increasement or decrease to the scaling factor. Range: [0, 7]. For example, when it is set to 0.5 and [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) is called to zoom in, the scale will increase `0.5`. The scale ranges [1，8] and defaults to `1`, which means an original size.
     *                  + `kZoomMoveOffset`：Ratio of the distance to the border of video images. It ranges [0, 0.5] and defaults to `0`, which means no offset. When you call [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) and choose `CAMERA_MOVE_LEFT`, the moving distance is size x original width. While for the `CAMERA_MOVE_UP`, the moving distance is size x original height. Suppose that a video spans 1080 px and the `size` is set to `0.5` so that the distance would be 0.5 x 1080 px = 540 px.
     * @notes
     * + Only one size can be set for a single call. You must call this API to pass values respectively if you intend to set multiple `size`s.
     * + As the default `size` is `0`, you must call this API before performing any digital zoom control by calling [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) or [startVideoDigitalZoomControl](85532#rtcvideo-startvideodigitalzoomcontrol).
     */
    /** {zh}
     * @brief 设置本地摄像头数码变焦参数，包括缩放倍数，移动步长。
     * @param type 数码变焦参数类型，缩放系数或移动步长。必填。
     * @param size 缩放系数或移动步长，保留到小数点后三位。默认值为 0。必填。
     *                  选择不同 `type` 时有不同的取值范围。当计算后的结果超过缩放和移动边界时，取临界值。
     *                  + `kZoomFocusOffset`：缩放系数增量，范围为 [0, 7]。例如，设置为 0.5 时，如果调用 [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) 选择 Zoom in，则缩放系数增加 0.5。缩放系数范围 [1，8]，默认为 `1`，原始大小。
     *                  + `kZoomMoveOffset`：移动百分比，范围为 [0, 0.5]，默认为 0，不移动。如果调用 [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) 选择的是左右移动，则移动距离为 size x 原始视频宽度；如果选择的是上下移动，则移动距离为 size x 原始视频高度。例如，视频帧边长为 1080 px，设置为 0.5 时，实际移动距离为 0.5 x 1080 px = 540 px。
     * @notes
     * + 每次调用本接口只能设置一种参数。如果缩放系数和移动步长都需要设置，分别调用本接口传入相应参数。
     * + 由于移动步长的默认值为 `0` ，在调用 [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) 或 [startVideoDigitalZoomControl](85532#rtcvideo-startvideodigitalzoomcontrol) 进行数码变焦操作前，应先调用本接口。
     */
    setVideoDigitalZoomConfig(type, size) {
        if (utils_1.isNull(type) || utils_1.isNull(size)) {
            return utils_1.errorFeedback("setVideoDigitalZoomConfig");
        }
        return this.instance.setVideoDigitalZoomConfig(type, size);
    }
    /** {en}
     * @brief Digital zoom or move the local video image once. This action affects both the video preview locally and the stream published.
     * @param direction Action of the digital zoom control.
     * @notes + As the default offset is `0`, you must call [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) before this API.
     * + You can only move video images after they are magnified via this API or [startVideoDigitalZoomControl](85532#rtcvideo-startvideodigitalzoomcontrol).
     * + When you request an out-of-range scale or movement, SDK will execute it with the limits. For example, when the image has been moved to the border, the image cannot be zoomed out, or has been magnified to 8x.
     * + Call [startVideoDigitalZoomControl](85532#rtcvideo-startvideodigitalzoomcontrol) to have a continuous and repeatedly digital zoom control.
     */
    /** {zh}
     * @brief 控制本地摄像头数码变焦，缩放或移动一次。设置对本地预览画面和发布到远端的视频都生效。
     * @param direction 数码变焦操作类型。
     * @notes + 由于默认步长为 `0`，调用该方法前需通过 [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) 设置参数。
     *  + 调用该方法进行移动前，应先使用本方法或 [startVideoDigitalZoomControl](85532#rtcvideo-startvideodigitalzoomcontrol) 进行放大，否则无法移动。
     * + 当数码变焦操作超出范围时，将置为临界值。例如，移动到了图片边界、放大到了 8 倍、缩小到原图大小。
     * + 如果你希望实现持续数码变焦操作，调用 [startVideoDigitalZoomControl](85532#rtcvideo-startvideodigitalzoomcontrol)。
     */
    setVideoDigitalZoomControl(direction) {
        if (utils_1.isNull(direction)) {
            return utils_1.errorFeedback("setVideoDigitalZoomControl");
        }
        return this.instance.setVideoDigitalZoomControl(direction);
    }
    /** {en}
     * @brief Continuous and repeatedly digital zoom control. This action effect both the video preview locally and the stream published.
     * @param direction Action of the digital zoom control.
     * @notes
     * + As the default offset is `0`, you must call [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) before this API.
     * + You can only move video images after they are magnified via this API or [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol).
     * + The control process stops when the scale reaches the limit, or the images have been moved to the border. if the next action exceeds the scale or movement range, SDK will execute it with the limits.
     * + Call [stopVideoDigitalZoomControl](85532#rtcvideo-stopvideodigitalzoomcontrol) to stop the ongoing zoom control.
     * + Call [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) to have a one-time digital zoom control.
     */
    /** {zh}
     * @brief 开启本地摄像头持续数码变焦，缩放或移动。设置对本地预览画面和发布到远端的视频都生效。
     * @param direction 数码变焦操作类型。
     * @notes
     * + 由于默认步长为 `0`，调用该方法前需通过 [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) 设置参数。
     * + 调用该方法进行移动前，应先使用本方法或 [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol) 进行放大，否则无法移动。
     * + 当数码变焦操作超出范围时，将置为临界值并停止操作。例如，移动到了图片边界、放大到了 8 倍、缩小到原图大小。
     * + 你也可以调用 [stopVideoDigitalZoomControl](85532#rtcvideo-stopvideodigitalzoomcontrol) 手动停止控制。
     * + 如果你希望实现单次数码变焦操作，调用 [setVideoDigitalZoomControl](85532#rtcvideo-setvideodigitalzoomcontrol)。
     */
    startVideoDigitalZoomControl(direction) {
        if (utils_1.isNull(direction)) {
            return utils_1.errorFeedback("startVideoDigitalZoomControl");
        }
        return this.instance.startVideoDigitalZoomControl(direction);
    }
    /** {en}
     * @brief Stop the ongoing digital zoom control instantly.
     * @notes Refer to [startVideoDigitalZoomControl](85532#rtcvideo-startvideodigitalzoomcontrol) for starting digital zooming.
     */
    /** {zh}
     * @brief 停止本地摄像头持续数码变焦。
     * @notes 关于开始数码变焦，参看 [startVideoDigitalZoomControl](85532#rtcvideo-startvideodigitalzoomcontrol)。
     */
    stopVideoDigitalZoomControl() {
        return this.instance.stopVideoDigitalZoomControl();
    }
    /** {en}
     * @brief Create a new task of pushing media streams to CDN and sets the relevant configurations.
     * @param task_id Task ID. The length should not exceed 126 bytes.
     *        You may want to push more than one mixed stream to CDN from the same room. When you do that, use different ID for corresponding tasks; if you will start only one task, use an empty string.
     * @param config Configurations to be set when pushing streams to CDN.
     * @return + 0: Success
     * + !0: Failure
     * @notes + When pushing more than one live streams in the same task, SDK will first mix those streams into one single stream and then push it to CDN.
     * + After calling this API, you will be informed of the result and errors during the pushing process via the [onSetRoomExtraInfoResult](85533#rtcroomcallback-onsetroomextrainforesult) callback.
     * + If you have subscribed the push-to-CDN callback in the [console](https://console.byteplus.com/rtc/cloudRTC?tab=callback), calling this API will receive a [TranscodeStarted](https://docs.byteplus.com/en/byteplus-rtc/docs/75125#transcodestarted) server callback notification. When calling this API repeatedly, the second call will trigger both [TranscodeStarted](https://docs.byteplus.com/en/byteplus-rtc/docs/75125#transcodestarted) and [TranscodeUpdated](https://docs.byteplus.com/en/byteplus-rtc/docs/75125#transcodeupdated) callbacks.  If the audio/video encoding parameters of the second call are different, [TranscodeStateChanged](https://docs.byteplus.com/en/byteplus-rtc/docs/75125#transcodestatechanged) callback will also be triggered.
     * + Call [stopPushStreamToCDN](85532#rtcvideo-stoppushstreamtocdn) to stop pushing streams to CDN.
     */
    /** {zh}
     * @brief 新增转推直播任务(新)，并设置合流的图片、视频视图布局和音频属性。
     * @param task_id 转推直播任务 ID，长度不超过 126 字节。
     *               你可以在同一房间内发起多个转推直播任务，并用不同的任务 ID 加以区分。当你需要发起多个转推直播任务时，应使用多个 ID；当你仅需发起一个转推直播任务时，建议使用空字符串。
     * @param config 转推直播配置参数。
     * @return
     * + 0: 成功
     * + !0: 失败
     * @notes + 同一个任务中转推多路直播流时，SDK 会先将多路流合成一路流，然后再进行转推。
     * + 调用该方法后，关于启动结果和推流过程中的错误，会收到 [onSetRoomExtraInfoResult](85533#rtcroomcallback-onsetroomextrainforesult) 回调。
     * + 如果你在[控制台](https://console.volcengine.com/rtc/cloudRTC?tab=callback)配置了转推直播回调，调用本接口会收到 [TranscodeStarted](https://www.volcengine.com/docs/6348/75125#transcodestarted) 服务端的回调通知。重复调用该接口时，第二次调用会同时触发 [TranscodeStarted](https://www.volcengine.com/docs/6348/75125#transcodestarted) 和 [TranscodeUpdated](https://www.volcengine.com/docs/6348/75125#transcodeupdated) ，如果第二次调用的参数不同，还会触发 [TranscodeStateChanged](https://www.volcengine.com/docs/6348/75125#transcodestatechanged)。
     * + 调用 [stopPushStreamToCDN](85532#rtcvideo-stoppushstreamtocdn) 停止转推直播。
     */
    startPushMixedStreamToCDN(task_id, config) {
        if (utils_1.isNull(task_id) || utils_1.isNull(config)) {
            return utils_1.errorFeedback("startPushMixedStreamToCDN");
        }
        return this.instance.startPushMixedStreamToCDN(task_id, {
            ...this.defaultMixedStreamConfig,
            ...config,
        });
    }
    /** {en}
     * @brief Update parameters needed when pushing media streams to CDN.
     * @param task_id Task ID. Specifys of which pushing task you want to update the parameters.
     * @param config Configurations that you want to update. Configurations that cannot be updated are specified in the description.
     * @return+ 0: Success
     * + !0: Failure
     * @notes + You will be informed of the change via the [onSetRoomExtraInfoResult](85533#rtcroomcallback-onsetroomextrainforesult) callback.
     * + After calling [startPushMixedStreamToCDN](85532#rtcvideo-startpushmixedstreamtocdn) to enable the function of pushing streams to CDN, you can call this API to update the relevant configurations.
     */
    /** {zh}
     * @brief 更新转推直播参数。
     * @param task_id 转推直播任务 ID。指定想要更新参数设置的转推直播任务。
     * @param config 转推直播配置参数。除特殊说明外，均支持过程中更新。
     * @return + 0: 成功
     * + !0: 失败
     * @notes + 会收到 [onSetRoomExtraInfoResult](85533#rtcroomcallback-onsetroomextrainforesult) 回调。
     * + 使用 [startPushMixedStreamToCDN](85532#rtcvideo-startpushmixedstreamtocdn) 启用转推直播功能后，使用此方法更新功能配置参数。
     */
    updatePushMixedStreamToCDN(task_id, config) {
        if (utils_1.isNull(task_id) || utils_1.isNull(config)) {
            return utils_1.errorFeedback("updatePushMixedStreamToCDN");
        }
        return this.instance.updatePushMixedStreamToCDN(task_id, {
            ...this.defaultMixedStreamConfig,
            ...config,
        });
    }
    /** {en}
     * @brief Assign a internal render view to the mixed stream.
     * @param task_id task ID
     * @param view View
     * @param renderOptions Render options
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes + Call this API to when you called [startPushMixedStreamToCDN](85532#irtcvideo-startpushmixedstreamtocdn).
     * + Call [`removeMixingVideo`](#removemixingvideo) to unbind.
     */
    /** {zh}
     * @brief 为客户端合流绑定本地视图
     * @param task_id task ID
     * @param view 视图
     * @param renderOptions 渲染选项
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes + 使用客户端合流功能时，调用 [startPushMixedStreamToCDN](85532#irtcvideo-startpushmixedstreamtocdn) 后，调用本 API 绑定。
     * + 如果需要解除绑定，调用 [`removeMixingVideo`](#removemixingvideo)。
     */
    setupMixingVideo(task_id, view, renderOptions = {
        render_mode: types_1.RenderMode.FIT,
        mirror: false,
    }) {
        if (!task_id || !view) {
            return utils_1.errorFeedback("setupMixingVideo");
        }
        let taskRender = this.mixingTaskViews.get(task_id);
        if (taskRender) {
            taskRender.destroy();
        }
        taskRender = new yuv_render_1.YUVRender(view, renderOptions.render_mode, renderOptions.mirror);
        this.mixingTaskViews.set(task_id, taskRender);
        return 0;
    }
    /** {en}
     * @brief Unbind the mixed stream from the view
     * @param task_id task ID
     * @returns + `0`: Success
     * + `-1`: Failure.
     * @notes Call this API after stopping pushing a mixed stream to CDN.
     */
    /** {zh}
     * @brief 为合流转推解绑本地视图
     * @param task_id task ID
     * @return + `0`：成功
     * + `-1`: 失败
     * @notes 停止接收合流转推时解绑视图。
     */
    removeMixingVideo(task_id) {
        if (!task_id) {
            return utils_1.errorFeedback("removeMixingVideo");
        }
        let taskRender = this.mixingTaskViews.get(task_id);
        if (taskRender) {
            taskRender.destroy();
            this.mixingTaskViews.delete(task_id);
        }
        return 0;
    }
    /** {en}
     * @brief Set the audio playback volume of the public stream.
     * @param public_stream_id ID of the public stream.
     * @param volume Ratio(%) of the audio playback volume to the original volume, in the range `[0, 400]`, with overflow protection. The default volume is 100.
     *               To ensure the audio quality, the recommended range is `[0,  100]`.
     * @return + 0: Success.
     * + -2: Wrong parameter.
     */
    /** {zh}
     * @brief 调节公共流的音频播放音量。
     * @param public_stream_id 公共流 ID
     * @param volume 音频播放音量值和原始音量值的比值，该比值的范围是 `[0, 400]`，单位为 %，且自带溢出保护。为保证更好的音频质量，建议设定在 `[0, 100]` 之间，其中 100 为系统默认值。
     * @return + 0: 成功调用。
     * + -2: 参数错误。
     */
    setPublicStreamAudioPlaybackVolume(public_stream_id, volume) {
        if (utils_1.isNull(public_stream_id) || utils_1.isNull(volume)) {
            return utils_1.errorFeedback("setPublicStreamAudioPlaybackVolume");
        }
        return this.instance.setPublicStreamAudioPlaybackVolume(public_stream_id, volume);
    }
    /** {en}
    * @brief Start echo detection before joining a room.
    * @param test_audio_file_path Absolute path of the music file for the detection. It is expected to encode with UTF-8. The following files are supported: mp3, aac, m4a, 3gp, wav.
    *          We recommend to assign a music file whose duration is between 10 to 20 seconds.
    *        Do not pass a Silent file.
    * @return Method call result:
    * + 0: Success.
    * + -1: Failure due to the onging process of the previous detection. Call [stopHardwareEchoDetection](85532#rtcvideo-stophardwareechodetection) to stop it before calling this API again.
    * + -2: Failure due to an invalid file path or file format.
    * @notes + You can use this feature only when `RoomProfileType` is set to `kRoomProfileTypeMeeting` or `kRoomProfileTypeMeetingRoom`.
    * + Before calling this API, ask the user for the permissions to access the local audio devices.
    * + Before calling this api, make sure the audio devices are activate and keep the capture volume and the playback volume within a reasonable range.
    * + The detection result is passed as the argument of [onHardwareEchoDetectionResult](85533#rtcvideocallback-onhardwareechodetectionresult).
    * + During the detection, the SDK is not able to response to the other testing APIs, such as [startEchoTest](85532#rtcvideo-startechotest) or [startAudioPlaybackDeviceTest](85532#rtcvideo-startaudioplaybackdevicetest).
    * + Call [stopHardwareEchoDetection](85532#rtcvideo-stophardwareechodetection) to stop the detection and release the audio devices.
    */
    /** {zh}
     * @brief 开启通话前回声检测
     * @param test_audio_file_path 用于回声检测的音频文件的绝对路径，路径字符串使用 UTF-8 编码格式，支持以下音频格式: mp3，aac，m4a，3gp，wav。
     *         音频文件不为静音文件，推荐时长为 10 ～ 20 秒。
     * @return 方法调用结果：
     * + 0: 成功。
     * + -1：失败。上一次检测未结束，请先调用 [stopHardwareEchoDetection](85532#rtcvideo-stophardwareechodetection) 停止检测 后重新调用本接口。
     * + -2：失败。路径不合法或音频文件格式不支持。
     * @notes + 只有当 `RoomProfileType` 为 `kRoomProfileTypeMeeting` 和 `kRoomProfileTypeMeetingRoom` 时支持开启本功能。
     * + 开启检测前，你需要向用户获取音频设备的使用权限。
     * + 开启检测前，请确保音频设备没有被静音，采集和播放音量正常。
     * + 调用本接口后监听 [onHardwareEchoDetectionResult](85533#rtcvideocallback-onhardwareechodetectionresult) 获取检测结果。
     * + 检测期间，进程将独占音频设备，无法使用其他音频设备测试接口： [startEchoTest](85532#rtcvideo-startechotest) 或 [startAudioPlaybackDeviceTest](85532#rtcvideo-startaudioplaybackdevicetest)。
     * + 调用 [stopHardwareEchoDetection](85532#rtcvideo-stophardwareechodetection) 停止检测，释放对音频设备的占用。
     */
    startHardwareEchoDetection(test_audio_file_path) {
        if (utils_1.isNull(test_audio_file_path)) {
            return utils_1.errorFeedback("startHardwareEchoDetection");
        }
        return this.instance.startHardwareEchoDetection(test_audio_file_path);
    }
    /** {en}
     * @brief Stop the echo detection before joining a room.
     * @return   Method call result:
     * + 0: Success.
     * + -1: Failure.
     * @notes + Refer to [startHardwareEchoDetection](85532#rtcvideo-starthardwareechodetection) for information on how to start a echo detection.
     * + We recommend calling this API to stop the detection once getting the detection result from [onHardwareEchoDetectionResult](85533#rtcvideocallback-onhardwareechodetectionresult).
     * + You must stop the echo detection to release the audio devices before the user joins a room. Otherwise, the detection may interfere with the call.
     */
    /** {zh}
     * @brief 停止通话前回声检测
     * @return 方法调用结果：
     * + 0: 成功。
     * + -1：失败。
     * @notes + 关于开启通话前回声检测，参看 [startHardwareEchoDetection](85532#rtcvideo-starthardwareechodetection) 。
     * + 建议在收到 [onHardwareEchoDetectionResult](85533#rtcvideocallback-onhardwareechodetectionresult) 通知的检测结果后，调用本接口停止检测。
     * + 在用户进入房间前结束回声检测，释放对音频设备的占用，以免影响正常通话。
     */
    stopHardwareEchoDetection() {
        return this.instance.stopHardwareEchoDetection();
    }
    /** {en}
     * @brief Sets local proxy.
     * @param configurations Local proxy configurations.
     *         You can set both Http tunnel and Socks5 as your local proxies, or only set one of them based on your needs. If you set both Http tunnel and Socks5 as your local proxies, then media traffic and signaling are routed through Socks5 proxy and Http requests through Http tunnel proxy. If you set either Http tunnel or Socks5 as your local proxy, then media traffic, signaling and Http requests are all routed through the proxy you chose.
     *         If you want to remove the existing local proxy configurations, you can call this API with the parameter set to null.
     * @notes + You must call this API before joining the room.
     * + After calling this API, you will receive [onLocalProxyStateChanged](85533#rtcvideocallback-onlocalproxystatechanged) callback that informs you of the states of local proxy connection.
     */
    /** {zh}
     * @brief 设置本地代理。
     * @param configurations 本地代理配置参数。
     *        你可以根据自己的需要选择同时设置 Http 隧道 和 Socks5 两类代理，或者单独设置其中一类代理。如果你同时设置了 Http 隧道 和 Socks5 两类代理，此时，媒体和信令采用 Socks5 代理， Http 请求采用 Http 隧道代理；如果只设置 Http 隧道 或 Socks5 一类代理，媒体、信令和 Http 请求均采用已设置的代理。
     *        调用此接口设置本地代理后，若想清空当前已有的代理设置，可再次调用此接口，选择不设置任何代理即可清空。
     * @notes + 该方法需要在进房前调用。
     * + 调用该方法设置本地代理后，SDK 会触发 [onLocalProxyStateChanged](85533#rtcvideocallback-onlocalproxystatechanged) ，返回代理连接的状态。
     */
    setLocalProxy(configurations) {
        if (utils_1.isNull(configurations)) {
            return utils_1.errorFeedback("setLocalProxy");
        }
        return this.instance.setLocalProxy(configurations);
    }
    /** {en}
     * @brief Turn on/off the earphone monitor function
     * @param mode Whether to turn on the earphone monitor function.
     * @return + 0: Success.
     * + < 0 : Fail.
     * @notes You can use ear monitoring feature when the earpiece is directly connected to the device by 3.5mm interface, USB interface, or BlueTooth. You cannot use ear monitoring feature when the earpiece is connected to a monitor via the HDMI or USB-C interface, and then connected to the device, or connected to an OTG external sound card, and then connected to the device.
     */
    /** {zh}
     * @brief 开启/关闭耳返功能
     * @param mode 是否开启耳返功能
     * @return + 0: 调用成功。
     * + < 0 : 调用失败。
     * @notes 耳返功能仅支持设备通过 3.5mm 接口、USB 接口、或蓝牙方式直连耳机时可以使用。对于通过 HDMI 或 USB-C 接口连接显示器，再连接，或通过连接 OTG 外接声卡再连接的耳机，不支持耳返功能。
     */
    setEarMonitorMode(mode) {
        if (utils_1.isNull(mode)) {
            return utils_1.errorFeedback("setEarMonitorMode");
        }
        return this.instance.setEarMonitorMode(mode);
    }
    /** {en}
     * @brief Set the volume of the earphone monitor
     * @param volume The volume of the earphone monitor, the value range: [0,100], the unit:%
     * @return + 0: Success.
     * + < 0 : Fail.
     * @notes Before setting the volume of the earphone monitor, you must first call [setEarMonitorMode](85532#rtcvideo-setearmonitormode)  to turn on the earphone monitor function.
     */
    /** {zh}
     * @brief 设置耳返的音量
     * @param volume 耳返的音量相对原始音量的比值，取值范围：[0,100]，单位：%
     * @return + 0: 调用成功。
     * + < 0 : 调用失败。
     * @notes 设置耳返音量前，你必须先调用 [setEarMonitorMode](85532#rtcvideo-setearmonitormode)  打开耳返功能。
     */
    setEarMonitorVolume(volume) {
        if (utils_1.isNull(volume)) {
            return utils_1.errorFeedback("setEarMonitorVolume");
        }
        return this.instance.setEarMonitorVolume(volume);
    }
    /** {en}
     * @brief Create an instance for audio effect player.
     * @return an instance for audio effect player
     */
    /** {zh}
     * @brief 创建音效播放器实例。
     * @return 音效播放器。
     */
    getAudioEffectPlayer() {
        if (!this.audioEffectPlayerIns) {
            this.audioEffectPlayerIns = new audio_effect_player_1.default();
        }
        return this.audioEffectPlayerIns;
    }
    /** {en}
     * @brief Create a media player instance.
     * @param player_id Media player id. The range is `[0, 3]`. You can create up to 4 instances at the same time. If it exceeds the range, nullptr will be returned.
     * @return Media player instance
     */
    /** {zh}
     * @brief 创建音乐播放器实例。
     * @param player_id 音乐播放器实例 id。取值范围为 `[0, 3]`。最多同时存在4个实例，超出取值范围时返回 nullptr。
     * @return 音乐播放器实例
     */
    getMediaPlayer(player_id) {
        if (utils_1.isNull(player_id)) {
            utils_1.errorFeedback("getMediaPlayer");
        }
        let player = data_1.createdMediaPlayer.get(player_id);
        if (!player) {
            player = new media_player_1.default(player_id);
        }
        return player;
    }
    /** {en}
     * @brief Enable the audio process mode for external sound card.
     * @param enable
     * + true: enable
     * + false: disable (by default)
     * @return + 0: Success.
     * + < 0 : Fail.
     * @notes + When you use external sound card for audio capture, enable this mode for better audio quality.
     * + When using the mode, you can only use earphones. If you need to use internal or external speaker, disable this mode.
     */
    /** {zh}
     * @brief 启用匹配外置声卡的音频处理模式
     * @param enable + true: 开启
     * + false: 不开启(默认)
     * @return + 0: 调用成功。
     * + < 0 : 调用失败。
     * @notes + 当采用外接声卡进行音频采集时，建议开启此模式，以获得更好的音质。
     * + 开启此模式时，仅支持耳机播放。如果需要使用扬声器或者外置音箱播放，关闭此模式。
     */
    enableExternalSoundCard(enable) {
        if (utils_1.isNull(enable)) {
            return utils_1.errorFeedback("enableExternalSoundCard");
        }
        return this.instance.enableExternalSoundCard(enable);
    }
    /** {en}
     * @brief Enable audio frames callback and set the format for the specified type of audio frames.
     * @param method Audio data callback method.
     *               If `method` is set as `kRecord`, `kPlayback`, `kMixed`, `kRecordScreen`, set `format` to the accurate value listed in the audio parameters format.
     *               If `method` is set as `kRemoteUser`, set `format` to `auto`.
     * @param format Audio parameters format.
     * @return + 0: Success.
     * + < 0 : Fail.
     */
    /** {zh}
     * @brief 设置并开启指定的音频数据帧回调
     * @param method 音频回调方法
     *               当音频回调方法设置为 `kRecord`、`kPlayback`、`kMixed`、`kRecordScreen`时，你需要在参数 `format` 中指定准确的采样率和声道，暂不支持设置为自动。
     *               当音频回调方法设置为 `kRemoteUser`时，暂不支持音频参数格式中设置准确的采样率和声道，你需要设置为自动。
     * @param format 音频参数格式
     * @return + 0: 调用成功。
     * + < 0 : 调用失败
     */
    enableAudioFrameCallback(method, format) {
        if (utils_1.isNull(method) || utils_1.isNull(format)) {
            return utils_1.errorFeedback("enableAudioFrameCallback");
        }
        return this.instance.enableAudioFrameCallback(method, format);
    }
    /** {en}
     * @brief Disables audio data callback.
     * @param method Audio data callback method.
     * @return  + 0: Success.
     * + < 0 : Fail.
     * @notes Call this API after calling [enableAudioFrameCallback](85532#rtcvideo-enableaudioframecallback).
     */
    /** {zh}
     * @brief 关闭音频回调
     * @param method 音频回调方法
     * @return + 0: 调用成功。
     * + < 0 : 调用失败。
     * @notes 该方法需要在调用 [enableAudioFrameCallback](85532#rtcvideo-enableaudioframecallback) 之后调用。
     */
    disableAudioFrameCallback(method) {
        if (utils_1.isNull(method)) {
            return utils_1.errorFeedback("disableAudioFrameCallback");
        }
        return this.instance.disableAudioFrameCallback(method);
    }
    /** {en}
     * @brief On the listener side, set all subscribed audio streams precisely timely aligned.
     * @param streamKey The remote audio stream used as the benchmark during time alignment.
     *                  You are recommended to use the audio stream from the lead singer.
     *                  You must call this API after receiving [onUserPublishStream](85533#rtcroomcallback-onuserpublishstream).
     * @param mode Whether to enable the alignment. Disabled by default.
     * @return  + 0: Success.
     * + < 0 : Fail.
     * @notes + You must use the function when all participants set [RoomProfileType](85535#roomprofiletype) to `kRoomProfileTypeChorus` when joining the room.
     * + All remote participants must call [startAudioMixing](85532#rtcvideo-startaudiomixing) to play background music and set `sync_progress_to_record_frame` of [AudioMixingConfig](85535#audiomixingconfig) to `true`.
     * + If the subscribed audio stream is delayed too much, it may not be precisely aligned.
     * + The chorus participants must not enable the alignment. If you wish to change the role from listener to participant, you should disable the alignment.
     */
    /** {zh}
     * @brief 在听众端，设置订阅的所有远端音频流精准对齐后播放。
     * @param streamKey 作为对齐基准的远端音频流。
     *                  一般选择主唱的音频流。
     *                  你必须在收到 [onUserPublishStream](85533#rtcroomcallback-onuserpublishstream)，确认此音频流已发布后，调用此 API。
     * @param mode 是否对齐，默认不对齐。
     * @return + 0: 调用成功。
     * + < 0 : 调用失败。
     * @notes + 你必须在实时合唱场景下使用此功能。在加入房间时，所有人应设置 [RoomProfileType](85535#roomprofiletype) 为 `kRoomProfileTypeChorus`。
     * + 订阅的所有远端流必须通过 [startAudioMixing](85532#rtcvideo-startaudiomixing) 开启了背景音乐混音，并将 [AudioMixingConfig](85535#audiomixingconfig) 中的 `sync_progress_to_record_frame` 设置为 `true`。
     * + 如果订阅的某个音频流延迟过大，可能无法实现精准对齐。
     * + 合唱的参与者不应调用此 API，因为调用此 API 会增加延迟。如果希望从听众变为合唱参与者，应关闭对齐功能。
     */
    setAudioAlignmentProperty(streamKey, mode) {
        if (utils_1.isNull(streamKey) || utils_1.isNull(mode)) {
            return utils_1.errorFeedback("setAudioAlignmentProperty");
        }
        return this.instance.setAudioAlignmentProperty(streamKey, mode);
    }
    /** {zh}
     * @brief 打开/关闭音量闪避功能，适用于在 RTC 通话过程中会同时播放短视频或音乐的场景，如“一起看”、“在线 KTV”等。
     *        开启该功能后，当检测到远端人声时，本地的媒体播放音量会自动减弱，从而保证远端人声的清晰可辨；当远端人声消失时，本地媒体音量会恢复到闪避前的音量水平。
     * @param enable 是否开启音量闪避：
     * + true: 是
     * + false: 否
     * @return  + 0: 调用成功。
     * + < 0 : 调用失败。
     */
    /** {en}
     * @brief Enables/disables the playback ducking function. This function is usually used in scenarios where short videos or music will be played simultaneously during RTC calls.
     *        With the function on, if remote voice is detected, the local media volume will be lowered to ensure the clarity of the remote voice. If remote voice disappears, the local media volume restores.
     * @param enable Whether to enable playback ducking:
     * + true: Yes
     * + false: No
     * @return
     * + 0: Success.
     * + < 0 : Fail.
     */
    enablePlaybackDucking(enable) {
        if (utils_1.isNull(enable)) {
            return utils_1.errorFeedback("enablePlaybackDucking");
        }
        return this.instance.enablePlaybackDucking(enable);
    }
    /** {en}
     * @brief Start the capture and playback test for local audio devices.
     * @param indication_interval During the test, you'll receive `onLocalAudioPropertiesReport` periodically. Set the period in ms with this parameter. Recommended value is 200 ms; the minimal value is 10 ms.
     * @return  result
     *         + 0: success
     *         + < 0: failure
     * @notes
     *       + The audio capturing stops in 30s after calling this API and begins to play the recording audio. Before that, you can call [stopAudioDeviceRecordAndPlayTest](85532#rtcvideo-stopaudiodevicerecordandplaytest) to stop audio capturing and start playing the recording audio.
     *       + Call [stopAudioDevicePlayTest](85532#rtcvideo-stopaudiodeviceplaytest) to stop the test, including capturing and playing the recording.
     *       + You must stop the test before starting another test for audio devices.
     *       + You must stop the test before calling `enableAudioPropertiesReport`.
     *       + This test performs locally and does not involve network connection testing.
     */
    /** {zh}
     * @brief 开始音频采集设备和音频播放设备测试。
     * @param indication_interval 测试中会收到 `onLocalAudioPropertiesReport` 回调，本参数指定了该周期回调的时间间隔，单位为毫秒。建议设置到大于 200 毫秒。最小不得少于 10 毫秒。
     * @return  方法调用结果
     *       + 0：方法调用成功
     *       + < 0：方法调用失败
     * @notes
     *       + 该方法在进房前后均可调用。且不可与其它音频设备测试功能同时应用。
     *       + 调用本接口 30 s 后，采集自动停止，并开始播放采集到的声音。录音播放完毕后，设备测试流程自动结束。你也可以在 30 s 内调用 [stopAudioDeviceRecordAndPlayTest](85532#rtcvideo-stopaudiodevicerecordandplaytest) 来停止采集并开始播放此前采集到的声音。
     *       + 调用 [stopAudioDevicePlayTest](85532#rtcvideo-stopaudiodeviceplaytest) 可以停止音频设备采集和播放测试。
     *       + 你不应在测试过程中，调用 `enableAudioPropertiesReport` 注册音量提示回调。
     *       + 该方法仅在本地进行音频设备测试，不涉及网络连接。
     */
    startAudioDeviceRecordTest(indication_interval) {
        if (utils_1.isNull(indication_interval)) {
            return utils_1.errorFeedback("startAudioDeviceRecordTest");
        }
        return this.instance.startAudioDeviceRecordTest(indication_interval);
    }
    /** {en}
     * @brief Call this API to stop recording in the test and start to play the recording in 30 s after calling [startAudioDeviceRecordTest](85532#rtcvideo-startaudiodevicerecordtest).
     * @return result
     *         + 0: Success
     *         + < 0: Failure
     * @notes After calling this API, the recording starts playing during which you can call [stopAudioDevicePlayTest](85532#rtcvideo-stopaudiodeviceplaytest) to stop playing.
     */
    /** {zh}
     * @brief 停止采集本地音频，并开始播放采集到的声音。录音播放完毕后，设备测试流程结束。
     *        调用 [startAudioDeviceRecordTest](85532#rtcvideo-startaudiodevicerecordtest) 30 s 内调用本接口来停止采集并开始播放此前采集到的声音。
     * @return  方法调用结果
     * + 0：方法调用成功
     * + < 0：方法调用失败
     * @notes 调用本接口开始播放录音后，可以在播放过程中调用 [stopAudioDevicePlayTest](85532#rtcvideo-stopaudiodeviceplaytest) 停止播放。
     */
    stopAudioDeviceRecordAndPlayTest() {
        return this.instance.stopAudioDeviceRecordAndPlayTest();
    }
    /** {en}
     * @brief Stop the capture and playback test for local audio devices which is started by calling [startAudioDeviceRecordTest](85532#rtcvideo-startaudiodevicerecordtest).
     * Before the test ends by itself, you can call this API to stop the recording or playing.
     * @return + 0: Success
     *         + < 0: failure
     */
    /** {zh}
     * @brief 停止由调用 [startAudioDeviceRecordTest](85532#rtcvideo-startaudiodevicerecordtest) 开始的音频播放设备测试。
     *        在音频播放设备测试自动结束前，可调用本接口停止音频采集与播放测试。
     * @return 方法调用结果
     * + 0：方法调用成功
     * + < 0：方法调用失败
     */
    stopAudioDevicePlayTest() {
        return this.instance.stopAudioDevicePlayTest();
    }
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // RTCVIDEOCALLBACK
    /**
     * @private
     */
    onLocalVideoFrame(obj) {
        const { Object } = obj;
        if (this.previewUser.videoRender) {
            let frame = yuv_render_1.YUVRender.buildYUVFrame(Object);
            this.previewUser.videoRender.renderFrame(frame);
        }
        //to be deprecated
        data_1.default.forEach(roomInfo => {
            let user = roomInfo.localUser;
            if (user.videoRender) {
                let frame = yuv_render_1.YUVRender.buildYUVFrame(Object);
                user.videoRender.renderFrame(frame);
            }
        });
    }
    /**
     * @private
     */
    onLocalScreenFrame(obj) {
        const { Object } = obj;
        if (this.previewUser.screenRender) {
            let frame = yuv_render_1.YUVRender.buildYUVFrame(Object);
            this.previewUser.screenRender.renderFrame(frame);
        }
        //to be deprecated
        data_1.default.forEach(roomInfo => {
            let user = roomInfo.localUser;
            if (user.screenRender) {
                let frame = yuv_render_1.YUVRender.buildYUVFrame(Object);
                user.screenRender.renderFrame(frame);
            }
        });
    }
    /**
     * @private
     */
    onRemoteVideoFrame(obj) {
        var _a, _b;
        const { Object } = obj;
        const userId = Object.user_id;
        const roomId = Object.channel_id;
        let user = (_a = data_1.default
            .get(roomId)) === null || _a === void 0 ? void 0 : _a.remoteUsers.get(userId);
        if ((_b = user) === null || _b === void 0 ? void 0 : _b.videoRender) {
            let frame = yuv_render_1.YUVRender.buildYUVFrame(Object);
            user.videoRender.renderFrame(frame);
        }
    }
    /**
     * @private
     */
    onPublicStreamVideoFrame(obj) {
        const { Object } = obj;
        const streamId = Object.public_stream_id;
        const streamRender = this.publicStreamViews.get(streamId);
        if (streamRender) {
            const frame = yuv_render_1.YUVRender.buildYUVFrame(Object);
            streamRender.renderFrame(frame);
        }
    }
    /**
     * @private
     */
    onMixingVideoFrame(obj) {
        const { Object } = obj;
        const task_id = Object.task_id;
        const taskRender = this.mixingTaskViews.get(task_id);
        if (taskRender) {
            const frame = yuv_render_1.YUVRender.buildYUVFrame(Object);
            taskRender.renderFrame(frame);
        }
    }
    /**
     * @private
     */
    onRemoteScreenFrame(obj) {
        var _a, _b, _c;
        const { Object } = obj;
        const userId = Object.user_id;
        const roomId = Object.channel_id;
        let user = (_b = (_a = data_1.default
            .get(roomId)) === null || _a === void 0 ? void 0 : _a.remoteUsers) === null || _b === void 0 ? void 0 : _b.get(userId);
        if ((_c = user) === null || _c === void 0 ? void 0 : _c.screenRender) {
            let frame = yuv_render_1.YUVRender.buildYUVFrame(Object);
            user.screenRender.renderFrame(frame);
        }
    }
    /**
     * @private
     */
    clearLocalVideoCanvas(userId, roomId) {
        let user = this.findUser(userId, roomId);
        if (user && user.videoRender) {
            user.videoRender.clearFrame();
        }
    }
    /**
     * @private
     */
    clearLocalScreenCanvas(userId, roomId) {
        let user = this.findUser(userId, roomId);
        if (user && user.screenRender) {
            user.screenRender.clearFrame();
        }
    }
    /**
     * @private
     */
    clearRemoteVideoCanvas(userId, roomId) {
        var _a, _b;
        let user = (_b = (_a = data_1.default
            .get(roomId)) === null || _a === void 0 ? void 0 : _a.remoteUsers) === null || _b === void 0 ? void 0 : _b.get(userId);
        if (user && user.videoRender) {
            user.videoRender.clearFrame();
        }
    }
    /**
     * @private
     */
    clearAllRemoteVideoCanvas(roomId) {
        var _a;
        const remoteUsers = (_a = data_1.default.get(roomId)) === null || _a === void 0 ? void 0 : _a.remoteUsers;
        if (!remoteUsers) {
            return;
        }
        remoteUsers.forEach((user) => {
            if (user && user.videoRender) {
                user.videoRender.clearFrame();
            }
        });
    }
    /**
     * @private
     */
    clearRemoteScreenCanvas(userId, roomId) {
        var _a, _b;
        const remoteUsers = (_a = data_1.default.get(roomId)) === null || _a === void 0 ? void 0 : _a.remoteUsers;
        let user = (_b = remoteUsers) === null || _b === void 0 ? void 0 : _b.get(userId);
        if (user && user.screenRender) {
            user.screenRender.clearFrame();
        }
    }
    /**
     * @private
     */
    cbEngine(obj) {
        if (obj.type == "GroupVideoFrame") {
            for (let i = 0; i < obj.group.length; i++) {
                this.processRTCVIDEOCALLBACK(obj.group[i]);
            }
        }
        else {
            this.processRTCVIDEOCALLBACK(obj);
        }
    }
    /**
     * @private
     */
    fire(event, ...args) {
        setImmediate(() => {
            this.emit(event, ...args);
        });
    }
    /**
     * @private
     */
    processRTCVIDEOCALLBACK(obj) {
        let type = obj.Type;
        let data = obj.Object;
        switch (type) {
            case "onLocalScreenFrame":
                {
                    this.onLocalScreenFrame(obj);
                    this.fire("onLocalScreenFrame", data);
                }
                break;
            case "onLocalVideoFrame":
                {
                    this.onLocalVideoFrame(obj);
                    this.fire("onLocalVideoFrame", data);
                }
                break;
            case "onRemoteScreenFrame":
                {
                    this.onRemoteScreenFrame(obj);
                    this.fire("onRemoteScreenFrame", data);
                }
                break;
            case "onRemoteVideoFrame":
                {
                    this.onRemoteVideoFrame(obj);
                    this.fire("onRemoteVideoFrame", data);
                }
                break;
            case "onPublicStreamVideoFrame":
                {
                    this.onPublicStreamVideoFrame(obj);
                    this.fire("onPublicStreamVideoFrame", data);
                }
                break;
            case "onPlayPublicStreamResult":
                {
                    const { public_stream_id, error_code } = data;
                    this.fire("onPlayPublicStreamResult", public_stream_id, error_code);
                }
                break;
            case "onPublicStreamSEIMessageReceived":
                {
                    const { public_stream_id, message, source_type } = data;
                    this.fire("onPublicStreamSEIMessageReceived", public_stream_id, message, source_type);
                }
                break;
            case "onFirstPublicStreamVideoFrameDecoded":
                {
                    const { public_stream_id, info } = data;
                    this.fire("onFirstPublicStreamVideoFrameDecoded", public_stream_id, info);
                }
                break;
            case "onPushPublicStreamResult":
                {
                    const { room_id, public_stream_id, error_code } = data;
                    this.fire("onPushPublicStreamResult", room_id, public_stream_id, error_code);
                }
                break;
            case "onFirstPublicStreamAudioFrame":
                {
                    const { public_stream_id } = data;
                    this.fire("onFirstPublicStreamAudioFrame", public_stream_id);
                }
                break;
            case "onWarning":
                {
                    const { warn } = data;
                    this.fire("onWarning", warn);
                }
                break;
            case "onError":
                {
                    const { err } = data;
                    this.fire("onError", err);
                }
                break;
            // case "onAudioMixingFinished":
            //   {
            //     this.fire("onAudioMixingFinished");
            //   }
            //   break;
            case "onAudioMixingStateChanged":
                {
                    this.fire("onAudioMixingStateChanged", data.mix_id, data.state, data.error);
                }
                break;
            case "onLogReport":
                {
                    this.fire("onLogReport", data.log_type, data.log_content);
                }
                break;
            case "onConnectionStateChanged":
                {
                    this.fire("onConnectionStateChanged", data.state);
                }
                break;
            case "onNetworkTypeChanged":
                {
                    this.fire("onNetworkTypeChanged", data.type);
                }
                break;
            case "onPerformanceAlarms":
                {
                    this.fire("onPerformanceAlarms", data.mode, data.room_id, data.reason, data.data);
                }
                break;
            case "onSysStats":
                {
                    let sysStats = data;
                    this.fire("onSysStats", sysStats);
                }
                break;
            case "onUserStartAudioCapture":
                {
                    this.fire("onUserStartAudioCapture", data.room_id, data.user_id);
                }
                break;
            case "onUserStopAudioCapture":
                {
                    this.fire("onUserStopAudioCapture", data.room_id, data.user_id);
                }
                break;
            case "onFirstLocalAudioFrame":
                {
                    this.fire("onFirstLocalAudioFrame", data.index);
                }
                break;
            case "onFirstRemoteAudioFrame":
                {
                    let remoteKey = data;
                    this.fire("onFirstRemoteAudioFrame", remoteKey);
                }
                break;
            case "onSimulcastSubscribeFallback":
                {
                    let streamSwitch = data;
                    this.fire("onSimulcastSubscribeFallback", streamSwitch);
                }
                break;
            case "onFirstLocalVideoFrameCaptured":
                {
                    let videoFrameInfo = data.info;
                    this.fire("onFirstLocalVideoFrameCaptured", data.index, videoFrameInfo);
                }
                break;
            case "onLocalVideoSizeChanged":
                {
                    let videoFrameInfo = data.info;
                    this.fire("onLocalVideoSizeChanged", data.index, videoFrameInfo);
                }
                break;
            case "onRemoteVideoSizeChanged":
                {
                    let videoFrameInfo = data.info;
                    this.fire("onRemoteVideoSizeChanged", data.key, videoFrameInfo);
                }
                break;
            case "onFirstRemoteVideoFrameRendered":
                {
                    let videoFrameInfo = data.info;
                    this.fire("onFirstRemoteVideoFrameRendered", data.key, videoFrameInfo);
                }
                break;
            case "onFirstRemoteVideoFrameDecoded":
                {
                    let videoFrameInfo = data.info;
                    this.fire("onFirstRemoteVideoFrameDecoded", data.key, videoFrameInfo);
                }
                break;
            case "onUserStartVideoCapture":
                {
                    this.fire("onUserStartVideoCapture", data.room_id, data.user_id);
                }
                break;
            case "onUserStopVideoCapture":
                {
                    this.fire("onUserStopVideoCapture", data.room_id, data.user_id);
                }
                break;
            case "onLocalAudioStateChanged":
                {
                    let state = data.state;
                    let error = data.error;
                    this.fire("onLocalAudioStateChanged", state, error);
                }
                break;
            case "onRemoteAudioStateChanged":
                {
                    let state = data.state;
                    let reason = data.reason;
                    this.fire("onRemoteAudioStateChanged", data.key, state, reason);
                }
                break;
            case "onLocalVideoStateChanged":
                {
                    let state = data.state;
                    let error = data.error;
                    this.fire("onLocalVideoStateChanged", data.streamIndex, state, error);
                }
                break;
            case "onRemoteVideoStateChanged":
                {
                    let state = data.state;
                    let reason = data.reason;
                    this.fire("onRemoteVideoStateChanged", data.key, state, reason);
                }
                break;
            case "onAudioFrameSendStateChanged":
                {
                    let user = data.user;
                    let state = data.state;
                    this.fire("onAudioFrameSendStateChanged", data.room_id, user, state);
                }
                break;
            case "onVideoFrameSendStateChanged":
                {
                    let user = data.user;
                    let state = data.state;
                    this.fire("onVideoFrameSendStateChanged", data.room_id, user, state);
                }
                break;
            case "onScreenVideoFrameSendStateChanged":
                {
                    let user = data.user;
                    let state = data.state;
                    this.fire("onScreenVideoFrameSendStateChanged", data.room_id, user, state);
                }
                break;
            case "onAudioFramePlayStateChanged":
                {
                    let user = data.user;
                    let state = data.state;
                    this.fire("onAudioFramePlayStateChanged", data.room_id, user, state);
                }
                break;
            case "onVideoFramePlayStateChanged":
                {
                    let user = data.user;
                    let state = data.state;
                    this.fire("onVideoFramePlayStateChanged", data.room_id, user, state);
                }
                break;
            case "onScreenVideoFramePlayStateChanged":
                {
                    let user = data.user;
                    let state = data.state;
                    this.fire("onScreenVideoFramePlayStateChanged", data.room_id, user, state);
                }
                break;
            // message
            case "onSEIMessageReceived":
                {
                    let streamKey = data.stream_key;
                    this.fire("onSEIMessageReceived", streamKey, data.message);
                }
                break;
            case "onStreamMixingEvent":
                {
                    this.fire("onStreamMixingEvent", data.event, data.task_id, data.error, data.mix_type);
                }
                break;
            case "onRecordingStateUpdate":
                {
                    let type = data.type;
                    let info = data.info;
                    this.fire("onRecordingStateUpdate", type, data.state, data.error_code, info);
                }
                break;
            case "onRecordingProgressUpdate":
                {
                    let type = data.type;
                    let process = data.process;
                    let info = data.info;
                    this.fire("onRecordingProgressUpdate", type, process, info);
                }
                break;
            case "onRecordAudioFrame":
                {
                    let audioFrame = data.audio_frame;
                    this.fire("onRecordAudioFrame", audioFrame);
                }
                break;
            case "onPlaybackAudioFrame":
                {
                    let audioFrame = data.audio_frame;
                    this.fire("onPlaybackAudioFrame", audioFrame);
                }
                break;
            case "onMixedAudioFrame":
                {
                    let audioFrame = data.audio_frame;
                    this.fire("onMixedAudioFrame", audioFrame);
                }
                break;
            case "onLoginResult":
                {
                    this.fire("onLoginResult", data.uid, data.error_code, data.elapsed);
                }
                break;
            case "onLogout":
                {
                    this.fire("onLogout");
                }
                break;
            case "onServerParamsSetResult":
                {
                    this.fire("onServerParamsSetResult", data.error);
                }
                break;
            case "onGetPeerOnlineStatus":
                {
                    this.fire("onGetPeerOnlineStatus", data.peer_user_id, data.status);
                }
                break;
            case "onUserMessageReceivedOutsideRoom":
                {
                    this.fire("onUserMessageReceivedOutsideRoom", data.uid, data.message);
                }
                break;
            case "onUserBinaryMessageReceivedOutsideRoom":
                {
                    this.fire("onUserBinaryMessageReceivedOutsideRoom", data.uid, data.message);
                }
                break;
            case "onUserMessageSendResultOutsideRoom":
                {
                    this.fire("onUserMessageSendResultOutsideRoom", data.msgid, data.error);
                }
                break;
            case "onAudioMixingPlayingProgress":
                {
                    this.fire("onAudioMixingPlayingProgress", data.mix_id, data.progress);
                }
                break;
            case "onServerMessageSendResult":
                {
                    this.fire("onServerMessageSendResult", data.msgid, data.error, data.msg);
                }
                break;
            case "onASRSuccess":
                {
                    this.fire("onASRSuccess");
                }
                break;
            case "onMessage":
                {
                    this.fire("onMessage", data.message);
                }
                break;
            case "onASRError":
                {
                    this.fire("onASRError", data.errorCode, data.errorMessage);
                }
                break;
            case "onNetworkDetectionResult":
                {
                    this.fire("onNetworkDetectionResult", data.type, data.quality, data.rtt, data.lost_rate, data.bit_rate, data.jitter);
                }
                break;
            case "onNetworkDetectionStopped":
                {
                    this.fire("onNetworkDetectionStopped", data.reason);
                }
                break;
            case "onLocalAudioPropertiesReport":
                {
                    let AudioPropertiesInfo = data.audio_properties_infos;
                    this.fire("onLocalAudioPropertiesReport", AudioPropertiesInfo, data.audio_properties_info_number);
                }
                break;
            case "onRemoteAudioPropertiesReport":
                {
                    let AudioPropertiesInfo = data.audio_properties_infos;
                    this.fire("onRemoteAudioPropertiesReport", AudioPropertiesInfo, data.audio_properties_info_number, data.total_remote_volume);
                }
                break;
            case "onEchoTestResult":
                {
                    this.fire("onEchoTestResult", data.result);
                }
                break;
            case "onVideoDeviceStateChanged":
                {
                    this.fire("onVideoDeviceStateChanged", data.device_id, data.device_type, data.device_state, data.device_error);
                }
                break;
            case "onAudioDeviceStateChanged":
                {
                    this.fire("onAudioDeviceStateChanged", data.device_id, data.device_type, data.device_state, data.device_error);
                }
                break;
            case "onAudioPlaybackDeviceTestVolume":
                {
                    this.fire("onAudioPlaybackDeviceTestVolume", data.volume);
                }
                break;
            case "onActiveSpeaker":
                {
                    this.fire("onActiveSpeaker", data.room_id, data.uid);
                }
                break;
            case "onStreamPushEvent":
                {
                    this.fire("onStreamPushEvent", data.event, data.task_id, data.error);
                }
                break;
            case "onMusicListResult":
                {
                    const { music_infos, total_musics_size, error_code } = data;
                    this.fire(type, music_infos, total_musics_size, error_code);
                }
                break;
            case "onSearchMusicResult":
                {
                    const { music_infos, total_musics_size, error_code } = data;
                    this.fire(type, music_infos, total_musics_size, error_code);
                }
                break;
            case "onHotMusicResult":
                {
                    const { hot_infos, error_code } = data;
                    this.fire(type, hot_infos, error_code);
                }
                break;
            case "onMusicDetailResult":
                {
                    const { music_info, error_code } = data;
                    this.fire(type, music_info, error_code);
                }
                break;
            case "onDownloadSuccess":
                {
                    const { download_id, download_info } = data;
                    this.fire(type, download_id, download_info);
                }
                break;
            case "onDownloadFailed":
                {
                    const { download_id, error_code } = data;
                    this.fire(type, download_id, error_code);
                }
                break;
            case "onDownloadMusicProgress":
                {
                    const { download_id, download_percentage } = data;
                    this.fire(type, download_id, download_percentage);
                }
                break;
            case "onPlayProgress":
                {
                    const { music_id, progress } = data;
                    this.fire(type, music_id, progress);
                }
                break;
            case "onPlayStateChanged":
                {
                    const { music_id, play_state, error_code } = data;
                    this.fire(type, music_id, play_state, error_code);
                }
                break;
            case "onRemoteVideoSuperResolutionModeChanged":
                {
                    const { stream_key, mode, reason } = data;
                    this.fire(type, stream_key, mode, reason);
                }
                break;
            case "onTakeLocalSnapshotResult":
                {
                    const { taskId, streamIndex, image, errorCode } = data;
                    const imgBase64 = "data:image/png;base64," + image;
                    this.fire(type, taskId, streamIndex, imgBase64, errorCode);
                }
                break;
            case "onTakeRemoteSnapshotResult":
                {
                    const { taskId, streamKey, image, errorCode } = data;
                    const imgBase64 = "data:image/png;base64," + image;
                    this.fire(type, taskId, streamKey, imgBase64, errorCode);
                }
                break;
            case "onCreateRoomStateChanged":
                {
                    const { room_id, error_code } = data;
                    this.fire(type, room_id, error_code);
                }
                break;
            case "onHttpProxyState":
                {
                    const { state } = data;
                    this.fire(type, state);
                }
                break;
            case "onHttpsProxyState":
                {
                    const { state } = data;
                    this.fire(type, state);
                }
                break;
            case "onSocks5ProxyState":
                {
                    const { state, cmd, proxy_address, local_address, remote_address, } = data;
                    this.fire(type, state, cmd, proxy_address, local_address, remote_address);
                }
                break;
            case "onStreamSyncInfoReceived":
                {
                    const { stream_key, stream_type, data: syncInfoData } = data;
                    this.fire(type, stream_key, stream_type, syncInfoData);
                }
                break;
            case "onScreenAudioFrameSendStateChanged":
                {
                    const { room_id, user, state } = data;
                    this.fire(type, room_id, user, state);
                }
                break;
            case "onScreenAudioFramePlayStateChanged":
                {
                    const { room_id, user, state } = data;
                    this.fire(type, room_id, user, state);
                }
                break;
            case "onCloudProxyConnected":
                {
                    const { interval } = data;
                    this.fire(type, interval);
                }
                break;
            case "onNetworkTimeSynchronized":
                {
                    this.fire(type);
                }
                break;
            case "onLicenseWillExpire":
                {
                    const { days } = data;
                    this.fire(type, days);
                }
                break;
            case "onFaceDetectResult":
                {
                    const { detect_result, face_count, rect, image_width, image_height, frame_timestamp_us, } = data;
                    this.fire(type, detect_result, face_count, rect, image_width, image_height, frame_timestamp_us);
                }
                break;
            case "onAudioDeviceVolumeChanged":
                {
                    const { device_type, volume, muted } = data;
                    this.fire(type, device_type, volume, muted);
                }
                break;
            case "onCurrentScoringInfo":
                {
                    const { info } = data;
                    this.fire(type, info);
                }
                break;
            case "onAudioRecordingStateUpdate":
                {
                    const { state, error_code } = data;
                    this.fire(type, state, error_code);
                }
                break;
            // 352
            case "onExtensionAccessError":
                {
                    const { extension_name, msg } = data;
                    this.fire(type, extension_name, msg);
                }
                break;
            case "onPublicStreamDataMessageReceived":
                {
                    const { public_stream_id, message, source_type } = data;
                    this.fire(type, public_stream_id, message, source_type);
                }
                break;
            case "onHardwareEchoDetectionResult":
                {
                    const { hardware_echo_detection_result } = data;
                    this.fire(type, hardware_echo_detection_result);
                }
                break;
            case "onLocalProxyStateChanged":
                {
                    const { local_proxy_type, local_proxy_state, local_proxy_error, } = data;
                    this.fire(type, local_proxy_type, local_proxy_state, local_proxy_error);
                }
                break;
            case "onMixingEvent":
                {
                    const { event, task_id, error, mix_type } = data;
                    this.fire(type, event, task_id, error, mix_type);
                }
                break;
            case "onMixingVideoFrame":
                {
                    this.onMixingVideoFrame(obj);
                    this.fire("onMixingVideoFrame", data);
                }
                break;
            case "onMixingAudioFrame":
                {
                    const { task_id, audio_frame } = data;
                    this.fire(type, task_id, audio_frame);
                }
                break;
            case "onMixingDataFrame":
                {
                    const { task_id, data_frame } = data;
                    this.fire(type, task_id, data_frame);
                }
                break;
            // 354
            case "onClearCacheResult":
                {
                    const { error_code } = data;
                    this.fire(type, error_code);
                }
                break;
            // 缺失回调补充
            case "onRemoteUserAudioFrame":
                {
                    const { stream_info, audio_frame } = data;
                    this.fire(type, stream_info, audio_frame);
                }
                break;
            case "onRecordScreenAudioFrame":
                {
                    const { audio_frame } = data;
                    this.fire(type, audio_frame);
                }
                break;
            case "onAudioDeviceWarning":
                {
                    const { device_id, device_type, device_warning } = data;
                    this.fire(type, device_id, device_type, device_warning);
                }
                break;
            case "onVideoDeviceWarning":
                {
                    const { device_id, device_type, device_warning } = data;
                    this.fire(type, device_id, device_type, device_warning);
                }
                break;
            case "onSEIStreamUpdate":
                {
                    const { key, type: SEIStreamEventType } = data;
                    this.fire(type, key, SEIStreamEventType);
                }
                break;
            default:
                {
                }
                break;
        }
    }
    /**
     * @private
     */
    findUser(userId, roomId) {
        var _a, _b, _c, _d;
        let ret = undefined;
        const localUser = (_a = data_1.default.get(roomId)) === null || _a === void 0 ? void 0 : _a.localUser;
        const remoteUsers = (_b = data_1.default.get(roomId)) === null || _b === void 0 ? void 0 : _b.remoteUsers;
        if (userId === ((_c = localUser) === null || _c === void 0 ? void 0 : _c.userId)) {
            ret = localUser;
        }
        else {
            ret = (_d = remoteUsers) === null || _d === void 0 ? void 0 : _d.get(userId);
        }
        return ret;
    }
}
__decorate([
    checkInit
], RTCVideo.prototype, "destroyRTCVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "feedback", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setBusinessId", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setRuntimeParameters", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startAudioCapture", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enumerateAudioPlaybackDevices", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enumerateAudioCaptureDevices", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioPlaybackDevice", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioCaptureDevice", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioPlaybackDevice", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioCaptureDevice", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioPlaybackDeviceVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioPlaybackDeviceVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioCaptureDeviceVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioCaptureDeviceVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioPlaybackDeviceMute", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioPlaybackDeviceMute", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioCaptureDeviceMute", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioCaptureDeviceMute", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setCaptureVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setPlaybackVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setRemoteAudioPlaybackVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopAudioPlaybackDeviceTest", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioProfile", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startAudioPlaybackDeviceTest", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startEchoTest", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopEchoTest", null);
__decorate([
    checkInit
], RTCVideo.prototype, "initAudioPlaybackDeviceForTest", null);
__decorate([
    checkInit
], RTCVideo.prototype, "initAudioCaptureDeviceForTest", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableAudioPropertiesReport", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableVocalInstrumentBalance", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setDummyCaptureImagePath", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startVideoCapture", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopVideoCapture", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enumerateVideoCaptureDevices", null);
__decorate([
    checkInit
], RTCVideo.prototype, "followSystemPlaybackDevice", null);
__decorate([
    checkInit
], RTCVideo.prototype, "followSystemCaptureDevice", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setVideoCaptureDevice", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getVideoCaptureDevice", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setMaxVideoEncoderConfig", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setLocalVideoMirrorType", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableSimulcastMode", null);
__decorate([
    checkInit
], RTCVideo.prototype, "initCVResource", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAuthMessage", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableVideoEffect", null);
__decorate([
    checkInit
], RTCVideo.prototype, "disableVideoEffect", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableEffectBeauty", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setBeautyIntensity", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setEffectNodes", null);
__decorate([
    checkInit
], RTCVideo.prototype, "updateEffectNode", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setColorFilter", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setColorFilterIntensity", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startLiveTranscoding", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopLiveTranscoding", null);
__decorate([
    checkInit
], RTCVideo.prototype, "updateLiveTranscoding", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startPushSingleStreamToCDN", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopPushStreamToCDN", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAnsMode", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setRemoteVideoSuperResolution", null);
__decorate([
    checkInit
], RTCVideo.prototype, "takeLocalSnapshot", null);
__decorate([
    checkInit
], RTCVideo.prototype, "takeRemoteSnapshot", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getNetworkTimeInfo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "sendStreamSyncInfo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startCloudProxy", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopCloudProxy", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setupPublicStreamVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "removePublicStreamVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setPublicStreamVideoSink", null);
__decorate([
    checkInit
], RTCVideo.prototype, "unsetPublicStreamVideoSink", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startScreenAudioCapture", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startMacScreenAudioCapture", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startScreenVideoCapture", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopScreenAudioCapture", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopScreenVideoCapture", null);
__decorate([
    checkInit
], RTCVideo.prototype, "updateScreenCaptureRegion", null);
__decorate([
    checkInit
], RTCVideo.prototype, "updateScreenCaptureHighlightConfig", null);
__decorate([
    checkInit
], RTCVideo.prototype, "updateScreenCaptureMouseCursor", null);
__decorate([
    checkInit
], RTCVideo.prototype, "updateScreenCaptureFilterConfig", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setScreenAudioChannel", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getScreenCaptureSourceList", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getThumbnail", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getWindowAppIcon", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setScreenAudioStreamIndex", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setScreenVideoEncoderConfig", null);
__decorate([
    checkInit
], RTCVideo.prototype, "login", null);
__decorate([
    checkInit
], RTCVideo.prototype, "logout", null);
__decorate([
    checkInit
], RTCVideo.prototype, "updateLoginToken", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setServerParams", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getPeerOnlineStatus", null);
__decorate([
    checkInit
], RTCVideo.prototype, "sendUserMessageOutsideRoom", null);
__decorate([
    checkInit
], RTCVideo.prototype, "sendUserBinaryMessageOutsideRoom", null);
__decorate([
    checkInit
], RTCVideo.prototype, "sendServerMessage", null);
__decorate([
    checkInit
], RTCVideo.prototype, "sendServerBinaryMessage", null);
__decorate([
    checkInit
], RTCVideo.prototype, "sendSEIMessage", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setVideoCaptureConfig", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startAudioMixing", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopAudioMixing", null);
__decorate([
    checkInit
], RTCVideo.prototype, "pauseAudioMixing", null);
__decorate([
    checkInit
], RTCVideo.prototype, "resumeAudioMixing", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioMixingVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioMixingDuration", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioMixingCurrentPosition", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioMixingPosition", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioMixingPlaybackDuration", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioMixingDualMonoMode", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioMixingPitch", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioMixingPlaybackSpeed", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioMixingLoudness", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioMixingProgressInterval", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioTrackCount", null);
__decorate([
    checkInit
], RTCVideo.prototype, "selectAudioTrack", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setLocalVoicePitch", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setPublishFallbackOption", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setRemoteUserPriority", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startNetworkDetection", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopNetworkDetection", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableVirtualBackground", null);
__decorate([
    checkInit
], RTCVideo.prototype, "disableVirtualBackground", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableFaceDetection", null);
__decorate([
    checkInit
], RTCVideo.prototype, "disableFaceDetection", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setVideoWatermark", null);
__decorate([
    checkInit
], RTCVideo.prototype, "clearVideoWatermark", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setupLocalVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "removeLocalVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setupRemoteVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "removeRemoteVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "removeAllRemoteVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setupLocalScreen", null);
__decorate([
    checkInit
], RTCVideo.prototype, "removeLocalScreen", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setupRemoteScreen", null);
__decorate([
    checkInit
], RTCVideo.prototype, "removeRemoteScreen", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setLocalVideoSink", null);
__decorate([
    checkInit
], RTCVideo.prototype, "unsetLocalVideoSink", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setRemoteVideoSink", null);
__decorate([
    checkInit
], RTCVideo.prototype, "unsetRemoteVideoSink", null);
__decorate([
    checkInit
], RTCVideo.prototype, "playMusic", null);
__decorate([
    checkInit
], RTCVideo.prototype, "pauseMusic", null);
__decorate([
    checkInit
], RTCVideo.prototype, "resumeMusic", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopMusic", null);
__decorate([
    checkInit
], RTCVideo.prototype, "seekMusic", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setMusicVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "switchAudioTrackType", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setMusicPitch", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setMaxCacheSize", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getMusicList", null);
__decorate([
    checkInit
], RTCVideo.prototype, "searchMusic", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getHotMusic", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getMusicDetail", null);
__decorate([
    checkInit
], RTCVideo.prototype, "downloadMusic", null);
__decorate([
    checkInit
], RTCVideo.prototype, "downloadLyric", null);
__decorate([
    checkInit
], RTCVideo.prototype, "downloadMidi", null);
__decorate([
    checkInit
], RTCVideo.prototype, "cancelDownload", null);
__decorate([
    checkInit
], RTCVideo.prototype, "clearCache", null);
__decorate([
    checkInit
], RTCVideo.prototype, "initSingScoring", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setSingScoringConfig", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getStandardPitchCount", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getStandardPitchInfo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startSingScoring", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopSingScoring", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getLastSentenceScore", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getTotalScore", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAverageScore", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setLocalVoiceEqualization", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setLocalVoiceReverbParam", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableLocalVoiceReverb", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startAudioRecording", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopAudioRecording", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableFilterSilentDevice", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopAllAudioMixing", null);
__decorate([
    checkInit
], RTCVideo.prototype, "pauseAllAudioMixing", null);
__decorate([
    checkInit
], RTCVideo.prototype, "resumeAllAudioMixing", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableAGC", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setVideoCaptureRotation", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setVideoDigitalZoomConfig", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setVideoDigitalZoomControl", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startVideoDigitalZoomControl", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopVideoDigitalZoomControl", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startPushMixedStreamToCDN", null);
__decorate([
    checkInit
], RTCVideo.prototype, "updatePushMixedStreamToCDN", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setupMixingVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "removeMixingVideo", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setPublicStreamAudioPlaybackVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startHardwareEchoDetection", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopHardwareEchoDetection", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setLocalProxy", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setEarMonitorMode", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setEarMonitorVolume", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getAudioEffectPlayer", null);
__decorate([
    checkInit
], RTCVideo.prototype, "getMediaPlayer", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableExternalSoundCard", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enableAudioFrameCallback", null);
__decorate([
    checkInit
], RTCVideo.prototype, "disableAudioFrameCallback", null);
__decorate([
    checkInit
], RTCVideo.prototype, "setAudioAlignmentProperty", null);
__decorate([
    checkInit
], RTCVideo.prototype, "enablePlaybackDucking", null);
__decorate([
    checkInit
], RTCVideo.prototype, "startAudioDeviceRecordTest", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopAudioDeviceRecordAndPlayTest", null);
__decorate([
    checkInit
], RTCVideo.prototype, "stopAudioDevicePlayTest", null);
__decorate([
    checkInit
], RTCVideo, "getErrorDescription", null);
///////////////////////////////////////////////////////////////////
exports.default = RTCVideo;
//# sourceMappingURL=video.js.map